{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3559a8bd-d3ef-4fc1-9d11-9adbc07d2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from utils.utils import set_seed\n",
    "set_seed()\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.distributions import Normal, Laplace, RelaxedOneHotCategorical\n",
    "from torchdiffeq import odeint  # For continuous-time normalizing flows\n",
    "\n",
    "from feature.scalers import ranged_scaler\n",
    "from feature.engineering import *\n",
    "from CARAT.model_utils import *\n",
    "from CARAT.model import CausalGraphVAE\n",
    "from CARAT.components import *\n",
    "from utils.utils import set_seed, logger\n",
    "\n",
    "# Torch settings\n",
    "#torch.use_deterministic_algorithms(False)\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.autograd.profiler.profile(enabled=False)\n",
    "#torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "#torch.autograd.set_detect_anomaly(mode=False)\n",
    "\n",
    "# Environment variables\n",
    "#os.environ['CUBLAS_WORKSPACE_CONFIG'] = '167772160'\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "#os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set device\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "data = []\n",
    "with open('data/TEP/idv1/y.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        data.append([float(col.strip()) for col in columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcf9903-62ed-4eec-9a22-28d013172a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = len(data[0])\n",
    "col_names = []\n",
    "for i in  range(0,vars):\n",
    "    col_names.append('x_'+str(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4186cd19-2804-4acc-9e80-651792a44849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from feature.scalers import ranged_scaler\n",
    "df = pl.DataFrame(data,schema=col_names)\n",
    "for col in df.columns:\n",
    "    df = df.with_columns(ranged_scaler(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f176e5-8328-47d3-898c-620aec152f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5211d2-8b0d-48f1-9863-9986f68f65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random dates, trivial for this exercise\n",
    "\n",
    "start_date = '2023-03-01'  # Define the start date\n",
    "date_range = pd.date_range(start=start_date, periods=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e78764d-6061-4347-a15b-42915ce98352",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = most_frequent(find_optimal_lags_for_dataframe(df))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41f2494-6c22-46f8-921d-dc3dd99a8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']=date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b131b6f5-0728-4a5f-a866-7b964d369d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='None', ylabel='x_44'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=df,y='x_44',x=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e39ac1b-36cc-429c-809f-01b016584bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['x_1', 'x_4','x_7','x_13','x_16','x_18','x_19','x_44','x_50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba3bdf6-cc0e-4f60-bd0d-ef5be924498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[200:]\n",
    "bad = df[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1ffb3d-85b0-4e90-be11-2e218b5f69b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_1', 'x_4', 'x_7', 'x_13', 'x_16', 'x_18', 'x_19', 'x_44', 'x_50'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3dc758-21df-44c7-bc12-ceb0dc3e36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    normal = normal.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "try:\n",
    "    bad = bad.drop('time',axis=1)\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a52bc7-6830-4a25-8c76-7d167da5d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb92727-92ff-4c95-ab54-be1c0a279212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_1', 'x_4', 'x_7', 'x_13', 'x_16', 'x_18', 'x_19', 'x_44', 'x_50']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645900e2-8fb0-4eb4-895b-f1d6c4c63c58",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fb9c3b-10ff-44ee-87bc-7612dc566c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 812.0176\n",
      "Recon Loss =778.9736, KL Loss = 0.0028, Sparsity Loss = 31.9106, Lagrangian Loss = 1.1306\n",
      "Epoch 51: Loss = 41.0472\n",
      "Recon Loss =6.0465, KL Loss = 1.2986, Sparsity Loss = 31.7032, Lagrangian Loss = 1.9989\n",
      "Epoch 101: Loss = 38.9552\n",
      "Recon Loss =2.6886, KL Loss = 1.6900, Sparsity Loss = 30.1271, Lagrangian Loss = 4.4494\n",
      "Early stopping triggered. Last Epoch: 106\n",
      "Recon Loss =2.6988, KL Loss = 1.7064, Sparsity Loss = 31.9658, Lagrangian Loss = 4.9728\n",
      "Epoch 1: Loss = 957.2318\n",
      "Recon Loss =906.3237, KL Loss = 0.0010, Sparsity Loss = 46.2988, Lagrangian Loss = 4.6082\n",
      "Epoch 51: Loss = 959.3618\n",
      "Recon Loss =906.2664, KL Loss = 0.0010, Sparsity Loss = 45.9023, Lagrangian Loss = 7.1921\n",
      "Early stopping triggered. Last Epoch: 50\n",
      "Recon Loss =906.2664, KL Loss = 0.0010, Sparsity Loss = 45.9023, Lagrangian Loss = 7.1921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.986847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.930929</td>\n",
       "      <td>0.849648</td>\n",
       "      <td>0.900638</td>\n",
       "      <td>0.865319</td>\n",
       "      <td>0.886634</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407225</td>\n",
       "      <td>0.823270</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.925631</td>\n",
       "      <td>0.830610</td>\n",
       "      <td>0.910614</td>\n",
       "      <td>0.623310</td>\n",
       "      <td>0.822541</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.906688</td>\n",
       "      <td>0.843386</td>\n",
       "      <td>0.859890</td>\n",
       "      <td>0.406988</td>\n",
       "      <td>0.754238</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.917131</td>\n",
       "      <td>0.836309</td>\n",
       "      <td>0.887852</td>\n",
       "      <td>0.358308</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.840945</td>\n",
       "      <td>0.773637</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.400123</td>\n",
       "      <td>0.705696</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.830790</td>\n",
       "      <td>0.666767</td>\n",
       "      <td>0.903228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600196</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_44  0.986847       1.000000  0.851095         1.000000         0.959486   \n",
       "x_16  0.930929       0.849648  0.900638         0.865319         0.886634   \n",
       "x_18  1.000000       0.885855  1.000000         0.407225         0.823270   \n",
       "x_13  0.925631       0.830610  0.910614         0.623310         0.822541   \n",
       "x_1   0.906688       0.843386  0.859890         0.406988         0.754238   \n",
       "x_19  0.917131       0.836309  0.887852         0.358308         0.749900   \n",
       "x_50  0.840945       0.773637  0.808081         0.400123         0.705696   \n",
       "x_7   0.830790       0.666767  0.903228         0.000000         0.600196   \n",
       "x_4   0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_44  0.000000  \n",
       "x_16  1.000000  \n",
       "x_18  0.250000  \n",
       "x_13  0.500001  \n",
       "x_1   1.000000  \n",
       "x_19  0.250000  \n",
       "x_50  0.500001  \n",
       "x_7   1.000000  \n",
       "x_4   0.500001  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_STEPS = 3\n",
    "BATCH_SIZE = 100\n",
    "hidden_dim = 256\n",
    "latent_dim = 16\n",
    "dataset_nominal = TimeSeriesDataset(normal, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = CausalGraphVAE(input_dim=normal.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=normal.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=None).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "# Train on nominal data\n",
    "#print(\"Pretraining on nominal data...\")\n",
    "model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "\n",
    "# Extract learned adjacency\n",
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "dataset_bad = TimeSeriesDataset(bad, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_bad = DataLoader(dataset_bad, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "fine_tuned = CausalGraphVAE(input_dim=bad.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=bad.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=prior_adj).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "# Train on nominal data\n",
    "# print(\"Pretraining on nominal data...\")\n",
    "fine_tuned.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "\n",
    "X_data = torch.empty(0,device=device)\n",
    "T_data = torch.empty(0,device=device)\n",
    "for batch_idx, (X_batch, time_batch) in enumerate(dataloader_bad):\n",
    "    X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "    T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "\n",
    "\n",
    "causes= fine_tuned.infer_causal_effect(X_data=X_data,T_data=T_data,target_variable='x_4',\n",
    "                                       labels=cols,non_causal_indices=[],root_rank=False)\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b52236-a1c7-4a5d-86fc-1d54ab617431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.934715</td>\n",
       "      <td>0.978929</td>\n",
       "      <td>0.875572</td>\n",
       "      <td>0.244501</td>\n",
       "      <td>0.758429</td>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.892575</td>\n",
       "      <td>0.804263</td>\n",
       "      <td>0.975344</td>\n",
       "      <td>0.234432</td>\n",
       "      <td>0.726653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.869936</td>\n",
       "      <td>0.910371</td>\n",
       "      <td>0.811402</td>\n",
       "      <td>0.300183</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.768353</td>\n",
       "      <td>0.654598</td>\n",
       "      <td>0.881077</td>\n",
       "      <td>0.585854</td>\n",
       "      <td>0.722470</td>\n",
       "      <td>0.199999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.962413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719015</td>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.704574</td>\n",
       "      <td>0.697514</td>\n",
       "      <td>0.706220</td>\n",
       "      <td>0.578498</td>\n",
       "      <td>0.671702</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.759935</td>\n",
       "      <td>0.632370</td>\n",
       "      <td>0.888331</td>\n",
       "      <td>0.168288</td>\n",
       "      <td>0.612231</td>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_1   1.000000       0.998528  1.000000         1.000000         0.999632   \n",
       "x_19  0.934715       0.978929  0.875572         0.244501         0.758429   \n",
       "x_13  0.892575       0.804263  0.975344         0.234432         0.726653   \n",
       "x_7   0.869936       0.910371  0.811402         0.300183         0.722973   \n",
       "x_18  0.768353       0.654598  0.881077         0.585854         0.722470   \n",
       "x_50  0.962413       1.000000  0.913646         0.000000         0.719015   \n",
       "x_4   0.704574       0.697514  0.706220         0.578498         0.671702   \n",
       "x_44  0.759935       0.632370  0.888331         0.168288         0.612231   \n",
       "x_16  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_1   0.800001  \n",
       "x_19  0.800001  \n",
       "x_13  0.000000  \n",
       "x_7   1.000000  \n",
       "x_18  0.199999  \n",
       "x_50  0.800001  \n",
       "x_4   0.400000  \n",
       "x_44  0.800001  \n",
       "x_16  0.800001  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_16',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d5a058-7d09-4574-b7e7-543328c60d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.891349</td>\n",
       "      <td>0.819792</td>\n",
       "      <td>0.933472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911153</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.978627</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216933</td>\n",
       "      <td>0.780312</td>\n",
       "      <td>0.166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962136</td>\n",
       "      <td>0.105441</td>\n",
       "      <td>0.766894</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.851594</td>\n",
       "      <td>0.831360</td>\n",
       "      <td>0.836972</td>\n",
       "      <td>0.233039</td>\n",
       "      <td>0.688241</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.829078</td>\n",
       "      <td>0.789980</td>\n",
       "      <td>0.837821</td>\n",
       "      <td>0.246023</td>\n",
       "      <td>0.675725</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.747413</td>\n",
       "      <td>0.642100</td>\n",
       "      <td>0.840983</td>\n",
       "      <td>0.433467</td>\n",
       "      <td>0.665991</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.809173</td>\n",
       "      <td>0.752627</td>\n",
       "      <td>0.839740</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.728976</td>\n",
       "      <td>0.640734</td>\n",
       "      <td>0.805436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543786</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_1   0.891349       0.819792  0.933472         1.000000         0.911153   \n",
       "x_13  0.978627       0.925689  1.000000         0.216933         0.780312   \n",
       "x_4   1.000000       1.000000  0.962136         0.105441         0.766894   \n",
       "x_44  0.851594       0.831360  0.836972         0.233039         0.688241   \n",
       "x_50  0.829078       0.789980  0.837821         0.246023         0.675725   \n",
       "x_16  0.747413       0.642100  0.840983         0.433467         0.665991   \n",
       "x_19  0.809173       0.752627  0.839740         0.188805         0.647586   \n",
       "x_7   0.728976       0.640734  0.805436         0.000000         0.543786   \n",
       "x_18  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_1   0.833333  \n",
       "x_13  0.166666  \n",
       "x_4   0.500000  \n",
       "x_44  0.500000  \n",
       "x_50  0.666667  \n",
       "x_16  0.833333  \n",
       "x_19  0.166666  \n",
       "x_7   1.000000  \n",
       "x_18  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_18',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7839e6-9779-4af4-b37b-d47ffd8241e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989295</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.898710</td>\n",
       "      <td>0.800574</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.844797</td>\n",
       "      <td>0.876077</td>\n",
       "      <td>0.600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.892453</td>\n",
       "      <td>0.752373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582238</td>\n",
       "      <td>0.806766</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.992083</td>\n",
       "      <td>0.986828</td>\n",
       "      <td>0.954328</td>\n",
       "      <td>0.201268</td>\n",
       "      <td>0.783627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.787409</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.889742</td>\n",
       "      <td>0.640065</td>\n",
       "      <td>0.744085</td>\n",
       "      <td>0.600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.753080</td>\n",
       "      <td>0.696097</td>\n",
       "      <td>0.781515</td>\n",
       "      <td>0.741056</td>\n",
       "      <td>0.742937</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.891952</td>\n",
       "      <td>0.820828</td>\n",
       "      <td>0.924130</td>\n",
       "      <td>0.242436</td>\n",
       "      <td>0.719836</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.817288</td>\n",
       "      <td>0.714335</td>\n",
       "      <td>0.888939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605141</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_18  1.000000       1.000000  0.957178         1.000000         0.989295   \n",
       "x_16  0.898710       0.800574  0.960227         0.844797         0.876077   \n",
       "x_50  0.892453       0.752373  1.000000         0.582238         0.806766   \n",
       "x_4   0.992083       0.986828  0.954328         0.201268         0.783627   \n",
       "x_1   0.787409       0.659123  0.889742         0.640065         0.744085   \n",
       "x_19  0.753080       0.696097  0.781515         0.741056         0.742937   \n",
       "x_7   0.891952       0.820828  0.924130         0.242436         0.719836   \n",
       "x_44  0.817288       0.714335  0.888939         0.000000         0.605141   \n",
       "x_13  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_18  0.200000  \n",
       "x_16  0.600001  \n",
       "x_50  1.000000  \n",
       "x_4   0.000000  \n",
       "x_1   0.600001  \n",
       "x_19  0.800000  \n",
       "x_7   0.200000  \n",
       "x_44  0.200000  \n",
       "x_13  0.200000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_13',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b6e21a-a6f8-4f41-a82a-78fd4545ebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.664498</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.857606</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.801161</td>\n",
       "      <td>0.710129</td>\n",
       "      <td>0.896137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851857</td>\n",
       "      <td>0.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>0.966824</td>\n",
       "      <td>0.360217</td>\n",
       "      <td>0.792855</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>0.756916</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.964356</td>\n",
       "      <td>0.978478</td>\n",
       "      <td>0.943171</td>\n",
       "      <td>0.051425</td>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.823855</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.968250</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>0.681565</td>\n",
       "      <td>0.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.818375</td>\n",
       "      <td>0.682921</td>\n",
       "      <td>0.963237</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.661383</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.637451</td>\n",
       "      <td>0.861696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_13  0.825503       0.664498  0.999254         0.941166         0.857606   \n",
       "x_44  0.801161       0.710129  0.896137         1.000000         0.851857   \n",
       "x_19  0.938130       0.906247  0.966824         0.360217         0.792855   \n",
       "x_16  1.000000       1.000000  1.000000         0.027664         0.756916   \n",
       "x_50  0.964356       0.978478  0.943171         0.051425         0.734357   \n",
       "x_1   0.823855       0.688635  0.968250         0.245522         0.681565   \n",
       "x_18  0.818375       0.682921  0.963237         0.180999         0.661383   \n",
       "x_4   0.744488       0.637451  0.861696         0.000000         0.560909   \n",
       "x_7   0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_13  0.333334  \n",
       "x_44  0.666668  \n",
       "x_19  0.333334  \n",
       "x_16  1.000000  \n",
       "x_50  0.000000  \n",
       "x_1   0.666668  \n",
       "x_18  0.000000  \n",
       "x_4   0.333334  \n",
       "x_7   0.333334  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_7',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3cbeed5-e520-4a71-90e8-9f4358cdf403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.961420</td>\n",
       "      <td>0.917622</td>\n",
       "      <td>0.887055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941524</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.967311</td>\n",
       "      <td>0.820885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>0.876974</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.990340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.833405</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.942138</td>\n",
       "      <td>0.915351</td>\n",
       "      <td>0.850888</td>\n",
       "      <td>0.619978</td>\n",
       "      <td>0.832089</td>\n",
       "      <td>0.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.783484</td>\n",
       "      <td>0.643535</td>\n",
       "      <td>0.830614</td>\n",
       "      <td>0.984654</td>\n",
       "      <td>0.810572</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.840715</td>\n",
       "      <td>0.643616</td>\n",
       "      <td>0.938086</td>\n",
       "      <td>0.480580</td>\n",
       "      <td>0.725749</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977652</td>\n",
       "      <td>0.902757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720102</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.735578</td>\n",
       "      <td>0.667476</td>\n",
       "      <td>0.716956</td>\n",
       "      <td>0.594098</td>\n",
       "      <td>0.678527</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_44  0.961420       0.917622  0.887055         1.000000         0.941524   \n",
       "x_1   0.967311       0.820885  1.000000         0.719700         0.876974   \n",
       "x_16  0.990340       1.000000  0.859592         0.483685         0.833405   \n",
       "x_7   0.942138       0.915351  0.850888         0.619978         0.832089   \n",
       "x_4   0.783484       0.643535  0.830614         0.984654         0.810572   \n",
       "x_13  0.840715       0.643616  0.938086         0.480580         0.725749   \n",
       "x_19  1.000000       0.977652  0.902757         0.000000         0.720102   \n",
       "x_18  0.735578       0.667476  0.716956         0.594098         0.678527   \n",
       "x_50  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_44  0.333334  \n",
       "x_1   1.000000  \n",
       "x_16  0.333334  \n",
       "x_7   0.666668  \n",
       "x_4   0.000000  \n",
       "x_13  0.000000  \n",
       "x_19  0.000000  \n",
       "x_18  0.333334  \n",
       "x_50  1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_50',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555c1d74-8249-4237-8c4d-71e2acb517b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.961893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958819</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996074</td>\n",
       "      <td>0.960963</td>\n",
       "      <td>0.438082</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.883861</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>0.932410</td>\n",
       "      <td>0.676671</td>\n",
       "      <td>0.822748</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.823898</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>0.779730</td>\n",
       "      <td>0.685475</td>\n",
       "      <td>0.778505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.876150</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>0.886001</td>\n",
       "      <td>0.223015</td>\n",
       "      <td>0.702662</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.926100</td>\n",
       "      <td>0.816904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685751</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.803171</td>\n",
       "      <td>0.655575</td>\n",
       "      <td>0.925757</td>\n",
       "      <td>0.282268</td>\n",
       "      <td>0.666693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.815935</td>\n",
       "      <td>0.760562</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.032997</td>\n",
       "      <td>0.611128</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_7   0.961893       1.000000  0.873382         1.000000         0.958819   \n",
       "x_16  1.000000       0.996074  0.960963         0.438082         0.848780   \n",
       "x_44  0.883861       0.798047  0.932410         0.676671         0.822748   \n",
       "x_13  0.823898       0.824918  0.779730         0.685475         0.778505   \n",
       "x_18  0.876150       0.825482  0.886001         0.223015         0.702662   \n",
       "x_50  0.926100       0.816904  1.000000         0.000000         0.685751   \n",
       "x_1   0.803171       0.655575  0.925757         0.282268         0.666693   \n",
       "x_4   0.815935       0.760562  0.835017         0.032997         0.611128   \n",
       "x_19  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_7        0.5  \n",
       "x_16       1.0  \n",
       "x_44       1.0  \n",
       "x_13       0.0  \n",
       "x_18       0.5  \n",
       "x_50       1.0  \n",
       "x_1        0.0  \n",
       "x_4        0.5  \n",
       "x_19       1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_19',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5057eeb3-1ac1-4644-a2bd-9d6550a42207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 923.4998\n",
      "Recon Loss =890.8873, KL Loss = 0.0019, Sparsity Loss = 31.4590, Lagrangian Loss = 1.1515\n",
      "Epoch 51: Loss = 41.7739\n",
      "Recon Loss =5.6480, KL Loss = 1.4505, Sparsity Loss = 32.5400, Lagrangian Loss = 2.1353\n",
      "Early stopping triggered. Last Epoch: 96\n",
      "Recon Loss =2.7229, KL Loss = 1.7721, Sparsity Loss = 32.4096, Lagrangian Loss = 4.3704\n",
      "Epoch 1: Loss = 918.2161\n",
      "Recon Loss =865.8217, KL Loss = 0.0013, Sparsity Loss = 46.7983, Lagrangian Loss = 5.5948\n",
      "Early stopping triggered. Last Epoch: 32\n",
      "Recon Loss =875.9733, KL Loss = 0.0013, Sparsity Loss = 47.5186, Lagrangian Loss = 8.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:02:24,921 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 0.00,  Blended Accuracy = 0.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 878.7849\n",
      "Recon Loss =843.0634, KL Loss = 0.0028, Sparsity Loss = 34.4280, Lagrangian Loss = 1.2906\n",
      "Epoch 51: Loss = 40.5325\n",
      "Recon Loss =4.9073, KL Loss = 1.3818, Sparsity Loss = 32.0804, Lagrangian Loss = 2.1631\n",
      "Early stopping triggered. Last Epoch: 91\n",
      "Recon Loss =2.5790, KL Loss = 1.6878, Sparsity Loss = 32.6422, Lagrangian Loss = 4.2340\n",
      "Epoch 1: Loss = 993.1023\n",
      "Recon Loss =941.3853, KL Loss = 0.0017, Sparsity Loss = 46.7186, Lagrangian Loss = 4.9968\n",
      "Early stopping triggered. Last Epoch: 37\n",
      "Recon Loss =945.0339, KL Loss = 0.0017, Sparsity Loss = 48.1170, Lagrangian Loss = 9.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:02:35,853 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 50.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 926.6265\n",
      "Recon Loss =892.6248, KL Loss = 0.0016, Sparsity Loss = 32.7710, Lagrangian Loss = 1.2292\n",
      "Epoch 51: Loss = 40.9806\n",
      "Recon Loss =5.2461, KL Loss = 1.4631, Sparsity Loss = 32.0113, Lagrangian Loss = 2.2602\n",
      "Epoch 101: Loss = 40.2060\n",
      "Recon Loss =2.6919, KL Loss = 1.7395, Sparsity Loss = 31.1549, Lagrangian Loss = 4.6197\n",
      "Early stopping triggered. Last Epoch: 112\n",
      "Recon Loss =2.5528, KL Loss = 1.7414, Sparsity Loss = 30.1439, Lagrangian Loss = 5.0405\n",
      "Epoch 1: Loss = 827.1363\n",
      "Recon Loss =772.1245, KL Loss = 0.0010, Sparsity Loss = 47.8742, Lagrangian Loss = 7.1366\n",
      "Epoch 51: Loss = 842.0300\n",
      "Recon Loss =783.5211, KL Loss = 0.0010, Sparsity Loss = 47.8572, Lagrangian Loss = 10.6506\n",
      "Early stopping triggered. Last Epoch: 59\n",
      "Recon Loss =783.7454, KL Loss = 0.0010, Sparsity Loss = 49.0185, Lagrangian Loss = 15.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:02:50,045 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 33.33,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 905.3773\n",
      "Recon Loss =872.4228, KL Loss = 0.0020, Sparsity Loss = 31.8810, Lagrangian Loss = 1.0714\n",
      "Epoch 51: Loss = 40.8056\n",
      "Recon Loss =4.5568, KL Loss = 1.4449, Sparsity Loss = 32.5980, Lagrangian Loss = 2.2059\n",
      "Epoch 101: Loss = 44.1699\n",
      "Recon Loss =2.9032, KL Loss = 1.7724, Sparsity Loss = 34.0570, Lagrangian Loss = 5.4373\n",
      "Early stopping triggered. Last Epoch: 102\n",
      "Recon Loss =2.7664, KL Loss = 1.7827, Sparsity Loss = 32.6086, Lagrangian Loss = 5.0152\n",
      "Epoch 1: Loss = 956.6114\n",
      "Recon Loss =902.2981, KL Loss = 0.0027, Sparsity Loss = 48.0900, Lagrangian Loss = 6.2206\n",
      "Epoch 51: Loss = 947.3044\n",
      "Recon Loss =892.3737, KL Loss = 0.0027, Sparsity Loss = 46.9634, Lagrangian Loss = 7.9646\n",
      "Early stopping triggered. Last Epoch: 78\n",
      "Recon Loss =893.7354, KL Loss = 0.0027, Sparsity Loss = 48.0785, Lagrangian Loss = 15.5182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:03:04,773 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 50.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 890.1070\n",
      "Recon Loss =856.6459, KL Loss = 0.0016, Sparsity Loss = 32.2697, Lagrangian Loss = 1.1897\n",
      "Epoch 51: Loss = 41.1675\n",
      "Recon Loss =5.3385, KL Loss = 1.3212, Sparsity Loss = 32.2307, Lagrangian Loss = 2.2772\n",
      "Early stopping triggered. Last Epoch: 95\n",
      "Recon Loss =2.7513, KL Loss = 1.7420, Sparsity Loss = 33.6718, Lagrangian Loss = 5.5852\n",
      "Epoch 1: Loss = 831.4580\n",
      "Recon Loss =780.9360, KL Loss = 0.0018, Sparsity Loss = 45.8495, Lagrangian Loss = 4.6707\n",
      "Early stopping triggered. Last Epoch: 36\n",
      "Recon Loss =784.5426, KL Loss = 0.0018, Sparsity Loss = 47.7606, Lagrangian Loss = 8.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:03:15,976 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 60.00,  Blended Accuracy = 40.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 841.9304\n",
      "Recon Loss =808.8258, KL Loss = 0.0013, Sparsity Loss = 31.9883, Lagrangian Loss = 1.1150\n",
      "Epoch 51: Loss = 50.2270\n",
      "Recon Loss =5.6433, KL Loss = 1.5076, Sparsity Loss = 39.3658, Lagrangian Loss = 3.7103\n",
      "Early stopping triggered. Last Epoch: 93\n",
      "Recon Loss =2.8754, KL Loss = 1.7719, Sparsity Loss = 38.7215, Lagrangian Loss = 6.4156\n",
      "Epoch 1: Loss = 969.3032\n",
      "Recon Loss =918.0578, KL Loss = 0.0021, Sparsity Loss = 45.9632, Lagrangian Loss = 5.2801\n",
      "Early stopping triggered. Last Epoch: 46\n",
      "Recon Loss =908.5320, KL Loss = 0.0021, Sparsity Loss = 46.8982, Lagrangian Loss = 8.3885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:03:27,693 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 875.2406\n",
      "Recon Loss =840.0955, KL Loss = 0.0018, Sparsity Loss = 33.9680, Lagrangian Loss = 1.1754\n",
      "Epoch 51: Loss = 39.3079\n",
      "Recon Loss =5.0758, KL Loss = 1.3953, Sparsity Loss = 30.6926, Lagrangian Loss = 2.1443\n",
      "Epoch 101: Loss = 39.4464\n",
      "Recon Loss =2.6480, KL Loss = 1.7040, Sparsity Loss = 30.7252, Lagrangian Loss = 4.3693\n",
      "Early stopping triggered. Last Epoch: 103\n",
      "Recon Loss =2.4832, KL Loss = 1.7081, Sparsity Loss = 30.7341, Lagrangian Loss = 4.7751\n",
      "Epoch 1: Loss = 844.8661\n",
      "Recon Loss =791.2635, KL Loss = 0.0018, Sparsity Loss = 47.2989, Lagrangian Loss = 6.3019\n",
      "Epoch 51: Loss = 857.1302\n",
      "Recon Loss =800.4185, KL Loss = 0.0018, Sparsity Loss = 47.2428, Lagrangian Loss = 9.4671\n",
      "Early stopping triggered. Last Epoch: 72\n",
      "Recon Loss =795.2875, KL Loss = 0.0018, Sparsity Loss = 46.3382, Lagrangian Loss = 13.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:03:41,979 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 42.86,  Blended Accuracy = 28.57,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 840.2360\n",
      "Recon Loss =802.5753, KL Loss = 0.0016, Sparsity Loss = 36.0936, Lagrangian Loss = 1.5655\n",
      "Epoch 51: Loss = 49.6155\n",
      "Recon Loss =5.3922, KL Loss = 1.3427, Sparsity Loss = 39.6217, Lagrangian Loss = 3.2589\n",
      "Epoch 101: Loss = 50.7452\n",
      "Recon Loss =2.7812, KL Loss = 1.7439, Sparsity Loss = 39.0235, Lagrangian Loss = 7.1966\n",
      "Early stopping triggered. Last Epoch: 107\n",
      "Recon Loss =2.6965, KL Loss = 1.7700, Sparsity Loss = 39.3897, Lagrangian Loss = 8.2313\n",
      "Epoch 1: Loss = 923.5396\n",
      "Recon Loss =874.3195, KL Loss = 0.0017, Sparsity Loss = 45.0400, Lagrangian Loss = 4.1783\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =857.4957, KL Loss = 0.0017, Sparsity Loss = 46.9772, Lagrangian Loss = 7.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:03:54,527 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 37.50,  Blended Accuracy = 25.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 934.5291\n",
      "Recon Loss =901.6274, KL Loss = 0.0023, Sparsity Loss = 31.7918, Lagrangian Loss = 1.1076\n",
      "Epoch 51: Loss = 41.4943\n",
      "Recon Loss =5.6426, KL Loss = 1.4094, Sparsity Loss = 32.3187, Lagrangian Loss = 2.1236\n",
      "Epoch 101: Loss = 40.2521\n",
      "Recon Loss =2.7604, KL Loss = 1.7429, Sparsity Loss = 31.4017, Lagrangian Loss = 4.3471\n",
      "Early stopping triggered. Last Epoch: 103\n",
      "Recon Loss =2.6237, KL Loss = 1.7426, Sparsity Loss = 32.8277, Lagrangian Loss = 5.2648\n",
      "Epoch 1: Loss = 915.8807\n",
      "Recon Loss =865.0868, KL Loss = 0.0023, Sparsity Loss = 46.3941, Lagrangian Loss = 4.3975\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =846.5155, KL Loss = 0.0023, Sparsity Loss = 47.1467, Lagrangian Loss = 7.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:04:06,732 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 33.33,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 863.1340\n",
      "Recon Loss =830.8285, KL Loss = 0.0021, Sparsity Loss = 31.2139, Lagrangian Loss = 1.0895\n",
      "Epoch 51: Loss = 47.2375\n",
      "Recon Loss =5.8485, KL Loss = 1.3688, Sparsity Loss = 36.7169, Lagrangian Loss = 3.3032\n",
      "Epoch 101: Loss = 46.2776\n",
      "Recon Loss =2.6912, KL Loss = 1.5992, Sparsity Loss = 35.9207, Lagrangian Loss = 6.0665\n",
      "Early stopping triggered. Last Epoch: 113\n",
      "Recon Loss =2.5388, KL Loss = 1.6230, Sparsity Loss = 35.8334, Lagrangian Loss = 7.3150\n",
      "Epoch 1: Loss = 900.3804\n",
      "Recon Loss =849.4302, KL Loss = 0.0018, Sparsity Loss = 46.3223, Lagrangian Loss = 4.6260\n",
      "Early stopping triggered. Last Epoch: 41\n",
      "Recon Loss =851.1674, KL Loss = 0.0018, Sparsity Loss = 48.1176, Lagrangian Loss = 8.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:04:19,750 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 30.00,  Blended Accuracy = 30.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 855.3524\n",
      "Recon Loss =818.4028, KL Loss = 0.0026, Sparsity Loss = 35.6631, Lagrangian Loss = 1.2838\n",
      "Epoch 51: Loss = 45.5386\n",
      "Recon Loss =5.1884, KL Loss = 1.5256, Sparsity Loss = 36.1081, Lagrangian Loss = 2.7165\n",
      "Epoch 101: Loss = 45.7683\n",
      "Recon Loss =2.6109, KL Loss = 1.6846, Sparsity Loss = 35.6364, Lagrangian Loss = 5.8365\n",
      "Early stopping triggered. Last Epoch: 108\n",
      "Recon Loss =2.6384, KL Loss = 1.6793, Sparsity Loss = 36.2646, Lagrangian Loss = 7.5474\n",
      "Epoch 1: Loss = 883.4346\n",
      "Recon Loss =829.9871, KL Loss = 0.0018, Sparsity Loss = 47.1090, Lagrangian Loss = 6.3368\n",
      "Early stopping triggered. Last Epoch: 37\n",
      "Recon Loss =838.4166, KL Loss = 0.0018, Sparsity Loss = 46.1628, Lagrangian Loss = 7.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:04:32,090 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 27.27,  Blended Accuracy = 36.36,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 901.9230\n",
      "Recon Loss =863.6213, KL Loss = 0.0016, Sparsity Loss = 36.8655, Lagrangian Loss = 1.4345\n",
      "Epoch 51: Loss = 51.6679\n",
      "Recon Loss =5.3093, KL Loss = 1.4441, Sparsity Loss = 40.7140, Lagrangian Loss = 4.2004\n",
      "Early stopping triggered. Last Epoch: 85\n",
      "Recon Loss =2.8550, KL Loss = 1.7437, Sparsity Loss = 38.4304, Lagrangian Loss = 5.5969\n",
      "Epoch 1: Loss = 922.4103\n",
      "Recon Loss =866.7642, KL Loss = 0.0015, Sparsity Loss = 47.9071, Lagrangian Loss = 7.7376\n",
      "Early stopping triggered. Last Epoch: 30\n",
      "Recon Loss =878.0331, KL Loss = 0.0015, Sparsity Loss = 49.1962, Lagrangian Loss = 10.5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:04:41,993 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 25.00,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 858.7453\n",
      "Recon Loss =824.4944, KL Loss = 0.0017, Sparsity Loss = 33.1061, Lagrangian Loss = 1.1431\n",
      "Epoch 51: Loss = 40.0804\n",
      "Recon Loss =5.5199, KL Loss = 1.3328, Sparsity Loss = 31.0893, Lagrangian Loss = 2.1384\n",
      "Epoch 101: Loss = 41.3864\n",
      "Recon Loss =2.7176, KL Loss = 1.6666, Sparsity Loss = 32.2124, Lagrangian Loss = 4.7897\n",
      "Early stopping triggered. Last Epoch: 108\n",
      "Recon Loss =2.5929, KL Loss = 1.6905, Sparsity Loss = 31.6962, Lagrangian Loss = 4.8084\n",
      "Epoch 1: Loss = 967.6604\n",
      "Recon Loss =917.4642, KL Loss = 0.0024, Sparsity Loss = 45.3500, Lagrangian Loss = 4.8437\n",
      "Early stopping triggered. Last Epoch: 37\n",
      "Recon Loss =922.6434, KL Loss = 0.0024, Sparsity Loss = 46.6008, Lagrangian Loss = 8.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:04:54,311 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 30.77,  Blended Accuracy = 38.46,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 879.3340\n",
      "Recon Loss =845.8203, KL Loss = 0.0015, Sparsity Loss = 32.3677, Lagrangian Loss = 1.1446\n",
      "Epoch 51: Loss = 41.3710\n",
      "Recon Loss =5.4378, KL Loss = 1.4960, Sparsity Loss = 32.1295, Lagrangian Loss = 2.3077\n",
      "Epoch 101: Loss = 40.9696\n",
      "Recon Loss =2.7183, KL Loss = 1.7817, Sparsity Loss = 31.9126, Lagrangian Loss = 4.5570\n",
      "Early stopping triggered. Last Epoch: 108\n",
      "Recon Loss =2.4799, KL Loss = 1.7954, Sparsity Loss = 30.3881, Lagrangian Loss = 4.7562\n",
      "Epoch 1: Loss = 950.8910\n",
      "Recon Loss =896.5814, KL Loss = 0.0022, Sparsity Loss = 47.9801, Lagrangian Loss = 6.3273\n",
      "Early stopping triggered. Last Epoch: 49\n",
      "Recon Loss =898.5336, KL Loss = 0.0022, Sparsity Loss = 48.7161, Lagrangian Loss = 11.4209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:05:07,397 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 28.57,  Blended Accuracy = 35.71,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 909.8593\n",
      "Recon Loss =875.2949, KL Loss = 0.0016, Sparsity Loss = 33.3990, Lagrangian Loss = 1.1636\n",
      "Epoch 51: Loss = 43.0127\n",
      "Recon Loss =5.2529, KL Loss = 1.5247, Sparsity Loss = 33.7762, Lagrangian Loss = 2.4589\n",
      "Early stopping triggered. Last Epoch: 93\n",
      "Recon Loss =2.6687, KL Loss = 1.7257, Sparsity Loss = 33.1848, Lagrangian Loss = 4.2070\n",
      "Epoch 1: Loss = 899.1845\n",
      "Recon Loss =848.9702, KL Loss = 0.0032, Sparsity Loss = 45.5992, Lagrangian Loss = 4.6118\n",
      "Epoch 51: Loss = 900.0093\n",
      "Recon Loss =844.0300, KL Loss = 0.0032, Sparsity Loss = 47.2152, Lagrangian Loss = 8.7609\n",
      "Early stopping triggered. Last Epoch: 99\n",
      "Recon Loss =833.2592, KL Loss = 0.0032, Sparsity Loss = 47.8891, Lagrangian Loss = 19.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:05:22,602 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 26.67,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 909.3013\n",
      "Recon Loss =875.3792, KL Loss = 0.0020, Sparsity Loss = 32.7547, Lagrangian Loss = 1.1654\n",
      "Epoch 51: Loss = 40.9382\n",
      "Recon Loss =6.6259, KL Loss = 1.5234, Sparsity Loss = 30.6783, Lagrangian Loss = 2.1106\n",
      "Epoch 101: Loss = 38.9720\n",
      "Recon Loss =2.7011, KL Loss = 1.7201, Sparsity Loss = 30.4240, Lagrangian Loss = 4.1268\n",
      "Early stopping triggered. Last Epoch: 115\n",
      "Recon Loss =2.5279, KL Loss = 1.7243, Sparsity Loss = 30.9768, Lagrangian Loss = 5.6410\n",
      "Epoch 1: Loss = 933.3649\n",
      "Recon Loss =880.5051, KL Loss = 0.0029, Sparsity Loss = 47.2057, Lagrangian Loss = 5.6513\n",
      "Early stopping triggered. Last Epoch: 32\n",
      "Recon Loss =876.2397, KL Loss = 0.0029, Sparsity Loss = 46.5272, Lagrangian Loss = 7.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:05:35,175 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 25.00,  Blended Accuracy = 31.25,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 873.6434\n",
      "Recon Loss =834.3834, KL Loss = 0.0017, Sparsity Loss = 37.5774, Lagrangian Loss = 1.6809\n",
      "Epoch 51: Loss = 40.2550\n",
      "Recon Loss =5.3760, KL Loss = 1.5750, Sparsity Loss = 31.1303, Lagrangian Loss = 2.1737\n",
      "Epoch 101: Loss = 40.9609\n",
      "Recon Loss =2.5708, KL Loss = 1.7713, Sparsity Loss = 31.9985, Lagrangian Loss = 4.6204\n",
      "Early stopping triggered. Last Epoch: 112\n",
      "Recon Loss =2.5335, KL Loss = 1.7506, Sparsity Loss = 31.5012, Lagrangian Loss = 5.3507\n",
      "Epoch 1: Loss = 876.7759\n",
      "Recon Loss =823.0110, KL Loss = 0.0016, Sparsity Loss = 47.6653, Lagrangian Loss = 6.0980\n",
      "Epoch 51: Loss = 890.7977\n",
      "Recon Loss =831.5353, KL Loss = 0.0016, Sparsity Loss = 48.2298, Lagrangian Loss = 11.0309\n",
      "Early stopping triggered. Last Epoch: 57\n",
      "Recon Loss =829.0507, KL Loss = 0.0016, Sparsity Loss = 46.2990, Lagrangian Loss = 8.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:05:49,227 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 23.53,  Blended Accuracy = 29.41,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 892.4432\n",
      "Recon Loss =859.5954, KL Loss = 0.0019, Sparsity Loss = 31.7525, Lagrangian Loss = 1.0934\n",
      "Epoch 51: Loss = 46.0836\n",
      "Recon Loss =6.1766, KL Loss = 1.4314, Sparsity Loss = 35.8541, Lagrangian Loss = 2.6214\n",
      "Early stopping triggered. Last Epoch: 91\n",
      "Recon Loss =2.7210, KL Loss = 1.7484, Sparsity Loss = 35.5812, Lagrangian Loss = 5.1969\n",
      "Epoch 1: Loss = 871.7120\n",
      "Recon Loss =820.8953, KL Loss = 0.0020, Sparsity Loss = 46.2915, Lagrangian Loss = 4.5232\n",
      "Early stopping triggered. Last Epoch: 38\n",
      "Recon Loss =818.6424, KL Loss = 0.0020, Sparsity Loss = 47.2512, Lagrangian Loss = 7.3186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:00,177 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 22.22,  Blended Accuracy = 27.78,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 878.7724\n",
      "Recon Loss =846.8163, KL Loss = 0.0024, Sparsity Loss = 30.8997, Lagrangian Loss = 1.0540\n",
      "Epoch 51: Loss = 41.1206\n",
      "Recon Loss =5.2911, KL Loss = 1.5194, Sparsity Loss = 32.0742, Lagrangian Loss = 2.2359\n",
      "Epoch 101: Loss = 40.3483\n",
      "Recon Loss =2.5595, KL Loss = 1.8078, Sparsity Loss = 31.2141, Lagrangian Loss = 4.7669\n",
      "Early stopping triggered. Last Epoch: 105\n",
      "Recon Loss =2.6409, KL Loss = 1.8169, Sparsity Loss = 32.0379, Lagrangian Loss = 5.1528\n",
      "Epoch 1: Loss = 931.2455\n",
      "Recon Loss =876.9354, KL Loss = 0.0030, Sparsity Loss = 47.6057, Lagrangian Loss = 6.7014\n",
      "Early stopping triggered. Last Epoch: 46\n",
      "Recon Loss =881.3325, KL Loss = 0.0030, Sparsity Loss = 46.9416, Lagrangian Loss = 8.2929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:12,828 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 21.05,  Blended Accuracy = 26.32,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 909.8478\n",
      "Recon Loss =875.6581, KL Loss = 0.0013, Sparsity Loss = 33.0251, Lagrangian Loss = 1.1634\n",
      "Epoch 51: Loss = 41.1569\n",
      "Recon Loss =5.1895, KL Loss = 1.4816, Sparsity Loss = 32.2106, Lagrangian Loss = 2.2751\n",
      "Early stopping triggered. Last Epoch: 97\n",
      "Recon Loss =2.7405, KL Loss = 1.7989, Sparsity Loss = 33.2082, Lagrangian Loss = 4.8224\n",
      "Epoch 1: Loss = 955.3694\n",
      "Recon Loss =899.0122, KL Loss = 0.0017, Sparsity Loss = 48.5280, Lagrangian Loss = 7.8274\n",
      "Epoch 51: Loss = 939.1556\n",
      "Recon Loss =878.5205, KL Loss = 0.0017, Sparsity Loss = 48.6242, Lagrangian Loss = 12.0092\n",
      "Early stopping triggered. Last Epoch: 63\n",
      "Recon Loss =899.0678, KL Loss = 0.0017, Sparsity Loss = 50.5123, Lagrangian Loss = 20.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:26,032 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 25.00,  Blended Accuracy = 30.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 875.4210\n",
      "Recon Loss =841.7144, KL Loss = 0.0017, Sparsity Loss = 32.5383, Lagrangian Loss = 1.1666\n",
      "Epoch 51: Loss = 43.3647\n",
      "Recon Loss =8.3661, KL Loss = 1.2343, Sparsity Loss = 31.5382, Lagrangian Loss = 2.2262\n",
      "Epoch 101: Loss = 39.1204\n",
      "Recon Loss =2.7111, KL Loss = 1.6585, Sparsity Loss = 30.3907, Lagrangian Loss = 4.3601\n",
      "Early stopping triggered. Last Epoch: 105\n",
      "Recon Loss =2.6056, KL Loss = 1.6833, Sparsity Loss = 31.4299, Lagrangian Loss = 5.2155\n",
      "Epoch 1: Loss = 894.6659\n",
      "Recon Loss =846.4778, KL Loss = 0.0024, Sparsity Loss = 44.8926, Lagrangian Loss = 3.2931\n",
      "Early stopping triggered. Last Epoch: 33\n",
      "Recon Loss =841.3287, KL Loss = 0.0024, Sparsity Loss = 46.8879, Lagrangian Loss = 6.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:37,853 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 23.81,  Blended Accuracy = 33.33,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 898.9993\n",
      "Recon Loss =863.6127, KL Loss = 0.0012, Sparsity Loss = 34.1407, Lagrangian Loss = 1.2449\n",
      "Epoch 51: Loss = 41.0342\n",
      "Recon Loss =5.3354, KL Loss = 1.4789, Sparsity Loss = 32.0537, Lagrangian Loss = 2.1663\n",
      "Epoch 101: Loss = 40.7200\n",
      "Recon Loss =2.7536, KL Loss = 1.8550, Sparsity Loss = 31.5759, Lagrangian Loss = 4.5354\n",
      "Early stopping triggered. Last Epoch: 132\n",
      "Recon Loss =2.5451, KL Loss = 1.8351, Sparsity Loss = 32.3550, Lagrangian Loss = 7.0328\n",
      "Epoch 1: Loss = 918.7467\n",
      "Recon Loss =864.5929, KL Loss = 0.0025, Sparsity Loss = 47.9593, Lagrangian Loss = 6.1921\n",
      "Epoch 51: Loss = 911.8880\n",
      "Recon Loss =860.0375, KL Loss = 0.0025, Sparsity Loss = 45.3940, Lagrangian Loss = 6.4540\n",
      "Early stopping triggered. Last Epoch: 71\n",
      "Recon Loss =870.1113, KL Loss = 0.0025, Sparsity Loss = 45.2969, Lagrangian Loss = 8.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:54,537 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 22.73,  Blended Accuracy = 36.36,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 907.8540\n",
      "Recon Loss =874.1597, KL Loss = 0.0015, Sparsity Loss = 32.4868, Lagrangian Loss = 1.2060\n",
      "Epoch 51: Loss = 41.5718\n",
      "Recon Loss =4.5531, KL Loss = 1.4343, Sparsity Loss = 33.1504, Lagrangian Loss = 2.4340\n",
      "Early stopping triggered. Last Epoch: 94\n",
      "Recon Loss =2.6051, KL Loss = 1.7450, Sparsity Loss = 32.4789, Lagrangian Loss = 4.4301\n",
      "Epoch 1: Loss = 889.0469\n",
      "Recon Loss =835.1943, KL Loss = 0.0024, Sparsity Loss = 47.6881, Lagrangian Loss = 6.1620\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =844.3776, KL Loss = 0.0024, Sparsity Loss = 48.7424, Lagrangian Loss = 10.7391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:07:06,420 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 21.74,  Blended Accuracy = 34.78,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 889.7897\n",
      "Recon Loss =857.1315, KL Loss = 0.0023, Sparsity Loss = 31.5380, Lagrangian Loss = 1.1179\n",
      "Epoch 51: Loss = 42.8229\n",
      "Recon Loss =6.9363, KL Loss = 1.2825, Sparsity Loss = 32.3111, Lagrangian Loss = 2.2929\n",
      "Epoch 101: Loss = 39.6809\n",
      "Recon Loss =2.6374, KL Loss = 1.7097, Sparsity Loss = 30.7051, Lagrangian Loss = 4.6287\n",
      "Early stopping triggered. Last Epoch: 103\n",
      "Recon Loss =2.6617, KL Loss = 1.7079, Sparsity Loss = 31.9455, Lagrangian Loss = 4.9028\n",
      "Epoch 1: Loss = 919.2493\n",
      "Recon Loss =867.1156, KL Loss = 0.0022, Sparsity Loss = 46.7549, Lagrangian Loss = 5.3766\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =855.1924, KL Loss = 0.0022, Sparsity Loss = 46.7708, Lagrangian Loss = 7.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:07:19,430 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 20.83,  Blended Accuracy = 37.50,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 844.5327\n",
      "Recon Loss =813.1517, KL Loss = 0.0025, Sparsity Loss = 30.3338, Lagrangian Loss = 1.0448\n",
      "Epoch 51: Loss = 40.1945\n",
      "Recon Loss =5.4774, KL Loss = 1.4111, Sparsity Loss = 31.1752, Lagrangian Loss = 2.1307\n",
      "Epoch 101: Loss = 39.9458\n",
      "Recon Loss =2.7127, KL Loss = 1.8513, Sparsity Loss = 30.6763, Lagrangian Loss = 4.7056\n",
      "Early stopping triggered. Last Epoch: 100\n",
      "Recon Loss =2.7127, KL Loss = 1.8513, Sparsity Loss = 30.6763, Lagrangian Loss = 4.7056\n",
      "Epoch 1: Loss = 954.9221\n",
      "Recon Loss =902.9885, KL Loss = 0.0017, Sparsity Loss = 46.6917, Lagrangian Loss = 5.2403\n",
      "Early stopping triggered. Last Epoch: 32\n",
      "Recon Loss =894.7676, KL Loss = 0.0017, Sparsity Loss = 48.6270, Lagrangian Loss = 8.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:07:31,506 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 20.00,  Blended Accuracy = 36.00,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 830.2301\n",
      "Recon Loss =797.1202, KL Loss = 0.0029, Sparsity Loss = 31.9800, Lagrangian Loss = 1.1271\n",
      "Epoch 51: Loss = 42.0372\n",
      "Recon Loss =5.6403, KL Loss = 1.4386, Sparsity Loss = 32.6727, Lagrangian Loss = 2.2856\n",
      "Early stopping triggered. Last Epoch: 95\n",
      "Recon Loss =2.7069, KL Loss = 1.7008, Sparsity Loss = 33.0388, Lagrangian Loss = 4.7228\n",
      "Epoch 1: Loss = 868.8365\n",
      "Recon Loss =815.9921, KL Loss = 0.0028, Sparsity Loss = 47.4210, Lagrangian Loss = 5.4205\n",
      "Epoch 51: Loss = 872.9104\n",
      "Recon Loss =816.8434, KL Loss = 0.0028, Sparsity Loss = 47.0055, Lagrangian Loss = 9.0587\n",
      "Early stopping triggered. Last Epoch: 54\n",
      "Recon Loss =797.2256, KL Loss = 0.0028, Sparsity Loss = 47.2838, Lagrangian Loss = 9.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:07:43,880 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 23.08,  Blended Accuracy = 38.46,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 907.5587\n",
      "Recon Loss =871.9923, KL Loss = 0.0018, Sparsity Loss = 34.3453, Lagrangian Loss = 1.2193\n",
      "Epoch 51: Loss = 40.1669\n",
      "Recon Loss =6.0555, KL Loss = 1.6061, Sparsity Loss = 30.5689, Lagrangian Loss = 1.9363\n",
      "Early stopping triggered. Last Epoch: 88\n",
      "Recon Loss =2.5710, KL Loss = 1.8603, Sparsity Loss = 31.0508, Lagrangian Loss = 3.8897\n",
      "Epoch 1: Loss = 939.1154\n",
      "Recon Loss =885.8948, KL Loss = 0.0014, Sparsity Loss = 47.8150, Lagrangian Loss = 5.4041\n",
      "Epoch 51: Loss = 939.7333\n",
      "Recon Loss =886.4575, KL Loss = 0.0014, Sparsity Loss = 46.3425, Lagrangian Loss = 6.9319\n",
      "Early stopping triggered. Last Epoch: 63\n",
      "Recon Loss =884.2687, KL Loss = 0.0014, Sparsity Loss = 44.7629, Lagrangian Loss = 6.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:07:56,388 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 22.22,  Blended Accuracy = 37.04,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 886.7258\n",
      "Recon Loss =852.4958, KL Loss = 0.0013, Sparsity Loss = 33.0180, Lagrangian Loss = 1.2106\n",
      "Epoch 51: Loss = 42.4492\n",
      "Recon Loss =5.4465, KL Loss = 1.5588, Sparsity Loss = 33.0393, Lagrangian Loss = 2.4045\n",
      "Early stopping triggered. Last Epoch: 95\n",
      "Recon Loss =2.7764, KL Loss = 1.8041, Sparsity Loss = 33.3566, Lagrangian Loss = 4.6726\n",
      "Epoch 1: Loss = 905.2235\n",
      "Recon Loss =853.9166, KL Loss = 0.0021, Sparsity Loss = 46.4522, Lagrangian Loss = 4.8527\n",
      "Early stopping triggered. Last Epoch: 30\n",
      "Recon Loss =862.0961, KL Loss = 0.0021, Sparsity Loss = 46.5417, Lagrangian Loss = 6.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:08:07,187 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 21.43,  Blended Accuracy = 35.71,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 867.5835\n",
      "Recon Loss =833.6240, KL Loss = 0.0020, Sparsity Loss = 32.8253, Lagrangian Loss = 1.1321\n",
      "Epoch 51: Loss = 40.1677\n",
      "Recon Loss =4.6441, KL Loss = 1.4750, Sparsity Loss = 31.8929, Lagrangian Loss = 2.1557\n",
      "Epoch 101: Loss = 41.1448\n",
      "Recon Loss =2.6186, KL Loss = 1.8381, Sparsity Loss = 31.9282, Lagrangian Loss = 4.7598\n",
      "Early stopping triggered. Last Epoch: 109\n",
      "Recon Loss =2.5865, KL Loss = 1.8471, Sparsity Loss = 31.5935, Lagrangian Loss = 5.1745\n",
      "Epoch 1: Loss = 917.4636\n",
      "Recon Loss =863.6752, KL Loss = 0.0014, Sparsity Loss = 47.6614, Lagrangian Loss = 6.1256\n",
      "Early stopping triggered. Last Epoch: 41\n",
      "Recon Loss =855.3022, KL Loss = 0.0014, Sparsity Loss = 49.0191, Lagrangian Loss = 11.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:08:19,855 INFO -- Edge Accuracy = 0.00, Instantaneous Accuracy = 0.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 20.69,  Blended Accuracy = 34.48,  RR Accuracy = 0.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 957.5738\n",
      "Recon Loss =921.5117, KL Loss = 0.0019, Sparsity Loss = 34.8030, Lagrangian Loss = 1.2572\n",
      "Epoch 51: Loss = 46.5995\n",
      "Recon Loss =5.3524, KL Loss = 1.4126, Sparsity Loss = 36.7720, Lagrangian Loss = 3.0625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train on nominal data\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#print(\"Pretraining on nominal data...\")\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_model(dataloader_nominal, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,BATCH_SIZE\u001b[38;5;241m=\u001b[39mBATCH_SIZE,rho_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m,alpha_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract learned adjacency\u001b[39;00m\n\u001b[0;32m     29\u001b[0m prior_adj \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcausal_graph\u001b[38;5;241m.\u001b[39madj_mat\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:196\u001b[0m, in \u001b[0;36mCausalGraphVAE.train_model\u001b[1;34m(self, dataloader, optimizer, num_epochs, patience, BATCH_SIZE, rho_max, alpha_max)\u001b[0m\n\u001b[0;32m    192\u001b[0m recon_loss , kl_loss , sparsity_loss , lagrangian_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(recon_X, X_batch, mu, logvar, adj_now, \n\u001b[0;32m    193\u001b[0m                                                                             adj_lag, epoch, num_epochs,rho_max,alpha_max)\n\u001b[0;32m    194\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m kl_loss \u001b[38;5;241m+\u001b[39m sparsity_loss \u001b[38;5;241m+\u001b[39m lagrangian_loss \n\u001b[1;32m--> 196\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    197\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    198\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 3\n",
    "BATCH_SIZE = 100\n",
    "hidden_dim = 256\n",
    "latent_dim = 16\n",
    "edge_correct = 0\n",
    "instantaneous_correct = 0\n",
    "lagged_correct = 0\n",
    "counterfactual_correct = 0 \n",
    "rr_correct = 0\n",
    "total_correct = 0\n",
    "total_checked = 0\n",
    "for i in range(30):\n",
    "    total_checked+=1\n",
    "    \n",
    "    dataset_nominal = TimeSeriesDataset(normal, device=device, time_steps=TIME_STEPS)\n",
    "    dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    model = CausalGraphVAE(input_dim=normal.shape[1], hidden_dim=hidden_dim,\n",
    "                            latent_dim=latent_dim, num_nodes=normal.shape[1],device=device,\n",
    "                            time_steps=TIME_STEPS, prior_adj=None).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "    \n",
    "    # Train on nominal data\n",
    "    #print(\"Pretraining on nominal data...\")\n",
    "    model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "    \n",
    "    # Extract learned adjacency\n",
    "    prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "    dataset_bad = TimeSeriesDataset(bad, device=device, time_steps=TIME_STEPS)\n",
    "    dataloader_bad = DataLoader(dataset_bad, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    fine_tuned = CausalGraphVAE(input_dim=bad.shape[1], hidden_dim=hidden_dim,\n",
    "                            latent_dim=latent_dim, num_nodes=bad.shape[1],device=device,\n",
    "                            time_steps=TIME_STEPS, prior_adj=prior_adj).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "    \n",
    "    # Train on nominal data\n",
    "    # print(\"Pretraining on nominal data...\")\n",
    "    fine_tuned.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "    \n",
    "    X_data = torch.empty(0,device=device)\n",
    "    T_data = torch.empty(0,device=device)\n",
    "    for batch_idx, (X_batch, time_batch) in enumerate(dataloader_bad):\n",
    "        X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "        T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "    \n",
    "    causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_4',cols,non_causal_indices=[])\n",
    "    \n",
    "    edge_cause_1 = causes.sort_values(by='causes',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    instant_cause_1 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    lag_cause_1 = causes.sort_values(by='lagged',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    counterfactual_cause_1 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    rr_cause_1 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    total_score_cause_1=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[0]\n",
    "    \n",
    "    if edge_cause_1 in ['x_1','x_44']:\n",
    "        edge_accuracy+=1\n",
    "    \n",
    "    if total_score_cause_1 in ['x_1','x_44']:\n",
    "        total_correct+=1\n",
    "    \n",
    "    if counterfactual_cause_1 in ['x_1','x_44']:\n",
    "        counterfactual_correct+=1\n",
    "    \n",
    "    if instant_cause_1 in ['x_1','x_44']:\n",
    "        instant_accuracy+=1\n",
    "    \n",
    "    if lag_cause_1 in ['x_1','x_44']:\n",
    "        lag_accuracy+=1\n",
    "    \n",
    "    if rr_cause_1 in ['x_1','x_44']:\n",
    "        rr_accuracy+=1\n",
    "        \n",
    "    total_accuracy = total_correct/total_checked* 100\n",
    "    edge_accuracy = edge_correct/total_checked* 100\n",
    "    cf_accuracy = counterfactual_correct/total_checked* 100\n",
    "    instant_accuracy = instantaneous_correct/total_checked* 100\n",
    "    lag_accuracy = lagged_correct/total_checked* 100\n",
    "    rr_accuracy = rr_correct/total_checked* 100\n",
    "    \n",
    "    \n",
    "    logger.info(f\"Edge Accuracy = {edge_accuracy:.2f}, Instantaneous Accuracy = {instant_accuracy:.2f}, Lagged Accuracy = {lag_accuracy:.2f}, Counterfactual Accuracy = {cf_accuracy:.2f},  Blended Accuracy = {total_accuracy:.2f},  RR Accuracy = {rr_accuracy:.2f}  \") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1d64d-a1c1-47b1-9cf5-46913c05fe91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
