{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3559a8bd-d3ef-4fc1-9d11-9adbc07d2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from utils.utils import set_seed\n",
    "set_seed()\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.distributions import Normal, Laplace, RelaxedOneHotCategorical\n",
    "from torchdiffeq import odeint  # For continuous-time normalizing flows\n",
    "\n",
    "from feature.scalers import ranged_scaler\n",
    "from feature.engineering import *\n",
    "from CARAT.model_utils import *\n",
    "from CARAT.model import CausalGraphVAE\n",
    "from CARAT.components import *\n",
    "from utils.utils import set_seed, logger\n",
    "\n",
    "# Torch settings\n",
    "#torch.use_deterministic_algorithms(False)\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.autograd.profiler.profile(enabled=False)\n",
    "#torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "#torch.autograd.set_detect_anomaly(mode=False)\n",
    "\n",
    "# Environment variables\n",
    "#os.environ['CUBLAS_WORKSPACE_CONFIG'] = '167772160'\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "#os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set device\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "data = []\n",
    "with open('data/TEP/idv1/y.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        data.append([float(col.strip()) for col in columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcf9903-62ed-4eec-9a22-28d013172a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = len(data[0])\n",
    "col_names = []\n",
    "for i in  range(0,vars):\n",
    "    col_names.append('x_'+str(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4186cd19-2804-4acc-9e80-651792a44849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from feature.scalers import ranged_scaler\n",
    "df = pl.DataFrame(data,schema=col_names)\n",
    "for col in df.columns:\n",
    "    df = df.with_columns(ranged_scaler(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f176e5-8328-47d3-898c-620aec152f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5211d2-8b0d-48f1-9863-9986f68f65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random dates, trivial for this exercise\n",
    "\n",
    "start_date = '2023-03-01'  # Define the start date\n",
    "date_range = pd.date_range(start=start_date, periods=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e78764d-6061-4347-a15b-42915ce98352",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = most_frequent(find_optimal_lags_for_dataframe(df))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41f2494-6c22-46f8-921d-dc3dd99a8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']=date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b131b6f5-0728-4a5f-a866-7b964d369d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='None', ylabel='x_44'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=df,y='x_44',x=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e39ac1b-36cc-429c-809f-01b016584bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['x_1', 'x_4','x_7','x_13','x_16','x_18','x_19','x_44','x_50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba3bdf6-cc0e-4f60-bd0d-ef5be924498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[200:]\n",
    "bad = df[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1ffb3d-85b0-4e90-be11-2e218b5f69b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_1', 'x_4', 'x_7', 'x_13', 'x_16', 'x_18', 'x_19', 'x_44', 'x_50'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3dc758-21df-44c7-bc12-ceb0dc3e36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    normal = normal.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "try:\n",
    "    bad = bad.drop('time',axis=1)\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a52bc7-6830-4a25-8c76-7d167da5d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb92727-92ff-4c95-ab54-be1c0a279212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_1', 'x_4', 'x_7', 'x_13', 'x_16', 'x_18', 'x_19', 'x_44', 'x_50']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645900e2-8fb0-4eb4-895b-f1d6c4c63c58",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fb9c3b-10ff-44ee-87bc-7612dc566c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 947.5201\n",
      "Recon Loss =823.8625, KL Loss = 0.0019, Sparsity Loss = 33.2894, Lagrangian Loss = 90.3664\n",
      "Epoch 51: Loss = 149.2762\n",
      "Recon Loss =5.0998, KL Loss = 1.4245, Sparsity Loss = 32.2786, Lagrangian Loss = 110.4733\n",
      "Early stopping triggered. Last Epoch: 80\n",
      "Recon Loss =3.2578, KL Loss = 1.7347, Sparsity Loss = 32.9214, Lagrangian Loss = 126.9844\n",
      "Epoch 1: Loss = 1677.4421\n",
      "Recon Loss =866.1261, KL Loss = 0.0014, Sparsity Loss = 49.6196, Lagrangian Loss = 761.6951\n",
      "Early stopping triggered. Last Epoch: 46\n",
      "Recon Loss =857.6923, KL Loss = 0.0014, Sparsity Loss = 47.5767, Lagrangian Loss = 551.7401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.960609</td>\n",
       "      <td>0.902041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889287</td>\n",
       "      <td>0.937984</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.925573</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.827296</td>\n",
       "      <td>0.947045</td>\n",
       "      <td>0.924832</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990153</td>\n",
       "      <td>0.996422</td>\n",
       "      <td>0.613642</td>\n",
       "      <td>0.900054</td>\n",
       "      <td>0.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.894371</td>\n",
       "      <td>0.884957</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>0.888424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.820930</td>\n",
       "      <td>0.849456</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859192</td>\n",
       "      <td>0.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.776031</td>\n",
       "      <td>0.796995</td>\n",
       "      <td>0.731378</td>\n",
       "      <td>0.963031</td>\n",
       "      <td>0.816859</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.805169</td>\n",
       "      <td>0.786140</td>\n",
       "      <td>0.799359</td>\n",
       "      <td>0.442268</td>\n",
       "      <td>0.708234</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.909537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675713</td>\n",
       "      <td>0.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_19  0.960609       0.902041  1.000000         0.889287         0.937984   \n",
       "x_16  0.925573       0.999414  0.827296         0.947045         0.924832   \n",
       "x_50  1.000000       0.990153  0.996422         0.613642         0.900054   \n",
       "x_7   0.894371       0.884957  0.878456         0.895911         0.888424   \n",
       "x_44  0.820930       0.849456  0.766384         1.000000         0.859192   \n",
       "x_18  0.776031       0.796995  0.731378         0.963031         0.816859   \n",
       "x_1   0.805169       0.786140  0.799359         0.442268         0.708234   \n",
       "x_13  0.909537       1.000000  0.793314         0.000000         0.675713   \n",
       "x_4   0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_19  0.666667  \n",
       "x_16  0.500000  \n",
       "x_50  0.833334  \n",
       "x_7   1.000000  \n",
       "x_44  0.833334  \n",
       "x_18  0.333333  \n",
       "x_1   0.000000  \n",
       "x_13  0.833334  \n",
       "x_4   1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_STEPS = 3\n",
    "BATCH_SIZE = 100\n",
    "hidden_dim = 256\n",
    "latent_dim = 16\n",
    "dataset_nominal = TimeSeriesDataset(normal, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = CausalGraphVAE(input_dim=normal.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=normal.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=None).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "# Train on nominal data\n",
    "#print(\"Pretraining on nominal data...\")\n",
    "model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "\n",
    "# Extract learned adjacency\n",
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "dataset_bad = TimeSeriesDataset(bad, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_bad = DataLoader(dataset_bad, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "fine_tuned = CausalGraphVAE(input_dim=bad.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=bad.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=prior_adj).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "# Train on nominal data\n",
    "# print(\"Pretraining on nominal data...\")\n",
    "fine_tuned.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "\n",
    "X_data = torch.empty(0,device=device)\n",
    "T_data = torch.empty(0,device=device)\n",
    "for batch_idx, (X_batch, time_batch) in enumerate(dataloader_bad):\n",
    "    X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "    T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "\n",
    "\n",
    "causes= fine_tuned.infer_causal_effect(X_data=X_data,T_data=T_data,target_variable='x_4',\n",
    "                                       labels=cols,non_causal_indices=[],root_rank=False)\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b52236-a1c7-4a5d-86fc-1d54ab617431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.922178</td>\n",
       "      <td>0.800994</td>\n",
       "      <td>0.937829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.968235</td>\n",
       "      <td>0.984078</td>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.684670</td>\n",
       "      <td>0.875567</td>\n",
       "      <td>0.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.987402</td>\n",
       "      <td>0.876167</td>\n",
       "      <td>0.989264</td>\n",
       "      <td>0.615925</td>\n",
       "      <td>0.867189</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.988794</td>\n",
       "      <td>0.866267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384180</td>\n",
       "      <td>0.809810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.946415</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>0.450784</td>\n",
       "      <td>0.801664</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>0.908882</td>\n",
       "      <td>0.054009</td>\n",
       "      <td>0.740543</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.999688</td>\n",
       "      <td>0.996848</td>\n",
       "      <td>0.910354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.900547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734382</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.665657</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_13  0.922178       0.800994  0.937829         1.000000         0.915250   \n",
       "x_19  0.968235       0.984078  0.865286         0.684670         0.875567   \n",
       "x_7   0.987402       0.876167  0.989264         0.615925         0.867189   \n",
       "x_44  0.988794       0.866267  1.000000         0.384180         0.809810   \n",
       "x_18  0.946415       0.973951  0.835506         0.450784         0.801664   \n",
       "x_50  1.000000       0.999280  0.908882         0.054009         0.740543   \n",
       "x_1   0.999688       0.996848  0.910354         0.000000         0.726723   \n",
       "x_4   0.900547       1.000000  0.734382         0.027700         0.665657   \n",
       "x_16  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_13  1.000000  \n",
       "x_19  0.833334  \n",
       "x_7   1.000000  \n",
       "x_44  1.000000  \n",
       "x_18  0.333333  \n",
       "x_50  1.000000  \n",
       "x_1   0.000000  \n",
       "x_4   0.500000  \n",
       "x_16  0.500000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_16',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d5a058-7d09-4574-b7e7-543328c60d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.992771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921627</td>\n",
       "      <td>0.689536</td>\n",
       "      <td>0.900984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.865555</td>\n",
       "      <td>0.692126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889420</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995929</td>\n",
       "      <td>0.941884</td>\n",
       "      <td>0.452708</td>\n",
       "      <td>0.847630</td>\n",
       "      <td>0.750001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.916187</td>\n",
       "      <td>0.912990</td>\n",
       "      <td>0.856662</td>\n",
       "      <td>0.363196</td>\n",
       "      <td>0.762259</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.976023</td>\n",
       "      <td>0.947503</td>\n",
       "      <td>0.944378</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>0.758192</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.885197</td>\n",
       "      <td>0.817055</td>\n",
       "      <td>0.900137</td>\n",
       "      <td>0.157568</td>\n",
       "      <td>0.689989</td>\n",
       "      <td>0.750001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.839475</td>\n",
       "      <td>0.737848</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>0.114664</td>\n",
       "      <td>0.646956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.865351</td>\n",
       "      <td>0.841567</td>\n",
       "      <td>0.832049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634742</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_1   0.992771       1.000000  0.921627         0.689536         0.900984   \n",
       "x_7   0.865555       0.692126  1.000000         1.000000         0.889420   \n",
       "x_4   1.000000       0.995929  0.941884         0.452708         0.847630   \n",
       "x_16  0.916187       0.912990  0.856662         0.363196         0.762259   \n",
       "x_50  0.976023       0.947503  0.944378         0.164862         0.758192   \n",
       "x_44  0.885197       0.817055  0.900137         0.157568         0.689989   \n",
       "x_13  0.839475       0.737848  0.895835         0.114664         0.646956   \n",
       "x_19  0.865351       0.841567  0.832049         0.000000         0.634742   \n",
       "x_18  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_1   0.000000  \n",
       "x_7   0.500001  \n",
       "x_4   0.750001  \n",
       "x_16  0.500001  \n",
       "x_50  0.500001  \n",
       "x_44  0.750001  \n",
       "x_13  1.000000  \n",
       "x_19  0.250000  \n",
       "x_18  0.250000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_18',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7839e6-9779-4af4-b37b-d47ffd8241e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.984821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989450</td>\n",
       "      <td>0.895815</td>\n",
       "      <td>0.814304</td>\n",
       "      <td>0.924892</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.933002</td>\n",
       "      <td>0.823346</td>\n",
       "      <td>0.938078</td>\n",
       "      <td>0.950219</td>\n",
       "      <td>0.911161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.942042</td>\n",
       "      <td>0.782816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601608</td>\n",
       "      <td>0.831616</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.960939</td>\n",
       "      <td>0.907956</td>\n",
       "      <td>0.903281</td>\n",
       "      <td>0.319114</td>\n",
       "      <td>0.772822</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.953030</td>\n",
       "      <td>0.898331</td>\n",
       "      <td>0.897587</td>\n",
       "      <td>0.194953</td>\n",
       "      <td>0.735975</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.928140</td>\n",
       "      <td>0.840407</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.128363</td>\n",
       "      <td>0.701708</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.784241</td>\n",
       "      <td>0.629873</td>\n",
       "      <td>0.857314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_50  0.984821       1.000000  0.852948         1.000000         0.959442   \n",
       "x_4   1.000000       0.989450  0.895815         0.814304         0.924892   \n",
       "x_7   0.933002       0.823346  0.938078         0.950219         0.911161   \n",
       "x_16  0.942042       0.782816  1.000000         0.601608         0.831616   \n",
       "x_18  0.960939       0.907956  0.903281         0.319114         0.772822   \n",
       "x_44  0.953030       0.898331  0.897587         0.194953         0.735975   \n",
       "x_19  0.928140       0.840407  0.909923         0.128363         0.701708   \n",
       "x_1   0.784241       0.629873  0.857314         0.000000         0.567857   \n",
       "x_13  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_50  0.833334  \n",
       "x_4   0.666667  \n",
       "x_7   1.000000  \n",
       "x_16  0.000000  \n",
       "x_18  0.166667  \n",
       "x_44  1.000000  \n",
       "x_19  0.666667  \n",
       "x_1   0.666667  \n",
       "x_13  1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_13',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b6e21a-a6f8-4f41-a82a-78fd4545ebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957192</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>0.776878</td>\n",
       "      <td>0.931139</td>\n",
       "      <td>0.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.846439</td>\n",
       "      <td>0.643726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872541</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.915724</td>\n",
       "      <td>0.777906</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.677782</td>\n",
       "      <td>0.842813</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.805076</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>0.850024</td>\n",
       "      <td>0.975539</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.976898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896529</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.833768</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.919341</td>\n",
       "      <td>0.897303</td>\n",
       "      <td>0.883177</td>\n",
       "      <td>0.346652</td>\n",
       "      <td>0.761618</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.869200</td>\n",
       "      <td>0.777636</td>\n",
       "      <td>0.906086</td>\n",
       "      <td>0.182256</td>\n",
       "      <td>0.683795</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.893107</td>\n",
       "      <td>0.888082</td>\n",
       "      <td>0.839359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655137</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_13  1.000000       0.957192  0.990487         0.776878         0.931139   \n",
       "x_16  0.846439       0.643726  1.000000         1.000000         0.872541   \n",
       "x_1   0.915724       0.777906  0.999841         0.677782         0.842813   \n",
       "x_19  0.805076       0.710023  0.850024         0.975539         0.835165   \n",
       "x_44  0.976898       1.000000  0.896529         0.461646         0.833768   \n",
       "x_4   0.919341       0.897303  0.883177         0.346652         0.761618   \n",
       "x_18  0.869200       0.777636  0.906086         0.182256         0.683795   \n",
       "x_50  0.893107       0.888082  0.839359         0.000000         0.655137   \n",
       "x_7   0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_13  0.666668  \n",
       "x_16  0.333334  \n",
       "x_1   0.333334  \n",
       "x_19  0.333334  \n",
       "x_44  0.333334  \n",
       "x_4   0.333334  \n",
       "x_18  0.000000  \n",
       "x_50  0.333334  \n",
       "x_7   1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_7',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3cbeed5-e520-4a71-90e8-9f4358cdf403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.889809</td>\n",
       "      <td>0.878924</td>\n",
       "      <td>0.857807</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.964974</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.902798</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.893502</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.845775</td>\n",
       "      <td>0.805150</td>\n",
       "      <td>0.847787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.964263</td>\n",
       "      <td>0.959413</td>\n",
       "      <td>0.927664</td>\n",
       "      <td>0.619863</td>\n",
       "      <td>0.867801</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.939680</td>\n",
       "      <td>0.617789</td>\n",
       "      <td>0.837465</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961570</td>\n",
       "      <td>0.381261</td>\n",
       "      <td>0.835708</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.785123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673503</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.786929</td>\n",
       "      <td>0.640955</td>\n",
       "      <td>0.908467</td>\n",
       "      <td>0.077750</td>\n",
       "      <td>0.603525</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_44  0.889809       0.878924  0.857807         0.965354         0.897974   \n",
       "x_19  0.964974       0.983607  0.902798         0.722628         0.893502   \n",
       "x_18  0.845775       0.805150  0.847787         1.000000         0.874678   \n",
       "x_7   0.964263       0.959413  0.927664         0.619863         0.867801   \n",
       "x_4   0.923611       0.868782  0.939680         0.617789         0.837465   \n",
       "x_13  1.000000       1.000000  0.961570         0.381261         0.835708   \n",
       "x_16  0.908889       0.785123  1.000000         0.000000         0.673503   \n",
       "x_1   0.786929       0.640955  0.908467         0.077750         0.603525   \n",
       "x_50  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_44  0.857143  \n",
       "x_19  0.714286  \n",
       "x_18  0.000000  \n",
       "x_7   1.000000  \n",
       "x_4   0.571429  \n",
       "x_13  0.714286  \n",
       "x_16  0.428571  \n",
       "x_1   0.142857  \n",
       "x_50  0.714286  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_50',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555c1d74-8249-4237-8c4d-71e2acb517b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.928873</td>\n",
       "      <td>0.978526</td>\n",
       "      <td>0.864197</td>\n",
       "      <td>0.761702</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.843321</td>\n",
       "      <td>0.873558</td>\n",
       "      <td>0.796724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878401</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.877488</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.960353</td>\n",
       "      <td>0.621424</td>\n",
       "      <td>0.812441</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.884326</td>\n",
       "      <td>0.944458</td>\n",
       "      <td>0.496819</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.915939</td>\n",
       "      <td>0.927384</td>\n",
       "      <td>0.892303</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.803072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196864</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.768506</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.786407</td>\n",
       "      <td>0.860081</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>0.199999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.968724</td>\n",
       "      <td>0.994042</td>\n",
       "      <td>0.935506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.724568</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_18  0.928873       0.978526  0.864197         0.761702         0.883325   \n",
       "x_16  0.843321       0.873558  0.796724         1.000000         0.878401   \n",
       "x_4   0.877488       0.790500  0.960353         0.621424         0.812441   \n",
       "x_44  0.918117       0.884326  0.944458         0.496819         0.810930   \n",
       "x_13  0.915939       0.927384  0.892303         0.476662         0.803072   \n",
       "x_50  1.000000       1.000000  1.000000         0.196864         0.799216   \n",
       "x_1   0.768506       0.742738  0.786407         0.860081         0.789433   \n",
       "x_7   0.968724       0.994042  0.935506         0.000000         0.724568   \n",
       "x_19  0.000000       0.000000  0.000000              NaN         0.000000   \n",
       "\n",
       "      RootRank  \n",
       "x_18  0.000000  \n",
       "x_16  0.400000  \n",
       "x_4   0.400000  \n",
       "x_44  1.000000  \n",
       "x_13  1.000000  \n",
       "x_50  0.400000  \n",
       "x_1   0.199999  \n",
       "x_7   1.000000  \n",
       "x_19  1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_19',cols,non_causal_indices=[])\n",
    "causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44039614-1138-4a1b-8aaa-3244219d7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define the seed value\n",
    "seed = 42\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for CUDA (if using GPUs)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "# Set seed for Python's random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior for PyTorch operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "344bfeb6-d2fd-4476-adda-89829a6bc1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 180.8236\n",
      "Recon Loss =56.0810, KL Loss = 0.0677, Sparsity Loss = 33.4604, Lagrangian Loss = 25.7073\n",
      "Early stopping triggered. Last Epoch: 48\n",
      "Recon Loss =0.5477, KL Loss = 0.0002, Sparsity Loss = 33.9743, Lagrangian Loss = 24.5831\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.644539</td>\n",
       "      <td>0.522534</td>\n",
       "      <td>0.551943</td>\n",
       "      <td>0.612221</td>\n",
       "      <td>0.604866</td>\n",
       "      <td>0.541450</td>\n",
       "      <td>0.590475</td>\n",
       "      <td>0.609725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.615948</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.520956</td>\n",
       "      <td>0.554811</td>\n",
       "      <td>0.646218</td>\n",
       "      <td>0.626983</td>\n",
       "      <td>0.513627</td>\n",
       "      <td>0.628174</td>\n",
       "      <td>0.648861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.542042</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.602807</td>\n",
       "      <td>0.556427</td>\n",
       "      <td>0.554175</td>\n",
       "      <td>0.643402</td>\n",
       "      <td>0.533793</td>\n",
       "      <td>0.544084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_13</th>\n",
       "      <td>0.540882</td>\n",
       "      <td>0.559267</td>\n",
       "      <td>0.643989</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.538686</td>\n",
       "      <td>0.576236</td>\n",
       "      <td>0.605953</td>\n",
       "      <td>0.552551</td>\n",
       "      <td>0.532405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_16</th>\n",
       "      <td>0.644338</td>\n",
       "      <td>0.604529</td>\n",
       "      <td>0.553317</td>\n",
       "      <td>0.530696</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.630805</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.615146</td>\n",
       "      <td>0.606393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>0.642389</td>\n",
       "      <td>0.626783</td>\n",
       "      <td>0.550396</td>\n",
       "      <td>0.536084</td>\n",
       "      <td>0.641907</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.558934</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.594505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.559507</td>\n",
       "      <td>0.556449</td>\n",
       "      <td>0.623338</td>\n",
       "      <td>0.638873</td>\n",
       "      <td>0.562238</td>\n",
       "      <td>0.553338</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.524894</td>\n",
       "      <td>0.541042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_44</th>\n",
       "      <td>0.620576</td>\n",
       "      <td>0.654581</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.529389</td>\n",
       "      <td>0.599364</td>\n",
       "      <td>0.627805</td>\n",
       "      <td>0.553022</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.641834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_50</th>\n",
       "      <td>0.608802</td>\n",
       "      <td>0.633360</td>\n",
       "      <td>0.554605</td>\n",
       "      <td>0.532644</td>\n",
       "      <td>0.645442</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.513911</td>\n",
       "      <td>0.609381</td>\n",
       "      <td>0.268941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_1       x_4       x_7      x_13      x_16      x_18      x_19  \\\n",
       "x_1   0.268941  0.644539  0.522534  0.551943  0.612221  0.604866  0.541450   \n",
       "x_4   0.615948  0.268941  0.520956  0.554811  0.646218  0.626983  0.513627   \n",
       "x_7   0.542042  0.571395  0.268941  0.602807  0.556427  0.554175  0.643402   \n",
       "x_13  0.540882  0.559267  0.643989  0.268941  0.538686  0.576236  0.605953   \n",
       "x_16  0.644338  0.604529  0.553317  0.530696  0.268941  0.630805  0.555686   \n",
       "x_18  0.642389  0.626783  0.550396  0.536084  0.641907  0.268941  0.558934   \n",
       "x_19  0.559507  0.556449  0.623338  0.638873  0.562238  0.553338  0.268941   \n",
       "x_44  0.620576  0.654581  0.553515  0.529389  0.599364  0.627805  0.553022   \n",
       "x_50  0.608802  0.633360  0.554605  0.532644  0.645442  0.660048  0.513911   \n",
       "\n",
       "          x_44      x_50  \n",
       "x_1   0.590475  0.609725  \n",
       "x_4   0.628174  0.648861  \n",
       "x_7   0.533793  0.544084  \n",
       "x_13  0.552551  0.532405  \n",
       "x_16  0.615146  0.606393  \n",
       "x_18  0.611544  0.594505  \n",
       "x_19  0.524894  0.541042  \n",
       "x_44  0.268941  0.641834  \n",
       "x_50  0.609381  0.268941  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_STEPS = 3\n",
    "BATCH_SIZE = 25\n",
    "hidden_dim = 256\n",
    "latent_dim = 8\n",
    "dataset_nominal = TimeSeriesDataset(normal, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = CausalGraphVAE(input_dim=normal.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=normal.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=None).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-0)\n",
    "\n",
    "# Train on nominal data\n",
    "#print(\"Pretraining on nominal data...\")\n",
    "model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=0.2,alpha_max=0.2)\n",
    "\n",
    "# Extract learned adjacency\n",
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "pd.DataFrame((prior_adj).cpu().detach().numpy(),index=cols,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5057eeb3-1ac1-4644-a2bd-9d6550a42207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 339.2449\n",
      "Recon Loss =206.3795, KL Loss = 0.0024, Sparsity Loss = 46.2560, Lagrangian Loss = 67.8252\n",
      "Early stopping triggered. Last Epoch: 34\n",
      "Recon Loss =206.5783, KL Loss = 0.0024, Sparsity Loss = 46.8429, Lagrangian Loss = 81.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:56:29,638 INFO -- Edge Accuracy = 100.00, Instantaneous Accuracy = 100.00, Lagged Accuracy = 100.00, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 100.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 331.8032\n",
      "Recon Loss =193.1337, KL Loss = 0.0007, Sparsity Loss = 48.5448, Lagrangian Loss = 98.0229\n",
      "Early stopping triggered. Last Epoch: 39\n",
      "Recon Loss =192.3735, KL Loss = 0.0007, Sparsity Loss = 46.7816, Lagrangian Loss = 78.5215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:56:36,810 INFO -- Edge Accuracy = 50.00, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 50.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 329.4909\n",
      "Recon Loss =187.3076, KL Loss = 0.0022, Sparsity Loss = 46.2384, Lagrangian Loss = 69.8043\n",
      "Epoch 51: Loss = 323.0338\n",
      "Recon Loss =190.3420, KL Loss = 0.0022, Sparsity Loss = 47.0186, Lagrangian Loss = 76.6265\n",
      "Epoch 101: Loss = 334.6929\n",
      "Recon Loss =186.3015, KL Loss = 0.0022, Sparsity Loss = 47.3794, Lagrangian Loss = 84.5864\n",
      "Early stopping triggered. Last Epoch: 101\n",
      "Recon Loss =188.4141, KL Loss = 0.0022, Sparsity Loss = 45.8411, Lagrangian Loss = 65.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:56:54,267 INFO -- Edge Accuracy = 66.67, Instantaneous Accuracy = 66.67, Lagged Accuracy = 66.67, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 66.67  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 341.9557\n",
      "Recon Loss =213.0356, KL Loss = 0.0036, Sparsity Loss = 46.3557, Lagrangian Loss = 81.5440\n",
      "Early stopping triggered. Last Epoch: 31\n",
      "Recon Loss =211.5249, KL Loss = 0.0036, Sparsity Loss = 46.1983, Lagrangian Loss = 74.2587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:00,050 INFO -- Edge Accuracy = 75.00, Instantaneous Accuracy = 75.00, Lagged Accuracy = 75.00, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 50.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 333.9895\n",
      "Recon Loss =183.0444, KL Loss = 0.0020, Sparsity Loss = 48.3161, Lagrangian Loss = 98.8868\n",
      "Early stopping triggered. Last Epoch: 31\n",
      "Recon Loss =182.9424, KL Loss = 0.0020, Sparsity Loss = 48.2616, Lagrangian Loss = 96.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:05,933 INFO -- Edge Accuracy = 80.00, Instantaneous Accuracy = 80.00, Lagged Accuracy = 80.00, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 60.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 322.8201\n",
      "Recon Loss =182.4622, KL Loss = 0.0024, Sparsity Loss = 46.0555, Lagrangian Loss = 72.4906\n",
      "Epoch 51: Loss = 312.6423\n",
      "Recon Loss =176.3662, KL Loss = 0.0024, Sparsity Loss = 46.2517, Lagrangian Loss = 88.5255\n",
      "Early stopping triggered. Last Epoch: 80\n",
      "Recon Loss =178.2677, KL Loss = 0.0024, Sparsity Loss = 46.7285, Lagrangian Loss = 84.2737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:19,837 INFO -- Edge Accuracy = 83.33, Instantaneous Accuracy = 83.33, Lagged Accuracy = 83.33, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 66.67  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 338.7035\n",
      "Recon Loss =199.7307, KL Loss = 0.0025, Sparsity Loss = 48.0182, Lagrangian Loss = 93.4773\n",
      "Early stopping triggered. Last Epoch: 49\n",
      "Recon Loss =197.4453, KL Loss = 0.0025, Sparsity Loss = 47.1597, Lagrangian Loss = 76.2664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:28,584 INFO -- Edge Accuracy = 85.71, Instantaneous Accuracy = 85.71, Lagged Accuracy = 85.71, Counterfactual Accuracy = 85.71,  Blended Accuracy = 85.71,  RR Accuracy = 71.43  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 339.8398\n",
      "Recon Loss =202.0997, KL Loss = 0.0033, Sparsity Loss = 46.9076, Lagrangian Loss = 74.1991\n",
      "Early stopping triggered. Last Epoch: 41\n",
      "Recon Loss =205.9369, KL Loss = 0.0033, Sparsity Loss = 45.2240, Lagrangian Loss = 59.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:36,088 INFO -- Edge Accuracy = 87.50, Instantaneous Accuracy = 87.50, Lagged Accuracy = 87.50, Counterfactual Accuracy = 75.00,  Blended Accuracy = 75.00,  RR Accuracy = 75.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 331.9559\n",
      "Recon Loss =200.9631, KL Loss = 0.0014, Sparsity Loss = 46.8183, Lagrangian Loss = 74.9346\n",
      "Epoch 51: Loss = 337.6224\n",
      "Recon Loss =203.1844, KL Loss = 0.0014, Sparsity Loss = 45.9618, Lagrangian Loss = 69.5121\n",
      "Early stopping triggered. Last Epoch: 79\n",
      "Recon Loss =202.7448, KL Loss = 0.0014, Sparsity Loss = 45.8836, Lagrangian Loss = 64.4074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:57:49,895 INFO -- Edge Accuracy = 77.78, Instantaneous Accuracy = 88.89, Lagged Accuracy = 77.78, Counterfactual Accuracy = 66.67,  Blended Accuracy = 66.67,  RR Accuracy = 66.67  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 357.6803\n",
      "Recon Loss =212.5864, KL Loss = 0.0039, Sparsity Loss = 47.9592, Lagrangian Loss = 96.2373\n",
      "Epoch 51: Loss = 350.3479\n",
      "Recon Loss =214.5603, KL Loss = 0.0039, Sparsity Loss = 47.8730, Lagrangian Loss = 91.2795\n",
      "Early stopping triggered. Last Epoch: 64\n",
      "Recon Loss =211.5472, KL Loss = 0.0039, Sparsity Loss = 46.5825, Lagrangian Loss = 72.2463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:01,294 INFO -- Edge Accuracy = 80.00, Instantaneous Accuracy = 90.00, Lagged Accuracy = 80.00, Counterfactual Accuracy = 60.00,  Blended Accuracy = 60.00,  RR Accuracy = 70.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 344.5853\n",
      "Recon Loss =198.8622, KL Loss = 0.0028, Sparsity Loss = 47.4406, Lagrangian Loss = 80.7018\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =197.0366, KL Loss = 0.0028, Sparsity Loss = 47.0382, Lagrangian Loss = 79.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:09,037 INFO -- Edge Accuracy = 81.82, Instantaneous Accuracy = 90.91, Lagged Accuracy = 81.82, Counterfactual Accuracy = 54.55,  Blended Accuracy = 63.64,  RR Accuracy = 72.73  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 325.8356\n",
      "Recon Loss =190.7728, KL Loss = 0.0014, Sparsity Loss = 46.6635, Lagrangian Loss = 74.7603\n",
      "Epoch 51: Loss = 321.2916\n",
      "Recon Loss =190.9207, KL Loss = 0.0014, Sparsity Loss = 47.5090, Lagrangian Loss = 87.7052\n",
      "Early stopping triggered. Last Epoch: 84\n",
      "Recon Loss =193.9751, KL Loss = 0.0014, Sparsity Loss = 48.3358, Lagrangian Loss = 101.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:23,858 INFO -- Edge Accuracy = 75.00, Instantaneous Accuracy = 83.33, Lagged Accuracy = 75.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 58.33,  RR Accuracy = 75.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 339.4050\n",
      "Recon Loss =198.9221, KL Loss = 0.0020, Sparsity Loss = 46.1507, Lagrangian Loss = 77.2975\n",
      "Early stopping triggered. Last Epoch: 40\n",
      "Recon Loss =199.7109, KL Loss = 0.0020, Sparsity Loss = 48.1800, Lagrangian Loss = 101.5249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:31,259 INFO -- Edge Accuracy = 76.92, Instantaneous Accuracy = 84.62, Lagged Accuracy = 76.92, Counterfactual Accuracy = 53.85,  Blended Accuracy = 61.54,  RR Accuracy = 69.23  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 345.3475\n",
      "Recon Loss =197.4405, KL Loss = 0.0014, Sparsity Loss = 47.0651, Lagrangian Loss = 78.4008\n",
      "Early stopping triggered. Last Epoch: 43\n",
      "Recon Loss =197.3994, KL Loss = 0.0014, Sparsity Loss = 47.1144, Lagrangian Loss = 93.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:39,138 INFO -- Edge Accuracy = 78.57, Instantaneous Accuracy = 85.71, Lagged Accuracy = 78.57, Counterfactual Accuracy = 57.14,  Blended Accuracy = 64.29,  RR Accuracy = 71.43  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 334.3962\n",
      "Recon Loss =199.4213, KL Loss = 0.0020, Sparsity Loss = 45.5038, Lagrangian Loss = 64.5515\n",
      "Epoch 51: Loss = 338.6804\n",
      "Recon Loss =200.6808, KL Loss = 0.0020, Sparsity Loss = 47.2476, Lagrangian Loss = 78.4043\n",
      "Early stopping triggered. Last Epoch: 68\n",
      "Recon Loss =202.1396, KL Loss = 0.0020, Sparsity Loss = 46.4413, Lagrangian Loss = 71.5252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:51,268 INFO -- Edge Accuracy = 80.00, Instantaneous Accuracy = 86.67, Lagged Accuracy = 80.00, Counterfactual Accuracy = 60.00,  Blended Accuracy = 66.67,  RR Accuracy = 73.33  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 331.6091\n",
      "Recon Loss =205.2221, KL Loss = 0.0026, Sparsity Loss = 46.6201, Lagrangian Loss = 78.2058\n",
      "Early stopping triggered. Last Epoch: 42\n",
      "Recon Loss =202.2160, KL Loss = 0.0026, Sparsity Loss = 47.3556, Lagrangian Loss = 85.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:58:59,024 INFO -- Edge Accuracy = 81.25, Instantaneous Accuracy = 87.50, Lagged Accuracy = 81.25, Counterfactual Accuracy = 62.50,  Blended Accuracy = 68.75,  RR Accuracy = 75.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 345.7864\n",
      "Recon Loss =191.9345, KL Loss = 0.0021, Sparsity Loss = 46.7260, Lagrangian Loss = 75.0477\n",
      "Epoch 51: Loss = 340.2709\n",
      "Recon Loss =191.6979, KL Loss = 0.0021, Sparsity Loss = 47.0162, Lagrangian Loss = 83.2443\n",
      "Early stopping triggered. Last Epoch: 59\n",
      "Recon Loss =192.1119, KL Loss = 0.0021, Sparsity Loss = 46.6511, Lagrangian Loss = 90.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:59:09,603 INFO -- Edge Accuracy = 82.35, Instantaneous Accuracy = 88.24, Lagged Accuracy = 76.47, Counterfactual Accuracy = 64.71,  Blended Accuracy = 70.59,  RR Accuracy = 70.59  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 335.1851\n",
      "Recon Loss =200.2745, KL Loss = 0.0017, Sparsity Loss = 46.8663, Lagrangian Loss = 72.5133\n",
      "Epoch 51: Loss = 329.5665\n",
      "Recon Loss =200.3478, KL Loss = 0.0017, Sparsity Loss = 45.7221, Lagrangian Loss = 62.2768\n",
      "Early stopping triggered. Last Epoch: 57\n",
      "Recon Loss =201.5123, KL Loss = 0.0017, Sparsity Loss = 46.8854, Lagrangian Loss = 78.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:59:19,871 INFO -- Edge Accuracy = 83.33, Instantaneous Accuracy = 88.89, Lagged Accuracy = 77.78, Counterfactual Accuracy = 61.11,  Blended Accuracy = 66.67,  RR Accuracy = 72.22  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 362.6976\n",
      "Recon Loss =199.7973, KL Loss = 0.0021, Sparsity Loss = 48.2230, Lagrangian Loss = 115.6355\n",
      "Epoch 51: Loss = 357.9128\n",
      "Recon Loss =202.2667, KL Loss = 0.0021, Sparsity Loss = 48.5629, Lagrangian Loss = 114.9612\n",
      "Epoch 101: Loss = 374.6592\n",
      "Recon Loss =204.2350, KL Loss = 0.0021, Sparsity Loss = 46.5437, Lagrangian Loss = 87.7203\n",
      "Early stopping triggered. Last Epoch: 120\n",
      "Recon Loss =198.5423, KL Loss = 0.0021, Sparsity Loss = 48.7393, Lagrangian Loss = 128.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:59:40,781 INFO -- Edge Accuracy = 78.95, Instantaneous Accuracy = 84.21, Lagged Accuracy = 78.95, Counterfactual Accuracy = 57.89,  Blended Accuracy = 63.16,  RR Accuracy = 73.68  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 353.7647\n",
      "Recon Loss =192.1852, KL Loss = 0.0023, Sparsity Loss = 48.9313, Lagrangian Loss = 114.2834\n",
      "Epoch 51: Loss = 346.0465\n",
      "Recon Loss =191.3927, KL Loss = 0.0023, Sparsity Loss = 47.0727, Lagrangian Loss = 86.9000\n",
      "Early stopping triggered. Last Epoch: 76\n",
      "Recon Loss =192.6792, KL Loss = 0.0023, Sparsity Loss = 47.7369, Lagrangian Loss = 91.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:59:54,276 INFO -- Edge Accuracy = 80.00, Instantaneous Accuracy = 85.00, Lagged Accuracy = 80.00, Counterfactual Accuracy = 55.00,  Blended Accuracy = 60.00,  RR Accuracy = 70.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 345.9719\n",
      "Recon Loss =196.2282, KL Loss = 0.0011, Sparsity Loss = 45.8904, Lagrangian Loss = 65.5383\n",
      "Early stopping triggered. Last Epoch: 31\n",
      "Recon Loss =198.7813, KL Loss = 0.0011, Sparsity Loss = 44.5617, Lagrangian Loss = 63.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:00,178 INFO -- Edge Accuracy = 80.95, Instantaneous Accuracy = 85.71, Lagged Accuracy = 80.95, Counterfactual Accuracy = 57.14,  Blended Accuracy = 61.90,  RR Accuracy = 66.67  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 336.7107\n",
      "Recon Loss =190.5860, KL Loss = 0.0025, Sparsity Loss = 48.1978, Lagrangian Loss = 94.4760\n",
      "Early stopping triggered. Last Epoch: 34\n",
      "Recon Loss =193.3929, KL Loss = 0.0025, Sparsity Loss = 46.5136, Lagrangian Loss = 84.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:06,537 INFO -- Edge Accuracy = 81.82, Instantaneous Accuracy = 86.36, Lagged Accuracy = 77.27, Counterfactual Accuracy = 54.55,  Blended Accuracy = 63.64,  RR Accuracy = 68.18  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 358.4248\n",
      "Recon Loss =200.7206, KL Loss = 0.0016, Sparsity Loss = 46.0578, Lagrangian Loss = 70.9155\n",
      "Early stopping triggered. Last Epoch: 36\n",
      "Recon Loss =202.4429, KL Loss = 0.0016, Sparsity Loss = 48.1423, Lagrangian Loss = 95.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:13,156 INFO -- Edge Accuracy = 82.61, Instantaneous Accuracy = 86.96, Lagged Accuracy = 73.91, Counterfactual Accuracy = 52.17,  Blended Accuracy = 65.22,  RR Accuracy = 65.22  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 346.0463\n",
      "Recon Loss =215.1415, KL Loss = 0.0020, Sparsity Loss = 47.1090, Lagrangian Loss = 78.7173\n",
      "Epoch 51: Loss = 349.3813\n",
      "Recon Loss =211.0893, KL Loss = 0.0020, Sparsity Loss = 46.0504, Lagrangian Loss = 74.0593\n",
      "Early stopping triggered. Last Epoch: 68\n",
      "Recon Loss =214.4621, KL Loss = 0.0020, Sparsity Loss = 48.2837, Lagrangian Loss = 103.5202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:25,131 INFO -- Edge Accuracy = 83.33, Instantaneous Accuracy = 87.50, Lagged Accuracy = 75.00, Counterfactual Accuracy = 54.17,  Blended Accuracy = 66.67,  RR Accuracy = 66.67  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 375.8833\n",
      "Recon Loss =211.1843, KL Loss = 0.0025, Sparsity Loss = 49.0931, Lagrangian Loss = 114.0239\n",
      "Epoch 51: Loss = 390.6217\n",
      "Recon Loss =217.1740, KL Loss = 0.0025, Sparsity Loss = 49.3151, Lagrangian Loss = 128.4837\n",
      "Early stopping triggered. Last Epoch: 70\n",
      "Recon Loss =212.5508, KL Loss = 0.0025, Sparsity Loss = 49.2752, Lagrangian Loss = 123.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:37,394 INFO -- Edge Accuracy = 84.00, Instantaneous Accuracy = 88.00, Lagged Accuracy = 72.00, Counterfactual Accuracy = 52.00,  Blended Accuracy = 64.00,  RR Accuracy = 64.00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 350.2736\n",
      "Recon Loss =215.8726, KL Loss = 0.0027, Sparsity Loss = 46.8003, Lagrangian Loss = 86.5812\n",
      "Epoch 51: Loss = 357.6506\n",
      "Recon Loss =213.8204, KL Loss = 0.0027, Sparsity Loss = 48.6931, Lagrangian Loss = 115.3527\n",
      "Early stopping triggered. Last Epoch: 77\n",
      "Recon Loss =212.2899, KL Loss = 0.0027, Sparsity Loss = 47.5467, Lagrangian Loss = 87.3895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:50,921 INFO -- Edge Accuracy = 84.62, Instantaneous Accuracy = 88.46, Lagged Accuracy = 73.08, Counterfactual Accuracy = 50.00,  Blended Accuracy = 61.54,  RR Accuracy = 61.54  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 349.7842\n",
      "Recon Loss =195.0355, KL Loss = 0.0020, Sparsity Loss = 47.9059, Lagrangian Loss = 87.3636\n",
      "Early stopping triggered. Last Epoch: 44\n",
      "Recon Loss =197.5073, KL Loss = 0.0020, Sparsity Loss = 48.1197, Lagrangian Loss = 111.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:00:58,803 INFO -- Edge Accuracy = 85.19, Instantaneous Accuracy = 85.19, Lagged Accuracy = 74.07, Counterfactual Accuracy = 51.85,  Blended Accuracy = 62.96,  RR Accuracy = 59.26  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 336.2931\n",
      "Recon Loss =201.6404, KL Loss = 0.0021, Sparsity Loss = 45.8079, Lagrangian Loss = 60.7245\n",
      "Epoch 51: Loss = 343.5644\n",
      "Recon Loss =202.1386, KL Loss = 0.0021, Sparsity Loss = 47.0301, Lagrangian Loss = 79.8680\n",
      "Early stopping triggered. Last Epoch: 53\n",
      "Recon Loss =200.8325, KL Loss = 0.0021, Sparsity Loss = 46.5228, Lagrangian Loss = 72.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:01:08,320 INFO -- Edge Accuracy = 85.71, Instantaneous Accuracy = 85.71, Lagged Accuracy = 75.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 64.29,  RR Accuracy = 60.71  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 353.6987\n",
      "Recon Loss =216.8077, KL Loss = 0.0022, Sparsity Loss = 46.3147, Lagrangian Loss = 70.2120\n",
      "Epoch 51: Loss = 345.1086\n",
      "Recon Loss =212.3732, KL Loss = 0.0022, Sparsity Loss = 44.9465, Lagrangian Loss = 58.8086\n",
      "Early stopping triggered. Last Epoch: 57\n",
      "Recon Loss =210.7558, KL Loss = 0.0022, Sparsity Loss = 46.5044, Lagrangian Loss = 78.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:01:18,399 INFO -- Edge Accuracy = 86.21, Instantaneous Accuracy = 86.21, Lagged Accuracy = 72.41, Counterfactual Accuracy = 48.28,  Blended Accuracy = 65.52,  RR Accuracy = 62.07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 329.7691\n",
      "Recon Loss =195.7222, KL Loss = 0.0037, Sparsity Loss = 46.8423, Lagrangian Loss = 76.0226\n",
      "Early stopping triggered. Last Epoch: 32\n",
      "Recon Loss =193.9079, KL Loss = 0.0037, Sparsity Loss = 47.7669, Lagrangian Loss = 84.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:01:24,422 INFO -- Edge Accuracy = 86.67, Instantaneous Accuracy = 86.67, Lagged Accuracy = 73.33, Counterfactual Accuracy = 46.67,  Blended Accuracy = 66.67,  RR Accuracy = 63.33  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_correct = 0\n",
    "instantaneous_correct = 0\n",
    "lagged_correct = 0\n",
    "counterfactual_correct = 0 \n",
    "rr_correct = 0\n",
    "total_correct = 0\n",
    "total_checked = 0\n",
    "for i in range(30):\n",
    "    total_checked+=1\n",
    "\n",
    "    dataset_bad = TimeSeriesDataset(bad, device=device, time_steps=TIME_STEPS)\n",
    "    dataloader_bad = DataLoader(dataset_bad, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    fine_tuned = CausalGraphVAE(input_dim=bad.shape[1], hidden_dim=hidden_dim,\n",
    "                            latent_dim=latent_dim, num_nodes=bad.shape[1],device=device,\n",
    "                            time_steps=TIME_STEPS, prior_adj=prior_adj).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-0)\n",
    "    \n",
    "    # Train on nominal data\n",
    "    # print(\"Pretraining on nominal data...\")\n",
    "    fine_tuned.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,BATCH_SIZE=BATCH_SIZE,rho_max=0.2,alpha_max=0.2)\n",
    "    \n",
    "    X_data = torch.empty(0,device=device)\n",
    "    T_data = torch.empty(0,device=device)\n",
    "    for batch_idx, (X_batch, time_batch) in enumerate(dataloader_bad):\n",
    "        X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "        T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "    \n",
    "    causes= fine_tuned.infer_causal_effect(X_data,T_data,'x_4',cols,non_causal_indices=[])\n",
    "    \n",
    "    edge_cause_1 = causes.sort_values(by='causes',ascending=False)[0:3].index[0]\n",
    "    edge_cause_2 = causes.sort_values(by='causes',ascending=False)[0:3].index[1]\n",
    "    edge_cause_3 = causes.sort_values(by='causes',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    instant_cause_1 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[0]\n",
    "    instant_cause_2 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[1]\n",
    "    instant_cause_3 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    lag_cause_1 = causes.sort_values(by='lagged',ascending=False)[0:3].index[0]\n",
    "    lag_cause_2 = causes.sort_values(by='lagged',ascending=False)[0:3].index[1]\n",
    "    lag_cause_3 = causes.sort_values(by='lagged',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    counterfactual_cause_1 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[0]\n",
    "    counterfactual_cause_2 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[1]\n",
    "    counterfactual_cause_3 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    rr_cause_1 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[0]\n",
    "    rr_cause_2 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[1]\n",
    "    rr_cause_3 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    total_score_cause_1=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[0]\n",
    "    total_score_cause_2=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[1]\n",
    "    total_score_cause_3=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    if (edge_cause_1 in ['x_1','x_44']) | (edge_cause_2 in ['x_1','x_44']) | (edge_cause_3 in ['x_1','x_44']):\n",
    "        edge_correct+=1\n",
    "    \n",
    "    if (  total_score_cause_1 in ['x_1','x_44']) | (total_score_cause_2 in ['x_1','x_44']) | ( total_score_cause_3 in ['x_1','x_44']):\n",
    "        total_correct+=1\n",
    "    \n",
    "    if (counterfactual_cause_1 in ['x_1','x_44']) | (counterfactual_cause_2 in ['x_1','x_44']) | (counterfactual_cause_3 in ['x_1','x_44']):\n",
    "        counterfactual_correct+=1\n",
    "    \n",
    "    if (instant_cause_1 in ['x_1','x_44']) | (instant_cause_2 in ['x_1','x_44']) |( instant_cause_3 in ['x_1','x_44'] ):\n",
    "        instantaneous_correct+=1\n",
    "    \n",
    "    if (lag_cause_1 in ['x_1','x_44']) | (lag_cause_2 in ['x_1','x_44'])  | (lag_cause_3 in ['x_1','x_44']):\n",
    "        lagged_correct+=1\n",
    "    \n",
    "    if (rr_cause_1 in ['x_1','x_44']) | (rr_cause_2 in ['x_1','x_44']) | (rr_cause_3 in ['x_1','x_44']):\n",
    "        rr_correct+=1\n",
    "        \n",
    "    total_accuracy = total_correct/total_checked* 100\n",
    "    edge_accuracy = edge_correct/total_checked* 100\n",
    "    cf_accuracy = counterfactual_correct/total_checked* 100\n",
    "    instant_accuracy = instantaneous_correct/total_checked* 100\n",
    "    lag_accuracy = lagged_correct/total_checked* 100\n",
    "    rr_accuracy = rr_correct/total_checked* 100\n",
    "    \n",
    "    \n",
    "    logger.info(f\"Edge Accuracy = {edge_accuracy:.2f}, Instantaneous Accuracy = {instant_accuracy:.2f}, Lagged Accuracy = {lag_accuracy:.2f}, Counterfactual Accuracy = {cf_accuracy:.2f},  Blended Accuracy = {total_accuracy:.2f},  RR Accuracy = {rr_accuracy:.2f}  \") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4eec4ebc-5af0-4b4e-b1b2-a3899bb8f85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causes</th>\n",
       "      <th>instantaneous</th>\n",
       "      <th>lagged</th>\n",
       "      <th>counterfactuals</th>\n",
       "      <th>causal_strength</th>\n",
       "      <th>RootRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577954</td>\n",
       "      <td>0.876324</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_19</th>\n",
       "      <td>0.885413</td>\n",
       "      <td>0.721384</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>0.303059</td>\n",
       "      <td>0.721535</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.843736</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.880709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617750</td>\n",
       "      <td>0.666668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        causes  instantaneous    lagged  counterfactuals  causal_strength  \\\n",
       "x_18  1.000000       0.927344  1.000000         0.577954         0.876324   \n",
       "x_19  0.885413       0.721384  0.976285         0.303059         0.721535   \n",
       "x_7   0.843736       0.746555  0.880709         0.000000         0.617750   \n",
       "\n",
       "      RootRank  \n",
       "x_18  1.000000  \n",
       "x_19  0.000000  \n",
       "x_7   0.666668  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causes.sort_values(by='lagged',ascending=False)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "516d6947-e922-4fa1-8882-3b79fb409978",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m time_context_dummy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(time_steps)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Batch size 1\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass to get computation graph\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m output, mu, logvar, adj_now, adj_lag \u001b[38;5;241m=\u001b[39m model(X_dummy, time_context_dummy)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create visualization\u001b[39;00m\n\u001b[0;32m     23\u001b[0m dot \u001b[38;5;241m=\u001b[39m torchviz\u001b[38;5;241m.\u001b[39mmake_dot(output[\u001b[38;5;241m0\u001b[39m], params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters()))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:50\u001b[0m, in \u001b[0;36mCausalGraphVAE.forward\u001b[1;34m(self, X, time_context)\u001b[0m\n\u001b[0;32m     47\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert input X to float32\u001b[39;00m\n\u001b[0;32m     48\u001b[0m time_context \u001b[38;5;241m=\u001b[39m time_context\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert time context to float32\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m mu, logvar, adj_now, adj_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(X, time_context)\n\u001b[0;32m     51\u001b[0m Z \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(logvar) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m logvar)\n\u001b[0;32m     52\u001b[0m recon_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(Z, adj_now, adj_lag)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:37\u001b[0m, in \u001b[0;36mCausalGraphVAE.encode\u001b[1;34m(self, X, time_context)\u001b[0m\n\u001b[0;32m     35\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_layer(X_enc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogvar_layer(X_enc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     36\u001b[0m Z \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(logvar) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m logvar)\n\u001b[1;32m---> 37\u001b[0m adj_now, adj_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcausal_graph(X, time_context,Z)  \u001b[38;5;66;03m# Use temporal causal graph\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, logvar, adj_now, adj_lag\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\components.py:116\u001b[0m, in \u001b[0;36mTemporalCausalGraph.forward\u001b[1;34m(self, X, time_context, Z)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    112\u001b[0m         lag_mats\u001b[38;5;241m.\u001b[39mappend( replace_zero(\n\u001b[0;32m    113\u001b[0m             hard_concrete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_score_now \u001b[38;5;241m*\u001b[39m weights_schedule[i]\n\u001b[0;32m    114\u001b[0m                                 )\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m    115\u001b[0m                                       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_adj )\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m--> 116\u001b[0m             \u001b[38;5;241m+\u001b[39m (hard_concrete(torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbk,bj->kj\u001b[39m\u001b[38;5;124m'\u001b[39m, x[i,:,:], x[i,:,:]) \u001b[38;5;241m*\u001b[39m weights_schedule[i]\n\u001b[0;32m    117\u001b[0m                                    ))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    118\u001b[0m                                      ,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfill_diagonal_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         lag_mats\u001b[38;5;241m.\u001b[39mappend(  replace_zero(\n\u001b[0;32m    121\u001b[0m             hard_concrete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_score_lag\u001b[38;5;241m*\u001b[39m weights_schedule[i]\n\u001b[0;32m    122\u001b[0m                                 )\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m                            ))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    126\u001b[0m                                      ,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfill_diagonal_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchviz\n",
    "from CARAT.model import CausalGraphVAE\n",
    "# Define model parameters (arbitrarily chosen for visualization)\n",
    "input_dim = 10\n",
    "hidden_dim = 32\n",
    "latent_dim = 8\n",
    "num_nodes = 10\n",
    "time_steps = 3\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = CausalGraphVAE(input_dim, hidden_dim, latent_dim, num_nodes, device, time_steps)\n",
    "\n",
    "# Generate dummy input data\n",
    "X_dummy = torch.randn(1, time_steps, input_dim)  # Batch size 1\n",
    "time_context_dummy = torch.arange(time_steps).float().unsqueeze(0)  # Batch size 1\n",
    "\n",
    "# Forward pass to get computation graph\n",
    "output, mu, logvar, adj_now, adj_lag = model(X_dummy, time_context_dummy)\n",
    "\n",
    "# Create visualization\n",
    "dot = torchviz.make_dot(output[0], params=dict(model.named_parameters()))\n",
    "\n",
    "# Display the graph\n",
    "dot.format = \"png\"\n",
    "dot.render(\"model_visualization\")\n",
    "from IPython.display import display\n",
    "display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe9c6336-02c9-47f4-9021-d68ca79ba92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\n",
      "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torchviz) (2.5.1+cu121)\n",
      "Requirement already satisfied: graphviz in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jlowh\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->torch->torchviz) (2.1.3)\n",
      "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: torchviz\n",
      "Successfully installed torchviz-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb9c39-253c-4306-bc7b-35b6d77bba79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
