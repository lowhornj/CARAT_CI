{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97d3321-4427-4837-8269-048dc64686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.distributions import Normal, Laplace, RelaxedOneHotCategorical\n",
    "from torchdiffeq import odeint  # For continuous-time normalizing flows\n",
    "\n",
    "from feature.scalers import ranged_scaler\n",
    "from feature.engineering import *\n",
    "from CARAT.model_utils import *\n",
    "from CARAT.model import CausalGraphVAE\n",
    "from CARAT.components import *\n",
    "from utils.utils import set_seed, logger\n",
    "\n",
    "# Torch settings\"\"\"\n",
    "\"\"\"torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.autograd.profiler.profile(enabled=False)\n",
    "torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "torch.autograd.set_detect_anomaly(mode=False)\n",
    "\n",
    "# Environment variables\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = '167772160'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\"\"\"\n",
    "# Set device\n",
    "device = torch.device('cpu')#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6981e0a1-e1c0-409d-ab6a-cf7d34bf1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 20)\n"
     ]
    }
   ],
   "source": [
    "cats_df = pl.read_csv(\"data/data.csv\", separator=\",\")  \n",
    "print(cats_df.shape)\n",
    "metadata = pl.read_csv('data/metadata.csv',separator=',')\n",
    "potential_causes = metadata['root_cause'].unique().to_list()\n",
    "\n",
    "for col in cats_df.columns:\n",
    "    unique_vals = cats_df[col].n_unique()\n",
    "    data_type = cats_df[col].dtype\n",
    "    bad_dtypes = [pl.Date,pl.Datetime,pl.Utf8]\n",
    "    if ((unique_vals >= 50) & (data_type not in bad_dtypes) ):\n",
    "        cats_df = cats_df.with_columns(ranged_scaler(cats_df[col]))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0f5a4d-1cf3-4a87-a3fb-751607296c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.with_columns(\n",
    "    pl.col('timestamp').str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    pl.Series(\"entity_id\",range(len(cats_df)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b9af15-9315-41d4-86fe-907430746a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_rows_list = metadata.rows(named=True)\n",
    "cats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52959448-4391-42ad-a59e-e0f732b1971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping column timestamp (not a float column)\n",
      "Column: aimp | Final ADF: -2211.6294 | p-value: 0.0000 | Diffs: 0\n",
      "Column: amud | Final ADF: -8.0091 | p-value: 0.0000 | Diffs: 0\n",
      "Column: arnd | Final ADF: -18.1248 | p-value: 0.0000 | Diffs: 0\n",
      "Column: asin1 | Final ADF: -5.7565 | p-value: 0.0000 | Diffs: 1\n",
      "Column: asin2 | Final ADF: -39.8976 | p-value: 0.0000 | Diffs: 3\n",
      "Column: adbr | Final ADF: -111.5305 | p-value: 0.0000 | Diffs: 0\n",
      "Column: adfl | Final ADF: -217.2031 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bed1 | Final ADF: -35.0214 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bed2 | Final ADF: -44.5328 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bfo1 | Final ADF: -8.5614 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bfo2 | Final ADF: -13.3015 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bso1 | Final ADF: -2164.1026 | p-value: 0.0000 | Diffs: 1\n",
      "Column: bso2 | Final ADF: -13.5707 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bso3 | Final ADF: -14.7270 | p-value: 0.0000 | Diffs: 0\n",
      "Column: ced1 | Final ADF: -727.3289 | p-value: 0.0000 | Diffs: 1\n",
      "Column: cfo1 | Final ADF: -6.7640 | p-value: 0.0000 | Diffs: 0\n",
      "Column: cso1 | Final ADF: -7.8526 | p-value: 0.0000 | Diffs: 0\n",
      "Column: y | Final ADF: -51.2989 | p-value: 0.0000 | Diffs: 0\n",
      "Column: category | Final ADF: -53.9463 | p-value: 0.0000 | Diffs: 0\n",
      "⚠️ Skipping column entity_id (not a float column)\n"
     ]
    }
   ],
   "source": [
    "cats_df = make_stationary(cats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b4cd0e-cacc-4d93-b0e9-a0cdca28b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e03dcda-4108-4fe2-9ec3-8ccbdeaf85f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['cso1']\", \"['cfo1']\", \"['ced1']\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['affected'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc297da3-97f8-4077-898e-cc23b8c2e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_causes = metadata['root_cause'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8be12f8-8ca1-49a7-81aa-5e05325023a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimp</th>\n",
       "      <th>amud</th>\n",
       "      <th>arnd</th>\n",
       "      <th>asin1</th>\n",
       "      <th>asin2</th>\n",
       "      <th>adbr</th>\n",
       "      <th>adfl</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>bfo1</th>\n",
       "      <th>bfo2</th>\n",
       "      <th>bso1</th>\n",
       "      <th>bso2</th>\n",
       "      <th>bso3</th>\n",
       "      <th>ced1</th>\n",
       "      <th>cfo1</th>\n",
       "      <th>cso1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.444480</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100401</td>\n",
       "      <td>-0.186461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.446078</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100408</td>\n",
       "      <td>-0.186406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.447166</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-8.000267e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100416</td>\n",
       "      <td>-0.186345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.442843</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100426</td>\n",
       "      <td>-0.186278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.441320</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-8.000045e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>-0.186205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aimp      amud      arnd    asin1         asin2  adbr  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:06   0.0  0.142857 -0.444480  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:07   0.0  0.142857 -0.446078  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:08   0.0  0.142857 -0.447166  0.00002 -8.000267e-12   0.0   \n",
       "2023-01-01 00:00:09   0.0  0.142857 -0.442843  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:10   0.0  0.142857 -0.441320  0.00002 -8.000045e-12   0.0   \n",
       "\n",
       "                     adfl     bed1      bed2      bfo1      bfo2      bso1  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:06   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000072   \n",
       "2023-01-01 00:00:07   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000083   \n",
       "2023-01-01 00:00:08   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000094   \n",
       "2023-01-01 00:00:09   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000104   \n",
       "2023-01-01 00:00:10   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000113   \n",
       "\n",
       "                         bso2      bso3  ced1      cfo1      cso1  \n",
       "timestamp                                                          \n",
       "2023-01-01 00:00:06 -0.507953 -0.716059   0.0  0.100401 -0.186461  \n",
       "2023-01-01 00:00:07 -0.507953 -0.716059   0.0  0.100408 -0.186406  \n",
       "2023-01-01 00:00:08 -0.507953 -0.716059   0.0  0.100416 -0.186345  \n",
       "2023-01-01 00:00:09 -0.507953 -0.716059   0.0  0.100426 -0.186278  \n",
       "2023-01-01 00:00:10 -0.507953 -0.716059   0.0  0.100438 -0.186205  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_df=cats_df.set_index('timestamp')\n",
    "cats_df = cats_df.drop(['y','category','entity_id'],axis=1)\n",
    "cats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c816fec8-c143-4f7e-a78c-1b1b18f32a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999994, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b15ba7-0bab-44e8-95aa-c6b534da9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = cats_df[0:1000000]\n",
    "test_df = cats_df[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7eaa704-a473-421e-acaf-0aff6efe4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab4ff270-6892-43e6-8571-b623acdd105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = train_df.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "try:\n",
    "    test_df = test_df.drop('time',axis=1)\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc22130-f5dd-4ef8-8d1b-e29c4f26b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(test_df.columns)\n",
    "non_causal_columns = list(set(cols).difference(set(potential_causes)))\n",
    "causal_indices = [train_df.columns.get_loc(col) for col in potential_causes]\n",
    "non_causal_indices = [train_df.columns.get_loc(col) for col in non_causal_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebb432e-a758-4045-ad93-c5ad7cb19bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining on nominal data...\n",
      "Epoch 1: Loss = 20710.2357\n",
      "Recon Loss =4991.9517, KL Loss = 2.2728, Sparsity Loss = 102.5059, Lagrangian Loss = 2.6903\n",
      "Epoch 51: Loss = 276.7871\n",
      "Recon Loss =361.1690, KL Loss = 4.3299, Sparsity Loss = 62.7255, Lagrangian Loss = 1.6437\n",
      "Early stopping triggered. Last Epoch: 91\n",
      "Recon Loss =201.5016, KL Loss = 4.4729, Sparsity Loss = 61.2792, Lagrangian Loss = 3.0696\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 3\n",
    "BATCH_SIZE = 10000\n",
    "hidden_dim = 64\n",
    "latent_dim = 8\n",
    "num_nodes = 17\n",
    "\n",
    "dataset_nominal = TimeSeriesDataset(train_df, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = CausalGraphVAE(input_dim=train_df.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=train_df.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=None)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "# Train on nominal data\n",
    "print(\"Pretraining on nominal data...\")\n",
    "model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=30,rho_max=5,alpha_max=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d35de27-37ce-4711-9b1f-c052549cdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "#scaled_prior = scale_tensor(prior_adj)\n",
    "for i, row in enumerate(prior_adj):\n",
    "    for j, column in enumerate(row):\n",
    "        if (j in non_causal_indices) and (i in causal_indices) & (i!=j):\n",
    "            continue\n",
    "        else:\n",
    "            prior_adj[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1969b33-7fd1-471c-b21a-3b6c42c157ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimp</th>\n",
       "      <th>amud</th>\n",
       "      <th>arnd</th>\n",
       "      <th>asin1</th>\n",
       "      <th>asin2</th>\n",
       "      <th>adbr</th>\n",
       "      <th>adfl</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>bfo1</th>\n",
       "      <th>bfo2</th>\n",
       "      <th>bso1</th>\n",
       "      <th>bso2</th>\n",
       "      <th>bso3</th>\n",
       "      <th>ced1</th>\n",
       "      <th>cfo1</th>\n",
       "      <th>cso1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aimp</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amud</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arnd</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adbr</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adfl</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed1</th>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed2</th>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.501146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfo1</th>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58379</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.582570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfo2</th>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.586276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bso1</th>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bso2</th>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.585069</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.582570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bso3</th>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.501616</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ced1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfo1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cso1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aimp     amud      arnd    asin1    asin2      adbr     adfl  bed1  \\\n",
       "aimp   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "amud   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "arnd   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "asin1  0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "asin2  0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "adbr   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "adfl   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "bed1   0.58257  0.58257  0.500250  0.50025  0.50025  0.500250  0.58257   0.0   \n",
       "bed2   0.58257  0.58257  0.500250  0.50025  0.50025  0.500250  0.58257   0.0   \n",
       "bfo1   0.50025  0.50025  0.582570  0.58257  0.58257  0.582570  0.50025   0.0   \n",
       "bfo2   0.50025  0.50025  0.582570  0.58257  0.58257  0.582570  0.50025   0.0   \n",
       "bso1   0.58257  0.58257  0.500250  0.50025  0.50025  0.500250  0.58257   0.0   \n",
       "bso2   0.50025  0.50025  0.582570  0.58257  0.58257  0.585069  0.50025   0.0   \n",
       "bso3   0.58257  0.58257  0.501616  0.50025  0.50025  0.500250  0.58257   0.0   \n",
       "ced1   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "cfo1   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "cso1   0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.00000   0.0   \n",
       "\n",
       "       bed2  bfo1  bfo2  bso1  bso2  bso3     ced1     cfo1      cso1  \n",
       "aimp    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "amud    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "arnd    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "asin1   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "asin2   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "adbr    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "adfl    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "bed1    0.0   0.0   0.0   0.0   0.0   0.0  0.50025  0.50025  0.500250  \n",
       "bed2    0.0   0.0   0.0   0.0   0.0   0.0  0.50025  0.50025  0.501146  \n",
       "bfo1    0.0   0.0   0.0   0.0   0.0   0.0  0.58379  0.58257  0.582570  \n",
       "bfo2    0.0   0.0   0.0   0.0   0.0   0.0  0.58257  0.58257  0.586276  \n",
       "bso1    0.0   0.0   0.0   0.0   0.0   0.0  0.50025  0.50025  0.500250  \n",
       "bso2    0.0   0.0   0.0   0.0   0.0   0.0  0.58257  0.58257  0.582570  \n",
       "bso3    0.0   0.0   0.0   0.0   0.0   0.0  0.50025  0.50025  0.500250  \n",
       "ced1    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "cfo1    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  \n",
       "cso1    0.0   0.0   0.0   0.0   0.0   0.0  0.00000  0.00000  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prior_adj.cpu().detach().numpy(),index=cols,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c7d362f-6a8a-4a3c-b03f-3839ca30f4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 22:55:28,225 INFO -- Model: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [3, 64] but got: [2, 64].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m fine_tuned \u001b[38;5;241m=\u001b[39m CausalGraphVAE(input_dim\u001b[38;5;241m=\u001b[39mnum_nodes, hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[0;32m     55\u001b[0m                        latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim, num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes,device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     56\u001b[0m                        time_steps\u001b[38;5;241m=\u001b[39mTIME_STEPS,prior_adj\u001b[38;5;241m=\u001b[39mprior_adj)\n\u001b[0;32m     57\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(fine_tuned\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)  \u001b[38;5;66;03m# L2 Regularization\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m fine_tuned\u001b[38;5;241m.\u001b[39mtrain_model(dataloader, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,BATCH_SIZE\u001b[38;5;241m=\u001b[39mBATCH_SIZE,rho_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m,alpha_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m)\n\u001b[0;32m     62\u001b[0m causes \u001b[38;5;241m=\u001b[39m fine_tuned\u001b[38;5;241m.\u001b[39minfer_causal_effect(X_data\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device),T_data\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device),anomaly,cols,non_causal_indices\u001b[38;5;241m=\u001b[39mnon_causal_indices)\n\u001b[0;32m     64\u001b[0m causes \u001b[38;5;241m=\u001b[39m causes\u001b[38;5;241m.\u001b[39mfilter(items\u001b[38;5;241m=\u001b[39mpotential_causes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:191\u001b[0m, in \u001b[0;36mCausalGraphVAE.train_model\u001b[1;34m(self, dataloader, optimizer, num_epochs, patience, BATCH_SIZE, rho_max, alpha_max)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 191\u001b[0m recon_X, mu, logvar, adj_now, adj_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_batch, time_batch)\n\u001b[0;32m    192\u001b[0m recon_loss , kl_loss , sparsity_loss , lagrangian_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(recon_X, X_batch, mu, logvar, adj_now, \n\u001b[0;32m    193\u001b[0m                                                                             adj_lag, epoch, num_epochs,rho_max,alpha_max)\n\u001b[0;32m    194\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m kl_loss \u001b[38;5;241m+\u001b[39m sparsity_loss \u001b[38;5;241m+\u001b[39m lagrangian_loss \n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:50\u001b[0m, in \u001b[0;36mCausalGraphVAE.forward\u001b[1;34m(self, X, time_context)\u001b[0m\n\u001b[0;32m     47\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert input X to float32\u001b[39;00m\n\u001b[0;32m     48\u001b[0m time_context \u001b[38;5;241m=\u001b[39m time_context\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert time context to float32\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m mu, logvar, adj_now, adj_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(X, time_context)\n\u001b[0;32m     51\u001b[0m Z \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(logvar) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m logvar)\n\u001b[0;32m     52\u001b[0m recon_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(Z, adj_now, adj_lag)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:37\u001b[0m, in \u001b[0;36mCausalGraphVAE.encode\u001b[1;34m(self, X, time_context)\u001b[0m\n\u001b[0;32m     35\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_layer(X_enc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogvar_layer(X_enc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     36\u001b[0m Z \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(logvar) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m logvar)\n\u001b[1;32m---> 37\u001b[0m adj_now, adj_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcausal_graph(X, time_context,Z)  \u001b[38;5;66;03m# Use temporal causal graph\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, logvar, adj_now, adj_lag\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\components.py:104\u001b[0m, in \u001b[0;36mTemporalCausalGraph.forward\u001b[1;34m(self, X, time_context, Z)\u001b[0m\n\u001b[0;32m    100\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding(pos_indices)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m    102\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention(X_permuted \u001b[38;5;241m+\u001b[39m pos_embedding)\n\u001b[1;32m--> 104\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_layer(X_transformed, hidden)\n\u001b[0;32m    106\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_projection2(attn_output)\n\u001b[0;32m    108\u001b[0m weights_schedule \u001b[38;5;241m=\u001b[39m generate_decreasing_weights(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_steps,start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\components.py:85\u001b[0m, in \u001b[0;36mTemporalCausalGraph.attention_layer\u001b[1;34m(self, transformer_out, final_hidden)\u001b[0m\n\u001b[0;32m     82\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_v(transformer_out)  \u001b[38;5;66;03m# [batch_size, time_steps, hidden_dim]\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Compute attention scores\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(Q, K\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# [batch_size, 1, time_steps]\u001b[39;00m\n\u001b[0;32m     86\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(attn_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, 1, time_steps]\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Compute weighted sum of values\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [3, 64] but got: [2, 64]."
     ]
    }
   ],
   "source": [
    "cols = list(test_df.columns)\n",
    "non_causal_columns = list(set(cols).difference(set(potential_causes)))\n",
    "causal_indices = [train_df.columns.get_loc(col) for col in potential_causes]\n",
    "non_causal_indices = [train_df.columns.get_loc(col) for col in non_causal_columns]\n",
    "num_nodes = len(train_df.columns)\n",
    "\n",
    "new_metadata = []\n",
    "BATCH_SIZE = 64\n",
    "hidden_dim=64\n",
    "latent_dim=8\n",
    "\n",
    "set_seed()\n",
    "edge_correct = 0\n",
    "instantaneous_correct = 0\n",
    "lagged_correct = 0\n",
    "counterfactual_correct = 0 \n",
    "rr_correct = 0\n",
    "total_correct = 0\n",
    "total_checked = 0\n",
    "incorrect = []\n",
    "\n",
    "for i, row in enumerate(cats_rows_list):\n",
    "    total_checked +=1 \n",
    "    logger.info('Model: '+ str(i))\n",
    "    anomaly = eval(row['affected'])[0]\n",
    "    print('Anomaly: ' + anomaly)\n",
    "    anomaly_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    #start_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = datetime.strptime(row['end_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    root_cause = row['root_cause']\n",
    "    #start_len = mod_df.shape[0]\n",
    "    #if start_len >1000:\n",
    "        #start_len = 1000\n",
    "    start_len = 50\n",
    "    start_time = anomaly_time- timedelta(seconds=start_len)\n",
    "    finish_time = end_time + timedelta(seconds=start_len)\n",
    "    mod_df = test_df[(test_df.index>= start_time) & (test_df.index<= finish_time)]\n",
    "    mod_df = mod_df[['aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl', 'bed1',\n",
    "       'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3', 'ced1', 'cfo1', 'cso1']]\n",
    "\n",
    "    \"\"\"\n",
    "    FIND THE OPTIMAL NUMBER OF LAGS\n",
    "    \"\"\"\n",
    "    TIME_STEPS = most_frequent(find_optimal_lags_for_dataframe(mod_df))+1\n",
    "\n",
    "    dataset = TimeSeriesDataset(mod_df,device=device, time_steps=TIME_STEPS)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    X_data = torch.empty(0,device=device)\n",
    "    T_data = torch.empty(0,device=device)\n",
    "    for batch_idx, (X_batch, time_batch) in enumerate(dataloader):\n",
    "        X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "        T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "    \n",
    "    fine_tuned = CausalGraphVAE(input_dim=num_nodes, hidden_dim=hidden_dim,\n",
    "                           latent_dim=latent_dim, num_nodes=num_nodes,device=device,\n",
    "                           time_steps=TIME_STEPS,prior_adj=prior_adj)\n",
    "    optimizer = torch.optim.AdamW(fine_tuned.parameters(), lr=0.01, weight_decay=1e-5)  # L2 Regularization\n",
    "\n",
    "    \n",
    "    fine_tuned.train_model(dataloader, optimizer, num_epochs=2500, patience=50,BATCH_SIZE=BATCH_SIZE,rho_max=5.0,alpha_max=2.5)\n",
    "\n",
    "    causes = fine_tuned.infer_causal_effect(X_data.to(torch.float32).to(device),T_data.to(torch.float32).to(device),anomaly,cols,non_causal_indices=non_causal_indices)\n",
    "    \n",
    "    causes = causes.filter(items=potential_causes, axis=0)\n",
    "    edge_cause_1 = causes.sort_values(by='causes',ascending=False)[0:3].index[0]\n",
    "    edge_cause_2 = causes.sort_values(by='causes',ascending=False)[0:3].index[1]\n",
    "    edge_cause_3 = causes.sort_values(by='causes',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    instant_cause_1 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[0]\n",
    "    instant_cause_2 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[1]\n",
    "    instant_cause_3 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    lag_cause_1 = causes.sort_values(by='lagged',ascending=False)[0:3].index[0]\n",
    "    lag_cause_2 = causes.sort_values(by='lagged',ascending=False)[0:3].index[1]\n",
    "    lag_cause_3 = causes.sort_values(by='lagged',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    counterfactual_cause_1 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[0]\n",
    "    counterfactual_cause_2 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[1]\n",
    "    counterfactual_cause_3 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[2]\n",
    "\n",
    "    rr_cause_1 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[0]\n",
    "    rr_cause_2 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[1]\n",
    "    rr_cause_3 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    total_score_cause_1=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[0]\n",
    "    total_score_cause_2=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[1]\n",
    "    total_score_cause_3=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_1'] = 1\n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_2'] = 1\n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == counterfactual_cause_1:\n",
    "        row['counterfactual_cause_1'] = 1\n",
    "    if root_cause == counterfactual_cause_2:\n",
    "        row['counterfactual_cause_2'] = 1\n",
    "    if root_cause == counterfactual_cause_3:\n",
    "        row['counterfactual_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == total_score_cause_1:\n",
    "        row['total_score_cause_1'] = 1\n",
    "    if root_cause == total_score_cause_2:\n",
    "        row['total_score_cause_2'] = 1\n",
    "    if root_cause == total_score_cause_3:\n",
    "        row['total_score_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == instant_cause_1:\n",
    "        row['instant_cause_1'] = 1\n",
    "    if root_cause == instant_cause_2:\n",
    "        row['instant_cause_2'] = 1\n",
    "    if root_cause == instant_cause_3:\n",
    "        row['instant_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == lag_cause_1:\n",
    "        row['lag_cause_1'] = 1\n",
    "    if root_cause == lag_cause_2:\n",
    "        row['lag_cause_2'] = 1\n",
    "    if root_cause == lag_cause_3:\n",
    "        row['lag_cause_3'] = 1\n",
    "\n",
    "    if root_cause == rr_cause_1:\n",
    "        row['rr_cause_1'] = 1\n",
    "    if root_cause == rr_cause_2:\n",
    "        row['rr_cause_2'] = 1\n",
    "    if root_cause == rr_cause_3:\n",
    "        row['rr_cause_3'] = 1\n",
    "    \n",
    "    new_metadata.append(row)\n",
    "    \n",
    "    if root_cause in [total_score_cause_1 , total_score_cause_2 , total_score_cause_3]:\n",
    "        total_correct+=1\n",
    "    if root_cause in [edge_cause_1 , edge_cause_2 , edge_cause_3]:\n",
    "        edge_correct+=1\n",
    "    if root_cause in [counterfactual_cause_1 , counterfactual_cause_2 , counterfactual_cause_3]:\n",
    "        counterfactual_correct+=1\n",
    "    if root_cause in [instant_cause_1 , instant_cause_2 , instant_cause_3]:\n",
    "        instantaneous_correct+=1\n",
    "    if root_cause in [lag_cause_1 , lag_cause_2 , lag_cause_3]:\n",
    "        lagged_correct+=1\n",
    "    if root_cause in [rr_cause_1 , rr_cause_2 , rr_cause_3]:\n",
    "        rr_correct+=1\n",
    "    \n",
    "    total_accuracy = total_correct/total_checked* 100\n",
    "    edge_accuracy = edge_correct/total_checked* 100\n",
    "    cf_accuracy = counterfactual_correct/total_checked* 100\n",
    "    instant_accuracy = instantaneous_correct/total_checked* 100\n",
    "    lag_accuracy = lagged_correct/total_checked* 100\n",
    "    rr_accuracy = rr_correct/total_checked* 100\n",
    "    \n",
    "    if root_cause not in [total_score_cause_1 , total_score_cause_2 , total_score_cause_3,edge_cause_1 , edge_cause_2 , edge_cause_3 ]:\n",
    "        incorrect.append(i) \n",
    "    logger.info(f\"Edge Accuracy = {edge_accuracy:.2f}, Instantaneous Accuracy = {instant_accuracy:.2f}, Lagged Accuracy = {lag_accuracy:.2f}, Counterfactual Accuracy = {cf_accuracy:.2f},  Blended Accuracy = {total_accuracy:.2f},  RR Accuracy = {rr_accuracy:.2f}  \") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3a638-f7c1-4ba2-ba66-380c14575be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
