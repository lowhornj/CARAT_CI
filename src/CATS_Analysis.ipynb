{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97d3321-4427-4837-8269-048dc64686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.distributions import Normal, Laplace, RelaxedOneHotCategorical\n",
    "from torchdiffeq import odeint  # For continuous-time normalizing flows\n",
    "\n",
    "from feature.scalers import ranged_scaler\n",
    "from feature.engineering import *\n",
    "from CARAT.model_utils import *\n",
    "from CARAT.model import CausalGraphVAE\n",
    "from CARAT.components import *\n",
    "from utils.utils import set_seed, logger\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define the seed value\n",
    "seed = 42\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for CUDA (if using GPUs)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "# Set seed for Python's random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior for PyTorch operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Set device\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set device\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6981e0a1-e1c0-409d-ab6a-cf7d34bf1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 20)\n"
     ]
    }
   ],
   "source": [
    "cats_df = pl.read_csv(\"data/data.csv\", separator=\",\")  \n",
    "print(cats_df.shape)\n",
    "metadata = pl.read_csv('data/metadata.csv',separator=',')\n",
    "potential_causes = metadata['root_cause'].unique().to_list()\n",
    "\n",
    "for col in cats_df.columns:\n",
    "    unique_vals = cats_df[col].n_unique()\n",
    "    data_type = cats_df[col].dtype\n",
    "    bad_dtypes = [pl.Date,pl.Datetime,pl.Utf8]\n",
    "    if ((unique_vals >= 50) & (data_type not in bad_dtypes) ):\n",
    "        cats_df = cats_df.with_columns(ranged_scaler(cats_df[col]))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0f5a4d-1cf3-4a87-a3fb-751607296c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.with_columns(\n",
    "    pl.col('timestamp').str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    pl.Series(\"entity_id\",range(len(cats_df)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b9af15-9315-41d4-86fe-907430746a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_rows_list = metadata.rows(named=True)\n",
    "cats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52959448-4391-42ad-a59e-e0f732b1971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping column timestamp (not a float column)\n",
      "Column: aimp | Final ADF: -2211.6294 | p-value: 0.0000 | Diffs: 0\n",
      "Column: amud | Final ADF: -8.0091 | p-value: 0.0000 | Diffs: 0\n",
      "Column: arnd | Final ADF: -18.1248 | p-value: 0.0000 | Diffs: 0\n",
      "Column: asin1 | Final ADF: -5.7565 | p-value: 0.0000 | Diffs: 1\n",
      "Column: asin2 | Final ADF: -39.8976 | p-value: 0.0000 | Diffs: 3\n",
      "Column: adbr | Final ADF: -111.5305 | p-value: 0.0000 | Diffs: 0\n",
      "Column: adfl | Final ADF: -217.2031 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bed1 | Final ADF: -35.0214 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bed2 | Final ADF: -44.5328 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bfo1 | Final ADF: -8.5614 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bfo2 | Final ADF: -13.3015 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bso1 | Final ADF: -2164.1026 | p-value: 0.0000 | Diffs: 1\n",
      "Column: bso2 | Final ADF: -13.5707 | p-value: 0.0000 | Diffs: 0\n",
      "Column: bso3 | Final ADF: -14.7270 | p-value: 0.0000 | Diffs: 0\n",
      "Column: ced1 | Final ADF: -727.3289 | p-value: 0.0000 | Diffs: 1\n",
      "Column: cfo1 | Final ADF: -6.7640 | p-value: 0.0000 | Diffs: 0\n",
      "Column: cso1 | Final ADF: -7.8526 | p-value: 0.0000 | Diffs: 0\n",
      "Column: y | Final ADF: -51.2989 | p-value: 0.0000 | Diffs: 0\n",
      "Column: category | Final ADF: -53.9463 | p-value: 0.0000 | Diffs: 0\n",
      "⚠️ Skipping column entity_id (not a float column)\n"
     ]
    }
   ],
   "source": [
    "cats_df = make_stationary(cats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b4cd0e-cacc-4d93-b0e9-a0cdca28b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e03dcda-4108-4fe2-9ec3-8ccbdeaf85f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['cso1']\", \"['ced1']\", \"['cfo1']\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['affected'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc297da3-97f8-4077-898e-cc23b8c2e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_causes = metadata['root_cause'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8be12f8-8ca1-49a7-81aa-5e05325023a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimp</th>\n",
       "      <th>amud</th>\n",
       "      <th>arnd</th>\n",
       "      <th>asin1</th>\n",
       "      <th>asin2</th>\n",
       "      <th>adbr</th>\n",
       "      <th>adfl</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>bfo1</th>\n",
       "      <th>bfo2</th>\n",
       "      <th>bso1</th>\n",
       "      <th>bso2</th>\n",
       "      <th>bso3</th>\n",
       "      <th>ced1</th>\n",
       "      <th>cfo1</th>\n",
       "      <th>cso1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.444480</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100401</td>\n",
       "      <td>-0.186461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.446078</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100408</td>\n",
       "      <td>-0.186406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.447166</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-8.000267e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100416</td>\n",
       "      <td>-0.186345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.442843</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-7.999823e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100426</td>\n",
       "      <td>-0.186278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.441320</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-8.000045e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.32802</td>\n",
       "      <td>-0.369237</td>\n",
       "      <td>-0.738163</td>\n",
       "      <td>-0.767181</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.507953</td>\n",
       "      <td>-0.716059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>-0.186205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aimp      amud      arnd    asin1         asin2  adbr  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:06   0.0  0.142857 -0.444480  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:07   0.0  0.142857 -0.446078  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:08   0.0  0.142857 -0.447166  0.00002 -8.000267e-12   0.0   \n",
       "2023-01-01 00:00:09   0.0  0.142857 -0.442843  0.00002 -7.999823e-12   0.0   \n",
       "2023-01-01 00:00:10   0.0  0.142857 -0.441320  0.00002 -8.000045e-12   0.0   \n",
       "\n",
       "                     adfl     bed1      bed2      bfo1      bfo2      bso1  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:06   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000072   \n",
       "2023-01-01 00:00:07   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000083   \n",
       "2023-01-01 00:00:08   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000094   \n",
       "2023-01-01 00:00:09   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000104   \n",
       "2023-01-01 00:00:10   0.0 -0.32802 -0.369237 -0.738163 -0.767181  0.000113   \n",
       "\n",
       "                         bso2      bso3  ced1      cfo1      cso1  \n",
       "timestamp                                                          \n",
       "2023-01-01 00:00:06 -0.507953 -0.716059   0.0  0.100401 -0.186461  \n",
       "2023-01-01 00:00:07 -0.507953 -0.716059   0.0  0.100408 -0.186406  \n",
       "2023-01-01 00:00:08 -0.507953 -0.716059   0.0  0.100416 -0.186345  \n",
       "2023-01-01 00:00:09 -0.507953 -0.716059   0.0  0.100426 -0.186278  \n",
       "2023-01-01 00:00:10 -0.507953 -0.716059   0.0  0.100438 -0.186205  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_df=cats_df.set_index('timestamp')\n",
    "cats_df = cats_df.drop(['y','category','entity_id'],axis=1)\n",
    "cats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c816fec8-c143-4f7e-a78c-1b1b18f32a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999994, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b15ba7-0bab-44e8-95aa-c6b534da9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = cats_df[0:1000000]\n",
    "test_df = cats_df[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7eaa704-a473-421e-acaf-0aff6efe4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab4ff270-6892-43e6-8571-b623acdd105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = train_df.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "try:\n",
    "    test_df = test_df.drop('time',axis=1)\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc22130-f5dd-4ef8-8d1b-e29c4f26b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(test_df.columns)\n",
    "non_causal_columns = list(set(cols).difference(set(potential_causes)))\n",
    "causal_indices = [train_df.columns.get_loc(col) for col in potential_causes]\n",
    "non_causal_indices = [train_df.columns.get_loc(col) for col in non_causal_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3198cc09-56e4-4f5b-8f20-aea6df75647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define the seed value\n",
    "seed = 42\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for CUDA (if using GPUs)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "# Set seed for Python's random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior for PyTorch operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb432e-a758-4045-ad93-c5ad7cb19bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining on nominal data...\n",
      "Epoch 1: Loss = 464.1137\n",
      "Recon Loss = 4.6111, KL Loss = 0.0000, Lagrangian Loss = 7.6478\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 15\n",
    "BATCH_SIZE = 128\n",
    "hidden_dim = 64\n",
    "latent_dim = 16\n",
    "num_nodes = 17\n",
    "\n",
    "dataset_nominal = TimeSeriesDataset(train_df, device=device, time_steps=TIME_STEPS)\n",
    "dataloader_nominal = DataLoader(dataset_nominal, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = CausalGraphVAE(input_dim=train_df.shape[1], hidden_dim=hidden_dim,\n",
    "                        latent_dim=latent_dim, num_nodes=train_df.shape[1],device=device,\n",
    "                        time_steps=TIME_STEPS, prior_adj=None,instantaneous_weight=0.4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Train on nominal data\n",
    "print(\"Pretraining on nominal data...\")\n",
    "model.train_model(dataloader_nominal, optimizer, num_epochs=250, patience=25,rho_max=3,alpha_max=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62199d32-95e0-464f-8a31-d074cc60fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "prior_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35de27-37ce-4711-9b1f-c052549cdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_adj = model.causal_graph.adj_mat.clone().detach()\n",
    "#scaled_prior = scale_tensor(prior_adj)\n",
    "for i, row in enumerate(prior_adj):\n",
    "    for j, column in enumerate(row):\n",
    "        if (j in non_causal_indices) and (i in causal_indices) & (i!=j):\n",
    "            continue\n",
    "        else:\n",
    "            prior_adj[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1969b33-7fd1-471c-b21a-3b6c42c157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(prior_adj.cpu().detach().numpy(),index=cols,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c7d362f-6a8a-4a3c-b03f-3839ca30f4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 08:00:43,227 INFO -- Model: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2142.1821\n",
      "Recon Loss = 1544.6382, KL Loss = 0.2464, Lagrangian Loss = 55.2770\n",
      "Epoch 51: Loss = 130.2133\n",
      "Recon Loss = 119.9956, KL Loss = 3.2680, Lagrangian Loss = 25.0616\n",
      "Epoch 101: Loss = 79.3184\n",
      "Recon Loss = 59.6290, KL Loss = 4.0164, Lagrangian Loss = 27.5530\n",
      "Epoch 151: Loss = 60.5041\n",
      "Recon Loss = 38.3329, KL Loss = 3.1908, Lagrangian Loss = 22.2487\n",
      "Epoch 201: Loss = 50.5777\n",
      "Recon Loss = 24.8533, KL Loss = 2.2769, Lagrangian Loss = 22.8569\n",
      "Epoch 251: Loss = 45.0816\n",
      "Recon Loss = 28.9451, KL Loss = 1.7998, Lagrangian Loss = 18.6154\n",
      "Epoch 301: Loss = 40.2754\n",
      "Recon Loss = 19.5170, KL Loss = 1.5060, Lagrangian Loss = 22.2257\n",
      "Epoch 351: Loss = 37.8796\n",
      "Recon Loss = 20.6481, KL Loss = 1.3024, Lagrangian Loss = 17.6442\n",
      "Epoch 401: Loss = 36.2191\n",
      "Recon Loss = 19.5806, KL Loss = 1.1504, Lagrangian Loss = 21.2405\n",
      "Epoch 451: Loss = 33.7137\n",
      "Recon Loss = 12.3846, KL Loss = 0.9730, Lagrangian Loss = 23.6803\n",
      "Early stopping triggered. Last Epoch: 456\n",
      "Recon Loss = 16.0156, KL Loss = 0.9071, Lagrangian Loss = 20.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 08:05:07,049 INFO -- Edge Accuracy = 100.00, Instantaneous Accuracy = 100.00, Lagged Accuracy = 0.00, Counterfactual Accuracy = 100.00,  Blended Accuracy = 100.00,  RR Accuracy = 100.00  \n",
      "2025-03-22 08:05:07,049 INFO -- Model: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 1039.7863\n",
      "Recon Loss = 481.7098, KL Loss = 1.8107, Lagrangian Loss = 45.2394\n",
      "Epoch 51: Loss = 43.1230\n",
      "Recon Loss = 17.1533, KL Loss = 1.2755, Lagrangian Loss = 23.7621\n",
      "Epoch 101: Loss = 24.8164\n",
      "Recon Loss = 5.3089, KL Loss = 0.2146, Lagrangian Loss = 20.5569\n",
      "Epoch 151: Loss = 20.1579\n",
      "Recon Loss = 2.6493, KL Loss = 0.0200, Lagrangian Loss = 18.5106\n",
      "Epoch 201: Loss = 18.1645\n",
      "Recon Loss = 1.8682, KL Loss = 0.0041, Lagrangian Loss = 16.5201\n",
      "Epoch 251: Loss = 16.4155\n",
      "Recon Loss = 1.6047, KL Loss = 0.0030, Lagrangian Loss = 18.5408\n",
      "Epoch 301: Loss = 14.9906\n",
      "Recon Loss = 1.2692, KL Loss = 0.0016, Lagrangian Loss = 13.8823\n",
      "Epoch 351: Loss = 14.0798\n",
      "Recon Loss = 1.2982, KL Loss = 0.0015, Lagrangian Loss = 10.0376\n",
      "Epoch 401: Loss = 12.6232\n",
      "Recon Loss = 1.5564, KL Loss = 0.0011, Lagrangian Loss = 10.9975\n",
      "Epoch 451: Loss = 11.6980\n",
      "Recon Loss = 0.8322, KL Loss = 0.0009, Lagrangian Loss = 10.5723\n",
      "Epoch 501: Loss = 10.9358\n",
      "Recon Loss = 0.8328, KL Loss = 0.0007, Lagrangian Loss = 8.3105\n",
      "Epoch 551: Loss = 10.3109\n",
      "Recon Loss = 0.9097, KL Loss = 0.0007, Lagrangian Loss = 10.5695\n",
      "Early stopping triggered. Last Epoch: 572\n",
      "Recon Loss = 1.0928, KL Loss = 0.0005, Lagrangian Loss = 9.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 09:42:08,854 INFO -- Edge Accuracy = 50.00, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 50.00,  RR Accuracy = 100.00  \n",
      "2025-03-22 09:42:08,854 INFO -- Model: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 2356.4095\n",
      "Recon Loss = 1089.8937, KL Loss = 0.5840, Lagrangian Loss = 42.1051\n",
      "Epoch 51: Loss = 112.0273\n",
      "Recon Loss = 89.0499, KL Loss = 4.6190, Lagrangian Loss = 25.9685\n",
      "Epoch 101: Loss = 71.7323\n",
      "Recon Loss = 46.5200, KL Loss = 2.7826, Lagrangian Loss = 27.3898\n",
      "Epoch 151: Loss = 54.7987\n",
      "Recon Loss = 26.7398, KL Loss = 1.8484, Lagrangian Loss = 21.8077\n",
      "Epoch 201: Loss = 47.1151\n",
      "Recon Loss = 25.2725, KL Loss = 1.4056, Lagrangian Loss = 29.3979\n",
      "Epoch 251: Loss = 40.5233\n",
      "Recon Loss = 18.3756, KL Loss = 1.1220, Lagrangian Loss = 24.0575\n",
      "Epoch 301: Loss = 35.2169\n",
      "Recon Loss = 13.1081, KL Loss = 0.9948, Lagrangian Loss = 21.0708\n",
      "Epoch 351: Loss = 30.1611\n",
      "Recon Loss = 8.7911, KL Loss = 0.8406, Lagrangian Loss = 23.6764\n",
      "Epoch 401: Loss = 28.5769\n",
      "Recon Loss = 8.9360, KL Loss = 0.6667, Lagrangian Loss = 20.2060\n",
      "Early stopping triggered. Last Epoch: 418\n",
      "Recon Loss = 6.5947, KL Loss = 0.5889, Lagrangian Loss = 21.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 09:49:58,657 INFO -- Edge Accuracy = 66.67, Instantaneous Accuracy = 66.67, Lagged Accuracy = 33.33, Counterfactual Accuracy = 33.33,  Blended Accuracy = 66.67,  RR Accuracy = 66.67  \n",
      "2025-03-22 09:49:58,658 INFO -- Model: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 2141.3139\n",
      "Recon Loss = 1876.4163, KL Loss = 0.1801, Lagrangian Loss = 46.4892\n",
      "Epoch 51: Loss = 171.4530\n",
      "Recon Loss = 162.4123, KL Loss = 2.5281, Lagrangian Loss = 33.3449\n",
      "Epoch 101: Loss = 99.3791\n",
      "Recon Loss = 75.2397, KL Loss = 3.2370, Lagrangian Loss = 28.1034\n",
      "Epoch 151: Loss = 72.3241\n",
      "Recon Loss = 47.2353, KL Loss = 3.1233, Lagrangian Loss = 32.0488\n",
      "Epoch 201: Loss = 58.5002\n",
      "Recon Loss = 31.1093, KL Loss = 2.4291, Lagrangian Loss = 26.5335\n",
      "Epoch 251: Loss = 49.3624\n",
      "Recon Loss = 30.2276, KL Loss = 1.5672, Lagrangian Loss = 26.8732\n",
      "Epoch 301: Loss = 45.0948\n",
      "Recon Loss = 24.6973, KL Loss = 1.1495, Lagrangian Loss = 23.3001\n",
      "Epoch 351: Loss = 43.0011\n",
      "Recon Loss = 20.2463, KL Loss = 0.9325, Lagrangian Loss = 31.4571\n",
      "Early stopping triggered. Last Epoch: 350\n",
      "Recon Loss = 20.2463, KL Loss = 0.9325, Lagrangian Loss = 31.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 09:51:55,288 INFO -- Edge Accuracy = 75.00, Instantaneous Accuracy = 75.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 25.00,  Blended Accuracy = 75.00,  RR Accuracy = 75.00  \n",
      "2025-03-22 09:51:55,288 INFO -- Model: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2128.3447\n",
      "Recon Loss = 1738.3760, KL Loss = 0.3675, Lagrangian Loss = 53.4780\n",
      "Epoch 51: Loss = 188.0932\n",
      "Recon Loss = 182.5275, KL Loss = 2.5389, Lagrangian Loss = 34.2117\n",
      "Epoch 101: Loss = 121.2006\n",
      "Recon Loss = 105.5360, KL Loss = 3.5709, Lagrangian Loss = 25.4311\n",
      "Epoch 151: Loss = 90.1863\n",
      "Recon Loss = 61.3320, KL Loss = 4.1974, Lagrangian Loss = 19.3665\n",
      "Epoch 201: Loss = 74.5283\n",
      "Recon Loss = 59.8171, KL Loss = 4.2948, Lagrangian Loss = 26.1925\n",
      "Epoch 251: Loss = 63.8374\n",
      "Recon Loss = 43.0749, KL Loss = 3.9231, Lagrangian Loss = 23.6670\n",
      "Epoch 301: Loss = 57.5694\n",
      "Recon Loss = 41.5244, KL Loss = 3.3844, Lagrangian Loss = 25.4069\n",
      "Epoch 351: Loss = 52.6462\n",
      "Recon Loss = 29.9793, KL Loss = 2.9095, Lagrangian Loss = 26.0613\n",
      "Early stopping triggered. Last Epoch: 384\n",
      "Recon Loss = 34.4356, KL Loss = 2.7099, Lagrangian Loss = 26.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 09:54:05,605 INFO -- Edge Accuracy = 60.00, Instantaneous Accuracy = 60.00, Lagged Accuracy = 60.00, Counterfactual Accuracy = 40.00,  Blended Accuracy = 80.00,  RR Accuracy = 60.00  \n",
      "2025-03-22 09:54:05,605 INFO -- Model: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2338.7471\n",
      "Recon Loss = 1396.3728, KL Loss = 0.3190, Lagrangian Loss = 47.9174\n",
      "Epoch 51: Loss = 106.4483\n",
      "Recon Loss = 76.9623, KL Loss = 4.3407, Lagrangian Loss = 24.4812\n",
      "Epoch 101: Loss = 64.5940\n",
      "Recon Loss = 45.1755, KL Loss = 3.7749, Lagrangian Loss = 24.9469\n",
      "Epoch 151: Loss = 53.2226\n",
      "Recon Loss = 31.8791, KL Loss = 2.4203, Lagrangian Loss = 20.5415\n",
      "Epoch 201: Loss = 45.0938\n",
      "Recon Loss = 25.6924, KL Loss = 1.6841, Lagrangian Loss = 24.3110\n",
      "Epoch 251: Loss = 40.3323\n",
      "Recon Loss = 18.9795, KL Loss = 1.3445, Lagrangian Loss = 21.6006\n",
      "Epoch 301: Loss = 37.5160\n",
      "Recon Loss = 17.8796, KL Loss = 1.0920, Lagrangian Loss = 24.9215\n",
      "Epoch 351: Loss = 34.3739\n",
      "Recon Loss = 12.7392, KL Loss = 0.8521, Lagrangian Loss = 20.5697\n",
      "Epoch 401: Loss = 31.9138\n",
      "Recon Loss = 13.9707, KL Loss = 0.7246, Lagrangian Loss = 22.0244\n",
      "Epoch 451: Loss = 30.3870\n",
      "Recon Loss = 10.9368, KL Loss = 0.5915, Lagrangian Loss = 20.3989\n",
      "Early stopping triggered. Last Epoch: 473\n",
      "Recon Loss = 9.4889, KL Loss = 0.5207, Lagrangian Loss = 20.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:00:21,703 INFO -- Edge Accuracy = 50.00, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 66.67,  RR Accuracy = 50.00  \n",
      "2025-03-22 10:00:21,704 INFO -- Model: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 2207.5810\n",
      "Recon Loss = 1920.2404, KL Loss = 0.3960, Lagrangian Loss = 69.4889\n",
      "Epoch 51: Loss = 190.6943\n",
      "Recon Loss = 204.0631, KL Loss = 2.8978, Lagrangian Loss = 28.1027\n",
      "Epoch 101: Loss = 123.5245\n",
      "Recon Loss = 116.5423, KL Loss = 3.7878, Lagrangian Loss = 25.6579\n",
      "Epoch 151: Loss = 89.0530\n",
      "Recon Loss = 78.2345, KL Loss = 4.1949, Lagrangian Loss = 18.2092\n",
      "Epoch 201: Loss = 72.8805\n",
      "Recon Loss = 57.0335, KL Loss = 4.0267, Lagrangian Loss = 24.7618\n",
      "Epoch 251: Loss = 61.9223\n",
      "Recon Loss = 46.2651, KL Loss = 3.2707, Lagrangian Loss = 20.3383\n",
      "Epoch 301: Loss = 56.5720\n",
      "Recon Loss = 35.3035, KL Loss = 2.5987, Lagrangian Loss = 20.8602\n",
      "Epoch 351: Loss = 52.0906\n",
      "Recon Loss = 38.5955, KL Loss = 2.1829, Lagrangian Loss = 22.3170\n",
      "Epoch 401: Loss = 48.6278\n",
      "Recon Loss = 29.3100, KL Loss = 1.8298, Lagrangian Loss = 23.4064\n",
      "Early stopping triggered. Last Epoch: 437\n",
      "Recon Loss = 29.0129, KL Loss = 1.6717, Lagrangian Loss = 17.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:02:51,381 INFO -- Edge Accuracy = 57.14, Instantaneous Accuracy = 57.14, Lagged Accuracy = 42.86, Counterfactual Accuracy = 57.14,  Blended Accuracy = 71.43,  RR Accuracy = 57.14  \n",
      "2025-03-22 10:02:51,382 INFO -- Model: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2564.4036\n",
      "Recon Loss = 1883.2520, KL Loss = 0.3158, Lagrangian Loss = 63.2248\n",
      "Epoch 51: Loss = 137.3347\n",
      "Recon Loss = 126.2799, KL Loss = 3.3219, Lagrangian Loss = 25.2118\n",
      "Epoch 101: Loss = 82.7500\n",
      "Recon Loss = 65.8702, KL Loss = 4.6815, Lagrangian Loss = 20.8497\n",
      "Epoch 151: Loss = 62.2462\n",
      "Recon Loss = 44.5384, KL Loss = 4.9371, Lagrangian Loss = 20.5944\n",
      "Epoch 201: Loss = 51.8525\n",
      "Recon Loss = 35.6448, KL Loss = 4.0976, Lagrangian Loss = 23.2539\n",
      "Epoch 251: Loss = 44.6718\n",
      "Recon Loss = 28.5679, KL Loss = 2.9590, Lagrangian Loss = 18.2962\n",
      "Epoch 301: Loss = 39.3628\n",
      "Recon Loss = 21.9008, KL Loss = 2.2611, Lagrangian Loss = 21.5568\n",
      "Epoch 351: Loss = 36.6591\n",
      "Recon Loss = 21.8140, KL Loss = 1.7410, Lagrangian Loss = 26.1229\n",
      "Epoch 401: Loss = 34.1879\n",
      "Recon Loss = 18.7268, KL Loss = 1.4268, Lagrangian Loss = 18.9285\n",
      "Early stopping triggered. Last Epoch: 424\n",
      "Recon Loss = 17.4775, KL Loss = 1.3127, Lagrangian Loss = 18.4918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:06:05,149 INFO -- Edge Accuracy = 62.50, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 62.50,  Blended Accuracy = 75.00,  RR Accuracy = 62.50  \n",
      "2025-03-22 10:06:05,149 INFO -- Model: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 1921.1971\n",
      "Recon Loss = 1123.4033, KL Loss = 0.4774, Lagrangian Loss = 44.8168\n",
      "Epoch 51: Loss = 101.7524\n",
      "Recon Loss = 77.7654, KL Loss = 3.6350, Lagrangian Loss = 33.7438\n",
      "Epoch 101: Loss = 65.6407\n",
      "Recon Loss = 42.6449, KL Loss = 2.5933, Lagrangian Loss = 26.7989\n",
      "Epoch 151: Loss = 52.3703\n",
      "Recon Loss = 32.0826, KL Loss = 1.5875, Lagrangian Loss = 23.9356\n",
      "Epoch 201: Loss = 45.8038\n",
      "Recon Loss = 20.1866, KL Loss = 1.1286, Lagrangian Loss = 24.7500\n",
      "Epoch 251: Loss = 42.2561\n",
      "Recon Loss = 19.4080, KL Loss = 0.8262, Lagrangian Loss = 24.3168\n",
      "Epoch 301: Loss = 38.3329\n",
      "Recon Loss = 16.2861, KL Loss = 0.5923, Lagrangian Loss = 25.9824\n",
      "Epoch 351: Loss = 34.4875\n",
      "Recon Loss = 13.5659, KL Loss = 0.4637, Lagrangian Loss = 24.8622\n",
      "Epoch 401: Loss = 31.4563\n",
      "Recon Loss = 9.4257, KL Loss = 0.3172, Lagrangian Loss = 25.2315\n",
      "Early stopping triggered. Last Epoch: 438\n",
      "Recon Loss = 7.5964, KL Loss = 0.2438, Lagrangian Loss = 21.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:11:53,477 INFO -- Edge Accuracy = 55.56, Instantaneous Accuracy = 44.44, Lagged Accuracy = 44.44, Counterfactual Accuracy = 55.56,  Blended Accuracy = 66.67,  RR Accuracy = 55.56  \n",
      "2025-03-22 10:11:53,477 INFO -- Model: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 2369.9901\n",
      "Recon Loss = 1695.4753, KL Loss = 0.4011, Lagrangian Loss = 53.0853\n",
      "Epoch 51: Loss = 140.9626\n",
      "Recon Loss = 128.7968, KL Loss = 3.5108, Lagrangian Loss = 26.2691\n",
      "Epoch 101: Loss = 88.6752\n",
      "Recon Loss = 67.6045, KL Loss = 4.2075, Lagrangian Loss = 17.7418\n",
      "Epoch 151: Loss = 67.9341\n",
      "Recon Loss = 53.4850, KL Loss = 3.2179, Lagrangian Loss = 20.0791\n",
      "Epoch 201: Loss = 57.8819\n",
      "Recon Loss = 41.3117, KL Loss = 2.2775, Lagrangian Loss = 17.0174\n",
      "Epoch 251: Loss = 51.5558\n",
      "Recon Loss = 35.3669, KL Loss = 1.7146, Lagrangian Loss = 18.0508\n",
      "Epoch 301: Loss = 46.0290\n",
      "Recon Loss = 30.2494, KL Loss = 1.2954, Lagrangian Loss = 18.1834\n",
      "Epoch 351: Loss = 42.3467\n",
      "Recon Loss = 32.4653, KL Loss = 1.0301, Lagrangian Loss = 17.8544\n",
      "Epoch 401: Loss = 39.1705\n",
      "Recon Loss = 26.2160, KL Loss = 0.8888, Lagrangian Loss = 19.1985\n",
      "Epoch 451: Loss = 35.1871\n",
      "Recon Loss = 18.4738, KL Loss = 0.6778, Lagrangian Loss = 16.0298\n",
      "Epoch 501: Loss = 32.9187\n",
      "Recon Loss = 14.8526, KL Loss = 0.5175, Lagrangian Loss = 18.2014\n",
      "Epoch 551: Loss = 29.6113\n",
      "Recon Loss = 13.4774, KL Loss = 0.3985, Lagrangian Loss = 16.4263\n",
      "Early stopping triggered. Last Epoch: 579\n",
      "Recon Loss = 14.1893, KL Loss = 0.3458, Lagrangian Loss = 15.8284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:17:26,990 INFO -- Edge Accuracy = 60.00, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 50.00,  Blended Accuracy = 70.00,  RR Accuracy = 50.00  \n",
      "2025-03-22 10:17:26,991 INFO -- Model: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2653.0802\n",
      "Recon Loss = 2410.3345, KL Loss = 0.1716, Lagrangian Loss = 47.6673\n",
      "Epoch 51: Loss = 170.1351\n",
      "Recon Loss = 159.3120, KL Loss = 2.8979, Lagrangian Loss = 29.1268\n",
      "Epoch 101: Loss = 104.0502\n",
      "Recon Loss = 89.4311, KL Loss = 3.8580, Lagrangian Loss = 32.0648\n",
      "Epoch 151: Loss = 77.0608\n",
      "Recon Loss = 60.8051, KL Loss = 3.8992, Lagrangian Loss = 29.4833\n",
      "Epoch 201: Loss = 64.6947\n",
      "Recon Loss = 45.9754, KL Loss = 3.2378, Lagrangian Loss = 28.6062\n",
      "Epoch 251: Loss = 56.7838\n",
      "Recon Loss = 42.3449, KL Loss = 2.3403, Lagrangian Loss = 19.1055\n",
      "Epoch 301: Loss = 55.4841\n",
      "Recon Loss = 39.9926, KL Loss = 1.7893, Lagrangian Loss = 32.8859\n",
      "Epoch 351: Loss = 48.6149\n",
      "Recon Loss = 25.9186, KL Loss = 1.5010, Lagrangian Loss = 30.7092\n",
      "Epoch 401: Loss = 43.7156\n",
      "Recon Loss = 25.1496, KL Loss = 1.2163, Lagrangian Loss = 26.1284\n",
      "Epoch 451: Loss = 44.5835\n",
      "Recon Loss = 22.0168, KL Loss = 1.0440, Lagrangian Loss = 24.5966\n",
      "Early stopping triggered. Last Epoch: 475\n",
      "Recon Loss = 18.3021, KL Loss = 0.9844, Lagrangian Loss = 27.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:20:06,631 INFO -- Edge Accuracy = 63.64, Instantaneous Accuracy = 54.55, Lagged Accuracy = 45.45, Counterfactual Accuracy = 45.45,  Blended Accuracy = 72.73,  RR Accuracy = 45.45  \n",
      "2025-03-22 10:20:06,631 INFO -- Model: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 1897.6582\n",
      "Recon Loss = 1194.1097, KL Loss = 0.6271, Lagrangian Loss = 54.2584\n",
      "Epoch 51: Loss = 99.8460\n",
      "Recon Loss = 76.0423, KL Loss = 4.4769, Lagrangian Loss = 28.8678\n",
      "Epoch 101: Loss = 68.4307\n",
      "Recon Loss = 46.0447, KL Loss = 3.3561, Lagrangian Loss = 21.9446\n",
      "Epoch 151: Loss = 55.6111\n",
      "Recon Loss = 29.6682, KL Loss = 2.2228, Lagrangian Loss = 24.1930\n",
      "Epoch 201: Loss = 48.4458\n",
      "Recon Loss = 31.0437, KL Loss = 1.5758, Lagrangian Loss = 22.4393\n",
      "Epoch 251: Loss = 41.5201\n",
      "Recon Loss = 18.6728, KL Loss = 1.2557, Lagrangian Loss = 20.7223\n",
      "Epoch 301: Loss = 38.8927\n",
      "Recon Loss = 19.0988, KL Loss = 1.0685, Lagrangian Loss = 23.1848\n",
      "Epoch 351: Loss = 35.8761\n",
      "Recon Loss = 14.6480, KL Loss = 0.9396, Lagrangian Loss = 21.9530\n",
      "Early stopping triggered. Last Epoch: 364\n",
      "Recon Loss = 17.9372, KL Loss = 0.8961, Lagrangian Loss = 25.3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:24:55,032 INFO -- Edge Accuracy = 66.67, Instantaneous Accuracy = 58.33, Lagged Accuracy = 41.67, Counterfactual Accuracy = 41.67,  Blended Accuracy = 75.00,  RR Accuracy = 41.67  \n",
      "2025-03-22 10:24:55,032 INFO -- Model: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 1702.4145\n",
      "Recon Loss = 961.4645, KL Loss = 0.5635, Lagrangian Loss = 44.1525\n",
      "Epoch 51: Loss = 95.8426\n",
      "Recon Loss = 62.1111, KL Loss = 4.3577, Lagrangian Loss = 21.4173\n",
      "Epoch 101: Loss = 62.2129\n",
      "Recon Loss = 36.8220, KL Loss = 2.7143, Lagrangian Loss = 23.1453\n",
      "Epoch 151: Loss = 49.1481\n",
      "Recon Loss = 28.6936, KL Loss = 1.8405, Lagrangian Loss = 19.7202\n",
      "Epoch 201: Loss = 41.9866\n",
      "Recon Loss = 19.9654, KL Loss = 1.5393, Lagrangian Loss = 18.7621\n",
      "Epoch 251: Loss = 35.8810\n",
      "Recon Loss = 16.8250, KL Loss = 1.2521, Lagrangian Loss = 20.4087\n",
      "Epoch 301: Loss = 31.1665\n",
      "Recon Loss = 13.2553, KL Loss = 1.0326, Lagrangian Loss = 19.3018\n",
      "Epoch 351: Loss = 27.6975\n",
      "Recon Loss = 8.9375, KL Loss = 0.8429, Lagrangian Loss = 19.4571\n",
      "Epoch 401: Loss = 23.5876\n",
      "Recon Loss = 6.6433, KL Loss = 0.6626, Lagrangian Loss = 17.8533\n",
      "Early stopping triggered. Last Epoch: 420\n",
      "Recon Loss = 5.4945, KL Loss = 0.6152, Lagrangian Loss = 16.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:32:51,317 INFO -- Edge Accuracy = 61.54, Instantaneous Accuracy = 53.85, Lagged Accuracy = 46.15, Counterfactual Accuracy = 38.46,  Blended Accuracy = 69.23,  RR Accuracy = 46.15  \n",
      "2025-03-22 10:32:51,318 INFO -- Model: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 2574.7079\n",
      "Recon Loss = 2283.2817, KL Loss = 0.5479, Lagrangian Loss = 61.1710\n",
      "Epoch 51: Loss = 210.1165\n",
      "Recon Loss = 208.1840, KL Loss = 3.1927, Lagrangian Loss = 29.1028\n",
      "Epoch 101: Loss = 120.8982\n",
      "Recon Loss = 108.8003, KL Loss = 4.8056, Lagrangian Loss = 24.3876\n",
      "Epoch 151: Loss = 91.9074\n",
      "Recon Loss = 78.1515, KL Loss = 5.8535, Lagrangian Loss = 27.7953\n",
      "Epoch 201: Loss = 78.5466\n",
      "Recon Loss = 55.7610, KL Loss = 6.1797, Lagrangian Loss = 30.7528\n",
      "Epoch 251: Loss = 67.4570\n",
      "Recon Loss = 51.3198, KL Loss = 5.6767, Lagrangian Loss = 22.6412\n",
      "Epoch 301: Loss = 58.9959\n",
      "Recon Loss = 33.2077, KL Loss = 4.8614, Lagrangian Loss = 26.4601\n",
      "Epoch 351: Loss = 54.1961\n",
      "Recon Loss = 35.5838, KL Loss = 4.1880, Lagrangian Loss = 20.4901\n",
      "Epoch 401: Loss = 49.9968\n",
      "Recon Loss = 31.7449, KL Loss = 3.5409, Lagrangian Loss = 24.4152\n",
      "Epoch 451: Loss = 46.7773\n",
      "Recon Loss = 26.7721, KL Loss = 3.1821, Lagrangian Loss = 22.4712\n",
      "Early stopping triggered. Last Epoch: 487\n",
      "Recon Loss = 27.5294, KL Loss = 2.9080, Lagrangian Loss = 21.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:35:37,719 INFO -- Edge Accuracy = 57.14, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 42.86,  Blended Accuracy = 64.29,  RR Accuracy = 42.86  \n",
      "2025-03-22 10:35:37,719 INFO -- Model: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2858.5398\n",
      "Recon Loss = 2442.0869, KL Loss = 0.1492, Lagrangian Loss = 52.4863\n",
      "Epoch 51: Loss = 190.2462\n",
      "Recon Loss = 181.9933, KL Loss = 2.6829, Lagrangian Loss = 33.6610\n",
      "Epoch 101: Loss = 119.2464\n",
      "Recon Loss = 100.6192, KL Loss = 3.6802, Lagrangian Loss = 26.5894\n",
      "Epoch 151: Loss = 89.9513\n",
      "Recon Loss = 69.3926, KL Loss = 4.1728, Lagrangian Loss = 29.0067\n",
      "Epoch 201: Loss = 71.3861\n",
      "Recon Loss = 57.1356, KL Loss = 4.1051, Lagrangian Loss = 25.1714\n",
      "Epoch 251: Loss = 65.6432\n",
      "Recon Loss = 42.1354, KL Loss = 3.4387, Lagrangian Loss = 29.2260\n",
      "Epoch 301: Loss = 55.5661\n",
      "Recon Loss = 34.1451, KL Loss = 2.8747, Lagrangian Loss = 29.5327\n",
      "Epoch 351: Loss = 51.8509\n",
      "Recon Loss = 36.5401, KL Loss = 2.2983, Lagrangian Loss = 25.6394\n",
      "Epoch 401: Loss = 49.9156\n",
      "Recon Loss = 29.5936, KL Loss = 1.9151, Lagrangian Loss = 30.6703\n",
      "Epoch 451: Loss = 45.9003\n",
      "Recon Loss = 23.4519, KL Loss = 1.5650, Lagrangian Loss = 31.8853\n",
      "Epoch 501: Loss = 42.9518\n",
      "Recon Loss = 21.6439, KL Loss = 1.4580, Lagrangian Loss = 25.5060\n",
      "Early stopping triggered. Last Epoch: 515\n",
      "Recon Loss = 20.5609, KL Loss = 1.3215, Lagrangian Loss = 27.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:38:33,692 INFO -- Edge Accuracy = 60.00, Instantaneous Accuracy = 53.33, Lagged Accuracy = 46.67, Counterfactual Accuracy = 40.00,  Blended Accuracy = 60.00,  RR Accuracy = 40.00  \n",
      "2025-03-22 10:38:33,693 INFO -- Model: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 1820.1459\n",
      "Recon Loss = 1274.6162, KL Loss = 0.3684, Lagrangian Loss = 50.9495\n",
      "Epoch 51: Loss = 123.5278\n",
      "Recon Loss = 93.9900, KL Loss = 4.3595, Lagrangian Loss = 30.0549\n",
      "Epoch 101: Loss = 76.1638\n",
      "Recon Loss = 50.4780, KL Loss = 5.5394, Lagrangian Loss = 24.0420\n",
      "Epoch 151: Loss = 59.1140\n",
      "Recon Loss = 36.4901, KL Loss = 4.6788, Lagrangian Loss = 20.7520\n",
      "Epoch 201: Loss = 49.5409\n",
      "Recon Loss = 21.2211, KL Loss = 3.4059, Lagrangian Loss = 21.2208\n",
      "Epoch 251: Loss = 42.1504\n",
      "Recon Loss = 24.7590, KL Loss = 2.6875, Lagrangian Loss = 23.8818\n",
      "Epoch 301: Loss = 38.5963\n",
      "Recon Loss = 19.6822, KL Loss = 2.1954, Lagrangian Loss = 22.7517\n",
      "Epoch 351: Loss = 34.8314\n",
      "Recon Loss = 13.3015, KL Loss = 1.8558, Lagrangian Loss = 20.7293\n",
      "Epoch 401: Loss = 33.3022\n",
      "Recon Loss = 10.5191, KL Loss = 1.5805, Lagrangian Loss = 21.3954\n",
      "Epoch 451: Loss = 30.8441\n",
      "Recon Loss = 10.9920, KL Loss = 1.3698, Lagrangian Loss = 23.2177\n",
      "Early stopping triggered. Last Epoch: 488\n",
      "Recon Loss = 9.6903, KL Loss = 1.2522, Lagrangian Loss = 23.0617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:43:18,625 INFO -- Edge Accuracy = 56.25, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 43.75,  Blended Accuracy = 62.50,  RR Accuracy = 37.50  \n",
      "2025-03-22 10:43:18,625 INFO -- Model: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 1974.4155\n",
      "Recon Loss = 1223.6022, KL Loss = 0.5807, Lagrangian Loss = 53.5267\n",
      "Epoch 51: Loss = 114.0139\n",
      "Recon Loss = 86.7179, KL Loss = 4.3039, Lagrangian Loss = 31.1739\n",
      "Epoch 101: Loss = 70.9825\n",
      "Recon Loss = 44.5767, KL Loss = 4.0175, Lagrangian Loss = 27.9308\n",
      "Epoch 151: Loss = 55.8516\n",
      "Recon Loss = 36.0608, KL Loss = 2.8507, Lagrangian Loss = 24.2698\n",
      "Epoch 201: Loss = 46.4960\n",
      "Recon Loss = 19.7596, KL Loss = 2.1570, Lagrangian Loss = 24.2194\n",
      "Epoch 251: Loss = 41.9724\n",
      "Recon Loss = 20.8786, KL Loss = 1.8011, Lagrangian Loss = 20.3599\n",
      "Epoch 301: Loss = 37.8250\n",
      "Recon Loss = 14.9000, KL Loss = 1.5630, Lagrangian Loss = 20.8336\n",
      "Epoch 351: Loss = 35.3984\n",
      "Recon Loss = 12.7054, KL Loss = 1.4143, Lagrangian Loss = 21.0183\n",
      "Early stopping triggered. Last Epoch: 364\n",
      "Recon Loss = 10.7152, KL Loss = 1.3531, Lagrangian Loss = 17.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:48:05,675 INFO -- Edge Accuracy = 58.82, Instantaneous Accuracy = 52.94, Lagged Accuracy = 52.94, Counterfactual Accuracy = 47.06,  Blended Accuracy = 64.71,  RR Accuracy = 35.29  \n",
      "2025-03-22 10:48:05,675 INFO -- Model: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 977.5003\n",
      "Recon Loss = 481.7601, KL Loss = 1.8166, Lagrangian Loss = 31.8834\n",
      "Epoch 51: Loss = 45.6861\n",
      "Recon Loss = 23.9987, KL Loss = 1.3445, Lagrangian Loss = 24.2841\n",
      "Epoch 101: Loss = 26.2592\n",
      "Recon Loss = 6.5238, KL Loss = 0.6904, Lagrangian Loss = 17.7749\n",
      "Epoch 151: Loss = 21.9423\n",
      "Recon Loss = 3.9800, KL Loss = 0.3686, Lagrangian Loss = 18.6684\n",
      "Epoch 201: Loss = 19.3508\n",
      "Recon Loss = 2.1320, KL Loss = 0.1987, Lagrangian Loss = 16.2666\n",
      "Epoch 251: Loss = 17.1308\n",
      "Recon Loss = 1.9105, KL Loss = 0.0349, Lagrangian Loss = 14.7342\n",
      "Epoch 301: Loss = 15.6692\n",
      "Recon Loss = 1.6401, KL Loss = 0.0031, Lagrangian Loss = 11.3830\n",
      "Epoch 351: Loss = 14.2256\n",
      "Recon Loss = 1.5792, KL Loss = 0.0012, Lagrangian Loss = 17.2623\n",
      "Epoch 401: Loss = 13.2480\n",
      "Recon Loss = 1.7683, KL Loss = 0.0011, Lagrangian Loss = 10.3452\n",
      "Epoch 451: Loss = 12.2797\n",
      "Recon Loss = 1.4879, KL Loss = 0.0007, Lagrangian Loss = 13.9384\n",
      "Epoch 501: Loss = 11.6638\n",
      "Recon Loss = 1.0491, KL Loss = 0.0012, Lagrangian Loss = 10.6010\n",
      "Epoch 551: Loss = 10.9108\n",
      "Recon Loss = 1.1551, KL Loss = 0.0013, Lagrangian Loss = 9.9355\n",
      "Epoch 601: Loss = 9.9686\n",
      "Recon Loss = 0.7881, KL Loss = 0.0006, Lagrangian Loss = 9.4384\n",
      "Epoch 651: Loss = 9.4337\n",
      "Recon Loss = 0.8751, KL Loss = 0.0008, Lagrangian Loss = 9.2932\n",
      "Epoch 701: Loss = 9.0036\n",
      "Recon Loss = 0.9380, KL Loss = 0.0006, Lagrangian Loss = 7.9793\n",
      "Epoch 751: Loss = 8.3535\n",
      "Recon Loss = 0.8163, KL Loss = 0.0005, Lagrangian Loss = 6.8292\n",
      "Epoch 801: Loss = 8.0263\n",
      "Recon Loss = 0.9205, KL Loss = 0.0007, Lagrangian Loss = 7.8806\n",
      "Epoch 851: Loss = 7.7448\n",
      "Recon Loss = 1.7927, KL Loss = 0.0003, Lagrangian Loss = 7.2222\n",
      "Early stopping triggered. Last Epoch: 863\n",
      "Recon Loss = 1.0214, KL Loss = 0.0004, Lagrangian Loss = 8.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:10:39,466 INFO -- Edge Accuracy = 55.56, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 44.44,  Blended Accuracy = 61.11,  RR Accuracy = 33.33  \n",
      "2025-03-22 12:10:39,466 INFO -- Model: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 2442.0214\n",
      "Recon Loss = 1609.9196, KL Loss = 0.7326, Lagrangian Loss = 57.6702\n",
      "Epoch 51: Loss = 144.6862\n",
      "Recon Loss = 130.5295, KL Loss = 4.0181, Lagrangian Loss = 25.2834\n",
      "Epoch 101: Loss = 85.2368\n",
      "Recon Loss = 60.4602, KL Loss = 4.4353, Lagrangian Loss = 24.5963\n",
      "Epoch 151: Loss = 65.2785\n",
      "Recon Loss = 48.4910, KL Loss = 3.1531, Lagrangian Loss = 26.2868\n",
      "Epoch 201: Loss = 54.4231\n",
      "Recon Loss = 34.5173, KL Loss = 1.9893, Lagrangian Loss = 18.9119\n",
      "Epoch 251: Loss = 49.2136\n",
      "Recon Loss = 31.5353, KL Loss = 1.4526, Lagrangian Loss = 26.0135\n",
      "Epoch 301: Loss = 44.8504\n",
      "Recon Loss = 25.3998, KL Loss = 1.1288, Lagrangian Loss = 26.3988\n",
      "Early stopping triggered. Last Epoch: 335\n",
      "Recon Loss = 23.6815, KL Loss = 0.9873, Lagrangian Loss = 27.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:13:47,736 INFO -- Edge Accuracy = 52.63, Instantaneous Accuracy = 47.37, Lagged Accuracy = 47.37, Counterfactual Accuracy = 42.11,  Blended Accuracy = 57.89,  RR Accuracy = 36.84  \n",
      "2025-03-22 12:13:47,736 INFO -- Model: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 2604.3408\n",
      "Recon Loss = 2176.5132, KL Loss = 0.2878, Lagrangian Loss = 45.3332\n",
      "Epoch 51: Loss = 183.6874\n",
      "Recon Loss = 180.6478, KL Loss = 3.3697, Lagrangian Loss = 29.1503\n",
      "Epoch 101: Loss = 102.3109\n",
      "Recon Loss = 87.0181, KL Loss = 4.4785, Lagrangian Loss = 25.2926\n",
      "Epoch 151: Loss = 74.5011\n",
      "Recon Loss = 46.1864, KL Loss = 4.5124, Lagrangian Loss = 28.7880\n",
      "Epoch 201: Loss = 63.3032\n",
      "Recon Loss = 43.4983, KL Loss = 3.5779, Lagrangian Loss = 28.7628\n",
      "Epoch 251: Loss = 54.9600\n",
      "Recon Loss = 33.8614, KL Loss = 2.7565, Lagrangian Loss = 21.7930\n",
      "Epoch 301: Loss = 50.8970\n",
      "Recon Loss = 28.9649, KL Loss = 2.2045, Lagrangian Loss = 26.7302\n",
      "Epoch 351: Loss = 43.6023\n",
      "Recon Loss = 26.1894, KL Loss = 1.8179, Lagrangian Loss = 20.2348\n",
      "Early stopping triggered. Last Epoch: 366\n",
      "Recon Loss = 31.4201, KL Loss = 1.6834, Lagrangian Loss = 19.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:15:58,484 INFO -- Edge Accuracy = 55.00, Instantaneous Accuracy = 50.00, Lagged Accuracy = 50.00, Counterfactual Accuracy = 45.00,  Blended Accuracy = 60.00,  RR Accuracy = 40.00  \n",
      "2025-03-22 12:15:58,485 INFO -- Model: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 2814.0631\n",
      "Recon Loss = 2441.0671, KL Loss = 0.3066, Lagrangian Loss = 58.0268\n",
      "Epoch 51: Loss = 188.4535\n",
      "Recon Loss = 184.1116, KL Loss = 3.1009, Lagrangian Loss = 36.1247\n",
      "Epoch 101: Loss = 111.4357\n",
      "Recon Loss = 98.2993, KL Loss = 4.3406, Lagrangian Loss = 33.9003\n",
      "Epoch 151: Loss = 80.8004\n",
      "Recon Loss = 58.0297, KL Loss = 4.7833, Lagrangian Loss = 26.7360\n",
      "Epoch 201: Loss = 68.0390\n",
      "Recon Loss = 45.5928, KL Loss = 4.4534, Lagrangian Loss = 33.6116\n",
      "Epoch 251: Loss = 56.4351\n",
      "Recon Loss = 38.6017, KL Loss = 3.6620, Lagrangian Loss = 26.0817\n",
      "Epoch 301: Loss = 49.1512\n",
      "Recon Loss = 30.2697, KL Loss = 2.9164, Lagrangian Loss = 24.3157\n",
      "Epoch 351: Loss = 45.6312\n",
      "Recon Loss = 23.8573, KL Loss = 2.4747, Lagrangian Loss = 24.7583\n",
      "Early stopping triggered. Last Epoch: 353\n",
      "Recon Loss = 25.2086, KL Loss = 2.4255, Lagrangian Loss = 23.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:18:02,760 INFO -- Edge Accuracy = 52.38, Instantaneous Accuracy = 47.62, Lagged Accuracy = 52.38, Counterfactual Accuracy = 42.86,  Blended Accuracy = 57.14,  RR Accuracy = 42.86  \n",
      "2025-03-22 12:18:02,760 INFO -- Model: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cfo1\n",
      "Epoch 1: Loss = 2734.2262\n",
      "Recon Loss = 1953.2896, KL Loss = 0.3755, Lagrangian Loss = 48.8505\n",
      "Epoch 51: Loss = 154.7931\n",
      "Recon Loss = 135.1642, KL Loss = 3.2265, Lagrangian Loss = 26.6985\n",
      "Epoch 101: Loss = 92.8851\n",
      "Recon Loss = 60.2373, KL Loss = 3.7070, Lagrangian Loss = 27.3216\n",
      "Epoch 151: Loss = 72.0914\n",
      "Recon Loss = 39.7093, KL Loss = 2.9037, Lagrangian Loss = 26.4222\n",
      "Epoch 201: Loss = 57.3824\n",
      "Recon Loss = 40.3737, KL Loss = 1.9601, Lagrangian Loss = 22.8855\n",
      "Epoch 251: Loss = 52.2234\n",
      "Recon Loss = 35.0998, KL Loss = 1.5085, Lagrangian Loss = 26.5877\n",
      "Epoch 301: Loss = 48.8896\n",
      "Recon Loss = 25.2760, KL Loss = 1.2211, Lagrangian Loss = 29.9150\n",
      "Epoch 351: Loss = 43.2534\n",
      "Recon Loss = 20.1836, KL Loss = 1.0256, Lagrangian Loss = 24.4254\n",
      "Epoch 401: Loss = 41.4708\n",
      "Recon Loss = 20.7031, KL Loss = 0.8894, Lagrangian Loss = 24.1932\n",
      "Epoch 451: Loss = 37.2406\n",
      "Recon Loss = 13.6955, KL Loss = 0.7752, Lagrangian Loss = 23.9665\n",
      "Epoch 501: Loss = 37.0504\n",
      "Recon Loss = 11.0983, KL Loss = 0.6700, Lagrangian Loss = 28.9186\n",
      "Early stopping triggered. Last Epoch: 519\n",
      "Recon Loss = 15.1080, KL Loss = 0.6505, Lagrangian Loss = 21.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:23:03,453 INFO -- Edge Accuracy = 50.00, Instantaneous Accuracy = 45.45, Lagged Accuracy = 54.55, Counterfactual Accuracy = 40.91,  Blended Accuracy = 54.55,  RR Accuracy = 45.45  \n",
      "2025-03-22 12:23:03,454 INFO -- Model: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: cso1\n",
      "Epoch 1: Loss = 2217.8210\n",
      "Recon Loss = 1770.1704, KL Loss = 0.4280, Lagrangian Loss = 47.3229\n",
      "Epoch 51: Loss = 153.4547\n",
      "Recon Loss = 144.9952, KL Loss = 4.2570, Lagrangian Loss = 25.6284\n",
      "Epoch 101: Loss = 95.3388\n",
      "Recon Loss = 72.4495, KL Loss = 5.1481, Lagrangian Loss = 24.1901\n",
      "Epoch 151: Loss = 70.2629\n",
      "Recon Loss = 50.1460, KL Loss = 4.5233, Lagrangian Loss = 22.4092\n",
      "Epoch 201: Loss = 60.4072\n",
      "Recon Loss = 36.3174, KL Loss = 3.4211, Lagrangian Loss = 30.4533\n",
      "Epoch 251: Loss = 52.8238\n",
      "Recon Loss = 39.3788, KL Loss = 2.6665, Lagrangian Loss = 22.7608\n",
      "Epoch 301: Loss = 46.9930\n",
      "Recon Loss = 29.4365, KL Loss = 2.1774, Lagrangian Loss = 22.9121\n",
      "Epoch 351: Loss = 42.4639\n",
      "Recon Loss = 28.9633, KL Loss = 1.8921, Lagrangian Loss = 22.0881\n",
      "Epoch 401: Loss = 41.8066\n",
      "Recon Loss = 19.7004, KL Loss = 1.6198, Lagrangian Loss = 25.5009\n",
      "Epoch 451: Loss = 41.1555\n",
      "Recon Loss = 18.9585, KL Loss = 1.4546, Lagrangian Loss = 33.3644\n",
      "Epoch 501: Loss = 38.7107\n",
      "Recon Loss = 20.6994, KL Loss = 1.2973, Lagrangian Loss = 22.6792\n",
      "Early stopping triggered. Last Epoch: 525\n",
      "Recon Loss = 12.9984, KL Loss = 1.2411, Lagrangian Loss = 22.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:27:06,131 INFO -- Edge Accuracy = 52.17, Instantaneous Accuracy = 47.83, Lagged Accuracy = 56.52, Counterfactual Accuracy = 39.13,  Blended Accuracy = 52.17,  RR Accuracy = 43.48  \n",
      "2025-03-22 12:27:06,131 INFO -- Model: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly: ced1\n",
      "Epoch 1: Loss = 908.1380\n",
      "Recon Loss = 442.5283, KL Loss = 2.1652, Lagrangian Loss = 35.0718\n",
      "Epoch 51: Loss = 39.1872\n",
      "Recon Loss = 16.0165, KL Loss = 1.2623, Lagrangian Loss = 24.0575\n",
      "Epoch 101: Loss = 24.1083\n",
      "Recon Loss = 3.5334, KL Loss = 0.2939, Lagrangian Loss = 23.1278\n",
      "Epoch 151: Loss = 20.1982\n",
      "Recon Loss = 2.5564, KL Loss = 0.0229, Lagrangian Loss = 17.2491\n",
      "Epoch 201: Loss = 17.8355\n",
      "Recon Loss = 1.9418, KL Loss = 0.0078, Lagrangian Loss = 13.4176\n",
      "Epoch 251: Loss = 16.1810\n",
      "Recon Loss = 0.9758, KL Loss = 0.0030, Lagrangian Loss = 12.0487\n",
      "Epoch 301: Loss = 14.7292\n",
      "Recon Loss = 1.0472, KL Loss = 0.0032, Lagrangian Loss = 15.8872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 57\u001b[0m\n\u001b[0;32m     51\u001b[0m fine_tuned \u001b[38;5;241m=\u001b[39m CausalGraphVAE(input_dim\u001b[38;5;241m=\u001b[39mnum_nodes, hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[0;32m     52\u001b[0m                        latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim, num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes,device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     53\u001b[0m                        time_steps\u001b[38;5;241m=\u001b[39mTIME_STEPS,prior_adj\u001b[38;5;241m=\u001b[39mprior_adj,instantaneous_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     54\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(fine_tuned\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)  \u001b[38;5;66;03m# L2 Regularization\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m fine_tuned\u001b[38;5;241m.\u001b[39mtrain_model(dataloader, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,BATCH_SIZE\u001b[38;5;241m=\u001b[39mBATCH_SIZE,rho_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m,alpha_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[0;32m     59\u001b[0m causes \u001b[38;5;241m=\u001b[39m fine_tuned\u001b[38;5;241m.\u001b[39minfer_causal_effect(X_data\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device),T_data\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device),anomaly,cols,non_causal_indices\u001b[38;5;241m=\u001b[39mnon_causal_indices)\n\u001b[0;32m     61\u001b[0m causes \u001b[38;5;241m=\u001b[39m causes\u001b[38;5;241m.\u001b[39mfilter(items\u001b[38;5;241m=\u001b[39mpotential_causes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:248\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(self, dataloader, optimizer, num_epochs, patience, BATCH_SIZE, rho_max, alpha_max)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loss function including reconstruction, KL divergence, DAG penalty, and prior regularization\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m recon_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(recon_X, X, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1.0\u001b[39m, epoch \u001b[38;5;241m/\u001b[39m (max_epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.3\u001b[39m))  \u001b[38;5;66;03m# Gradual increase in KL weight\u001b[39;00m\n\u001b[0;32m    249\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m logvar \u001b[38;5;241m-\u001b[39m mu\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m logvar\u001b[38;5;241m.\u001b[39mexp()) \u001b[38;5;241m*\u001b[39m beta\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Regularization on adjacency matrix (pretrained `prior_adj` should remain mostly intact)\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m#prior_loss = lambda_prior * (torch.norm(adj_now - self.prior_adj, p=1) + torch.norm(adj_lag - self.prior_adj, p=1))\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#lagrangian_loss = (self.alpha * h_value + 0.5 * self.rho * (h_value ** 2)) #/ (self.num_nodes ** 2)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model.py:226\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(self, recon_X, X, mu, logvar, adj_now, adj_lag, epoch, max_epochs, rho_max, alpha_max, lambda_prior)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Identity matrix\u001b[39;00m\n\u001b[0;32m    225\u001b[0m m \u001b[38;5;241m=\u001b[39m adj_mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 226\u001b[0m I \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(m, device\u001b[38;5;241m=\u001b[39madj_mat\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Matrix exponential approximation via power series\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# We compute (I + A + A²/2! + A³/3! + ...) - I\u001b[39;00m\n\u001b[0;32m    230\u001b[0m power_sum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(I)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\CARAT_CI\\src\\CARAT\\model_utils.py:95\u001b[0m, in \u001b[0;36mnotears_constraint\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     93\u001b[0m d \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     94\u001b[0m W \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m expm_ww \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatrix_exp(W \u001b[38;5;241m*\u001b[39m W)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtrace(expm_ww) \u001b[38;5;241m-\u001b[39m d\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols = list(test_df.columns)\n",
    "non_causal_columns = list(set(cols).difference(set(potential_causes)))\n",
    "causal_indices = [train_df.columns.get_loc(col) for col in potential_causes]\n",
    "non_causal_indices = [train_df.columns.get_loc(col) for col in non_causal_columns]\n",
    "num_nodes = len(train_df.columns)\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "new_metadata = []\n",
    "edge_correct = 0\n",
    "instantaneous_correct = 0\n",
    "lagged_correct = 0\n",
    "counterfactual_correct = 0 \n",
    "rr_correct = 0\n",
    "total_correct = 0\n",
    "total_checked = 0\n",
    "incorrect = []\n",
    "\n",
    "for i, row in enumerate(cats_rows_list):\n",
    "    total_checked +=1 \n",
    "    logger.info('Model: '+ str(i))\n",
    "    anomaly = eval(row['affected'])[0]\n",
    "    print('Anomaly: ' + anomaly)\n",
    "    anomaly_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    #start_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = datetime.strptime(row['end_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    root_cause = row['root_cause']\n",
    "    #start_len = mod_df.shape[0]\n",
    "    #if start_len >1000:\n",
    "        #start_len = 1000\n",
    "    start_len = 8\n",
    "    start_time = anomaly_time- timedelta(seconds=start_len)\n",
    "    finish_time = end_time + timedelta(seconds=start_len)\n",
    "    mod_df = test_df[(test_df.index>= start_time) & (test_df.index<= finish_time)]\n",
    "    mod_df = mod_df[['aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl', 'bed1',\n",
    "       'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3', 'ced1', 'cfo1', 'cso1']]\n",
    "\n",
    "    \"\"\"\n",
    "    FIND THE OPTIMAL NUMBER OF LAGS\n",
    "    \"\"\"\n",
    "    TIME_STEPS = 8#max(most_frequent(find_optimal_lags_for_dataframe(mod_df))+1,3)\n",
    "\n",
    "    dataset = TimeSeriesDataset(mod_df,device=device, time_steps=TIME_STEPS)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    X_data = torch.empty(0,device=device)\n",
    "    T_data = torch.empty(0,device=device)\n",
    "    for batch_idx, (X_batch, time_batch) in enumerate(dataloader):\n",
    "        X_data = torch.cat((X_data[:batch_idx], X_batch, X_data[batch_idx:]))\n",
    "        T_data = torch.cat((T_data[:batch_idx], time_batch, T_data[batch_idx:]))\n",
    "    \n",
    "    fine_tuned = CausalGraphVAE(input_dim=num_nodes, hidden_dim=hidden_dim,\n",
    "                           latent_dim=latent_dim, num_nodes=num_nodes,device=device,\n",
    "                           time_steps=TIME_STEPS,prior_adj=prior_adj,instantaneous_weight=0.5)\n",
    "    optimizer = torch.optim.AdamW(fine_tuned.parameters(), lr=0.0001, weight_decay=1e-3)  # L2 Regularization\n",
    "\n",
    "    \n",
    "    fine_tuned.train_model(dataloader, optimizer, num_epochs=2500, patience=20,BATCH_SIZE=BATCH_SIZE,rho_max=2.0,alpha_max=2.0)\n",
    "\n",
    "    causes = fine_tuned.infer_causal_effect(X_data.to(torch.float32).to(device),T_data.to(torch.float32).to(device),anomaly,cols,non_causal_indices=non_causal_indices)\n",
    "    \n",
    "    causes = causes.filter(items=potential_causes, axis=0)\n",
    "    edge_cause_1 = causes.sort_values(by='causes',ascending=False)[0:3].index[0]\n",
    "    edge_cause_2 = causes.sort_values(by='causes',ascending=False)[0:3].index[1]\n",
    "    edge_cause_3 = causes.sort_values(by='causes',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    instant_cause_1 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[0]\n",
    "    instant_cause_2 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[1]\n",
    "    instant_cause_3 = causes.sort_values(by='instantaneous',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    lag_cause_1 = causes.sort_values(by='lagged',ascending=False)[0:3].index[0]\n",
    "    lag_cause_2 = causes.sort_values(by='lagged',ascending=False)[0:3].index[1]\n",
    "    lag_cause_3 = causes.sort_values(by='lagged',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    counterfactual_cause_1 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[0]\n",
    "    counterfactual_cause_2 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[1]\n",
    "    counterfactual_cause_3 = causes.sort_values(by='counterfactuals',ascending=False)[0:3].index[2]\n",
    "\n",
    "    rr_cause_1 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[0]\n",
    "    rr_cause_2 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[1]\n",
    "    rr_cause_3 = causes.sort_values(by='RootRank',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    total_score_cause_1=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[0]\n",
    "    total_score_cause_2=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[1]\n",
    "    total_score_cause_3=causes.sort_values(by='causal_strength',ascending=False)[0:3].index[2]\n",
    "    \n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_1'] = 1\n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_2'] = 1\n",
    "    if root_cause == edge_cause_1:\n",
    "        row['edge_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == counterfactual_cause_1:\n",
    "        row['counterfactual_cause_1'] = 1\n",
    "    if root_cause == counterfactual_cause_2:\n",
    "        row['counterfactual_cause_2'] = 1\n",
    "    if root_cause == counterfactual_cause_3:\n",
    "        row['counterfactual_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == total_score_cause_1:\n",
    "        row['total_score_cause_1'] = 1\n",
    "    if root_cause == total_score_cause_2:\n",
    "        row['total_score_cause_2'] = 1\n",
    "    if root_cause == total_score_cause_3:\n",
    "        row['total_score_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == instant_cause_1:\n",
    "        row['instant_cause_1'] = 1\n",
    "    if root_cause == instant_cause_2:\n",
    "        row['instant_cause_2'] = 1\n",
    "    if root_cause == instant_cause_3:\n",
    "        row['instant_cause_3'] = 1\n",
    "    \n",
    "    if root_cause == lag_cause_1:\n",
    "        row['lag_cause_1'] = 1\n",
    "    if root_cause == lag_cause_2:\n",
    "        row['lag_cause_2'] = 1\n",
    "    if root_cause == lag_cause_3:\n",
    "        row['lag_cause_3'] = 1\n",
    "\n",
    "    if root_cause == rr_cause_1:\n",
    "        row['rr_cause_1'] = 1\n",
    "    if root_cause == rr_cause_2:\n",
    "        row['rr_cause_2'] = 1\n",
    "    if root_cause == rr_cause_3:\n",
    "        row['rr_cause_3'] = 1\n",
    "    \n",
    "    new_metadata.append(row)\n",
    "    \n",
    "    if root_cause in [total_score_cause_1 , total_score_cause_2 , total_score_cause_3]:\n",
    "        total_correct+=1\n",
    "    if root_cause in [edge_cause_1 , edge_cause_2 , edge_cause_3]:\n",
    "        edge_correct+=1\n",
    "    if root_cause in [counterfactual_cause_1 , counterfactual_cause_2 , counterfactual_cause_3]:\n",
    "        counterfactual_correct+=1\n",
    "    if root_cause in [instant_cause_1 , instant_cause_2 , instant_cause_3]:\n",
    "        instantaneous_correct+=1\n",
    "    if root_cause in [lag_cause_1 , lag_cause_2 , lag_cause_3]:\n",
    "        lagged_correct+=1\n",
    "    if root_cause in [rr_cause_1 , rr_cause_2 , rr_cause_3]:\n",
    "        rr_correct+=1\n",
    "    \n",
    "    total_accuracy = total_correct/total_checked* 100\n",
    "    edge_accuracy = edge_correct/total_checked* 100\n",
    "    cf_accuracy = counterfactual_correct/total_checked* 100\n",
    "    instant_accuracy = instantaneous_correct/total_checked* 100\n",
    "    lag_accuracy = lagged_correct/total_checked* 100\n",
    "    rr_accuracy = rr_correct/total_checked* 100\n",
    "    \n",
    "    if root_cause not in [total_score_cause_1 , total_score_cause_2 , total_score_cause_3,edge_cause_1 , edge_cause_2 , edge_cause_3 ]:\n",
    "        incorrect.append(i) \n",
    "    logger.info(f\"Edge Accuracy = {edge_accuracy:.2f}, Instantaneous Accuracy = {instant_accuracy:.2f}, Lagged Accuracy = {lag_accuracy:.2f}, Counterfactual Accuracy = {cf_accuracy:.2f},  Blended Accuracy = {total_accuracy:.2f},  RR Accuracy = {rr_accuracy:.2f}  \") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3a638-f7c1-4ba2-ba66-380c14575be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20161b14-2938-4fa8-98c8-b34e7ed63141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eabbf0-6cbb-4b3b-8a2e-e92cfec228bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
